{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/turbouser44/research/Arxiv2Arxode\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# relative import error with python modules and what not, the path needs to change according to cwd :) \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "print(project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"./datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'https://github.com/IDEA-Research/Grounded-Segment-Anything',\n",
       "  'https://github.com/NVIDIA/vid2vid',\n",
       "  'https://github.com/Stability-AI/stablediffusion',\n",
       "  'https://github.com/black0017/MedicalZooPytorch',\n",
       "  'https://github.com/brightmart/text_classification',\n",
       "  'https://github.com/deep-floyd/if',\n",
       "  'https://github.com/dmlc/dgl',\n",
       "  'https://github.com/eriklindernoren/PyTorch-GAN',\n",
       "  'https://github.com/facebookresearch/esm',\n",
       "  'https://github.com/google-research/bert',\n",
       "  'https://github.com/huggingface/pytorch-image-models',\n",
       "  'https://github.com/microsoft/muzic',\n",
       "  'https://github.com/mlfoundations/open_clip',\n",
       "  'https://github.com/salesforce/lavis',\n",
       "  'https://github.com/tensorflow/tensor2tensor',\n",
       "  'https://github.com/thuml/Time-Series-Library',\n",
       "  'https://github.com/vinits5/learning3d',\n",
       "  'https://github.com/xmu-xiaoma666/External-Attention-pytorch'},\n",
       " 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_repos = set()\n",
    "for subset in ds.values():\n",
    "    unique_repos.update(subset['github'])\n",
    "unique_repos, len(unique_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "GITHUB_API = \"https://api.github.com/repos/{}/readme\"\n",
    "\n",
    "ARXIV_REGEX = re.compile(r'arxiv.org/(abs|pdf)/\\d{4}\\.\\d{5}')\n",
    "\n",
    "def fetch_readme(repo_full_name, token=None):\n",
    "    headers = {\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "    }\n",
    "    if token:\n",
    "        headers['Authorization'] = f'Bearer {token}'\n",
    "\n",
    "    url = GITHUB_API.format(repo_full_name)\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        readme_data = response.json()\n",
    "        readme_content = requests.get(readme_data['download_url']).text\n",
    "        return readme_content\n",
    "    else:\n",
    "        print(f\"Failed to fetch README for {repo_full_name}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def check_for_arxiv_links(readme_content):\n",
    "    m = ARXIV_REGEX.search(readme_content)\n",
    "    if m:\n",
    "        url = m.group(0)\n",
    "        return url\n",
    "\n",
    "def d(repo_list, token=None):\n",
    "    xs = []\n",
    "    for repo in repo_list:\n",
    "        readme_content = fetch_readme(repo, token)\n",
    "        if readme_content:\n",
    "            x = check_for_arxiv_links(readme_content)\n",
    "            if x:\n",
    "                print(x)\n",
    "                xs.append(x)\n",
    "            else:\n",
    "                print(None)\n",
    "    return xs\n",
    "\n",
    "github_token = os.environ.get(\"GH_PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv.org/pdf/2205.11487\n",
      "arxiv.org/pdf/2003.00982\n",
      "arxiv.org/abs/1610.09585\n",
      "None\n",
      "arxiv.org/pdf/2311.17049\n",
      "arxiv.org/abs/2303.05499\n",
      "arxiv.org/abs/1808.06601\n",
      "arxiv.org/abs/1606.06650\n",
      "arxiv.org/abs/2209.09019\n",
      "arxiv.org/abs/2204.06125\n",
      "arxiv.org/abs/2105.02358\n",
      "arxiv.org/abs/2106.05630\n",
      "arxiv.org/pdf/2010.09185\n",
      "arxiv.org/abs/1607.01759\n",
      "arxiv.org/abs/2407.13278\n",
      "arxiv.org/abs/1908.08962\n",
      "arxiv.org/abs/1812.02825\n",
      "arxiv.org/abs/2212.07143\n"
     ]
    }
   ],
   "source": [
    "# \"/\".join(list(unique_repos)[0].split(\"/\")[3:])\n",
    "\n",
    "mlbench_repos = [\"/\".join(repo.split(\"/\")[3:]) for repo in list(unique_repos)]\n",
    "# mlbench_repos\n",
    "arxiv_links = d(mlbench_repos, github_token)\n",
    "# paperlist = d([\"/\".join(repo.split(\"/\")[3:]) for repo in list(unique_repos)], github_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2205.11487',\n",
       " '2003.00982',\n",
       " '1610.09585',\n",
       " '2311.17049',\n",
       " '2303.05499',\n",
       " '1808.06601',\n",
       " '1606.06650',\n",
       " '2209.09019',\n",
       " '2204.06125',\n",
       " '2105.02358',\n",
       " '2106.05630',\n",
       " '2010.09185',\n",
       " '1607.01759',\n",
       " '2407.13278',\n",
       " '1908.08962',\n",
       " '1812.02825',\n",
       " '2212.07143']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arxiv_links[0].split(\"/\")[-1]\n",
    "arxiv_ids = [link.split(\"/\")[-1] for link in arxiv_links]\n",
    "arxiv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1610.09585\n",
      "Downloaded 2311.17049\n",
      "Downloaded 2303.05499\n",
      "Downloaded 1808.06601\n",
      "Downloaded 1606.06650\n",
      "Downloaded 2209.09019\n",
      "Downloaded 2204.06125\n",
      "Downloaded 2105.02358\n",
      "Downloaded 2106.05630\n",
      "Downloaded 2010.09185\n",
      "Downloaded 1607.01759\n",
      "Downloaded 2407.13278\n",
      "Downloaded 1908.08962\n",
      "Downloaded 1812.02825\n",
      "Downloaded 2212.07143\n"
     ]
    }
   ],
   "source": [
    "from utils.arxiv import arxiv_search\n",
    "\n",
    "# arxiv_search.ArxivScraper().download_papers(ids = arxiv_ids[:1], dirpath=\"./MLBench_papers/\")\n",
    "# arxiv_search.ArxivScraper().download_papers(ids = arxiv_ids[1:], dirpath=\"./MLBench_papers/\")\n",
    "for pid in arxiv_ids[2:]:\n",
    "    arxiv_search.ArxivScraper().download_papers(ids = [pid], dirpath=\"./MLBench_papers/\")\n",
    "    print(f\"Downloaded {pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??re.search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a2a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
