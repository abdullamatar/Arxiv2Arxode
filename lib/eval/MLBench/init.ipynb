{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# relative import error with python modules and what not, the path needs to change according to cwd :)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook extracts GitHub URLS from the [MLBench](https://huggingface.co/datasets/super-dainiu/ml-bench) dataset, searches for any Arxiv links, and then downloads all the papers it has found (exactly 17 of the 18 repositories in the dataset contained links to Arxiv). It then creates one large embeddings database with all the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://pgvector_user:pgvector_password@localhost:5432/pgvector_database\n"
     ]
    }
   ],
   "source": [
    "#hf\n",
    "from datasets import load_from_disk\n",
    "\n",
    "#a2a\n",
    "from utils.arxiv import arxiv_search\n",
    "import lib.embeddings as emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"./datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['quarter'][13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xscreensaver: 14:38:08: already running on display :0.0 (window 0x60003f)\n",
      " from process 4552 (turbouser44@adcompute00).\n",
      "Python 3.11.4 (main, Jul  5 2023, 13:45:01) [GCC 11.2.0] on linux\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      ">>> \n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 0, in <module>\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "# \"!\"+ds.get(\"full\")[9]['prefix_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'https://github.com/IDEA-Research/Grounded-Segment-Anything',\n",
       "  'https://github.com/NVIDIA/vid2vid',\n",
       "  'https://github.com/Stability-AI/stablediffusion',\n",
       "  'https://github.com/black0017/MedicalZooPytorch',\n",
       "  'https://github.com/brightmart/text_classification',\n",
       "  'https://github.com/deep-floyd/if',\n",
       "  'https://github.com/dmlc/dgl',\n",
       "  'https://github.com/eriklindernoren/PyTorch-GAN',\n",
       "  'https://github.com/facebookresearch/esm',\n",
       "  'https://github.com/google-research/bert',\n",
       "  'https://github.com/huggingface/pytorch-image-models',\n",
       "  'https://github.com/microsoft/muzic',\n",
       "  'https://github.com/mlfoundations/open_clip',\n",
       "  'https://github.com/salesforce/lavis',\n",
       "  'https://github.com/tensorflow/tensor2tensor',\n",
       "  'https://github.com/thuml/Time-Series-Library',\n",
       "  'https://github.com/vinits5/learning3d',\n",
       "  'https://github.com/xmu-xiaoma666/External-Attention-pytorch'},\n",
       " 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_repos = set()\n",
    "for subset in ds.values():\n",
    "    unique_repos.update(subset['github'])\n",
    "unique_repos, len(unique_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GITHUB_API = \"https://api.github.com/repos/{}/readme\"\n",
    "\n",
    "ARXIV_REGEX = re.compile(r'arxiv.org/(abs|pdf)/\\d{4}\\.\\d{5}')\n",
    "\n",
    "def fetch_readme(repo_full_name, token=None):\n",
    "    headers = {\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\"\n",
    "    }\n",
    "    if token:\n",
    "        headers['Authorization'] = f'Bearer {token}'\n",
    "\n",
    "    url = GITHUB_API.format(repo_full_name)\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        readme_data = response.json()\n",
    "        readme_content = requests.get(readme_data['download_url']).text\n",
    "        return readme_content\n",
    "    else:\n",
    "        print(f\"Failed to fetch README for {repo_full_name}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def check_for_arxiv_links(readme_content):\n",
    "    m = ARXIV_REGEX.search(readme_content)\n",
    "    if m:\n",
    "        url = m.group(0)\n",
    "        return url\n",
    "\n",
    "def d(repo_list, token=None):\n",
    "    xs = []\n",
    "    for repo in repo_list:\n",
    "        readme_content = fetch_readme(repo, token)\n",
    "        if readme_content:\n",
    "            x = check_for_arxiv_links(readme_content)\n",
    "            if x:\n",
    "                print(x)\n",
    "                xs.append(x)\n",
    "            else:\n",
    "                print(None)\n",
    "    return xs\n",
    "\n",
    "github_token = os.environ.get(\"GH_PAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"/\".join(list(unique_repos)[0].split(\"/\")[3:])\n",
    "\n",
    "mlbench_repos = [\"/\".join(repo.split(\"/\")[3:]) for repo in list(unique_repos)]\n",
    "# mlbench_repos\n",
    "arxiv_links = d(mlbench_repos, github_token)\n",
    "# paperlist = d([\"/\".join(repo.split(\"/\")[3:]) for repo in list(unique_repos)], github_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_links[0].split(\"/\")[-1]\n",
    "arxiv_ids = [link.split(\"/\")[-1] for link in arxiv_links]\n",
    "arxiv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# arxiv_search.ArxivScraper().download_papers(ids = arxiv_ids[:1], dirpath=\"./MLBench_papers/\")\n",
    "# arxiv_search.ArxivScraper().download_papers(ids = arxiv_ids[1:], dirpath=\"./MLBench_papers/\")\n",
    "for pid in arxiv_ids[2:]:\n",
    "    arxiv_search.ArxivScraper().download_papers(ids = [pid], dirpath=\"./MLBench_papers/\")\n",
    "    print(f\"Downloaded {pid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoishe/miniconda3/envs/Research/lib/python3.12/site-packages/pypdf/_crypt_providers/_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "chunked_documents = emb.load_and_chunk_papers(\n",
    "    pdf_path=\"./MLBench_papers/\",\n",
    ")\n",
    "# print(len(chunked_documents))\n",
    "# chunked_documents[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null char with unicode replacement char\n",
    "for i in range(len(chunked_documents)):\n",
    "    chunked_documents[i].page_content = chunked_documents[i].page_content.replace(\n",
    "        \"\\x00\", \"\\uFFFD\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whoishe/miniconda3/envs/Research/lib/python3.12/site-packages/langchain_community/vectorstores/pgvector.py:328: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"MLBench_papers\"\n",
    "pgvec_connection = emb.create_embedding_collection(\n",
    "    chunked_docs=chunked_documents,\n",
    "    embeddings=emb.get_embedding_func(model=\"text-embedding-3-large\"),\n",
    "    collection_name=collection_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'MLBench_papers/3D_U-Net:_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation.pdf'}, page_content='We show the successful application of the proposed method on diﬃcult con- focal microscopic data set of the Xenopus kidney. During its development, the Xenopus kidney forms a complex structure [7] which limits the applicability of pre-deﬁned parametric models. First we provide qualitative results to demon- strate the quality of the densiﬁcation from few annotated slices. These results are supported by quantitative evaluations. We also provide experiments which shows the eﬀect of the number of annotated slices on the performance of our net- work. The Caﬀe[5] based network implementation is provided as OpenSource1.\\n\\n1.1 Related Work'),\n",
       " Document(metadata={'source': 'MLBench_papers/3D_U-Net:_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation.pdf'}, page_content='We also introduce batch normalization (“BN”) before each ReLU. In [4], each batch is normalized during training with its mean and standard deviation and global statistics are updated using these values. This is followed by a layer to learn scale and bias explicitly. At test time, normalization is done via these computed global statistics and the learned scale and bias. However, we have a batch size of one and few samples. In such applications, using the current statistics also at test time works the best.\\n\\nThe important part of the architecture, which allows us to train on sparse annotations, is the weighted softmax loss function. Setting the weights of unla- beled pixels to zero makes it possible to learn from only the labelled ones and, hence, to generalize to the whole volume.\\n\\n3\\n\\nImplementation Details\\n\\n3.1 Data\\n\\nWe have three samples of Xenopus kidney embryos at Nieuwkoop-Faber stage 36-37 [10]. One of them is shown in Fig. 1 (left). 3D Data have been recorded in'),\n",
       " Document(metadata={'source': 'MLBench_papers/3D_U-Net:_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation.pdf'}, page_content='We have introduced an end-to-end learning method that semi-automatically and fully-automatically segments a 3D volume from a sparse annotation. It oﬀers an accurate segmentation for the highly variable structures of the Xenopus kidney. We achieve an average IoU of 0.863 in 3-fold cross validation experiments for the semi-automated setup. In a fully-automated setup we demonstrate the per- formance gain of the 3D architecture to an equivalent 2D implementation. The network is trained from scratch, and it is not optimized in any way for this appli- cation. We expect that it will be applicable to many other biomedical volumetric segmentation tasks. Its implementation is provided as OpenSource.\\n\\n7\\n\\n8\\n\\nVolumetric Segmentation with the 3D U-Net'),\n",
       " Document(metadata={'source': 'MLBench_papers/3D_U-Net:_Learning_Dense_Volumetric_Segmentation_from_Sparse_Annotation.pdf'}, page_content='7. Lienkamp, S., Ganner, A., Boehlke, C., Schmidt, T., Arnold, S.J., Sch¨afer, T., Romaker, D., Schuler, J., Hoﬀ, S., Powelske, C., Eiﬂer, A., Kr¨onig, C., Bullerkotte, A., Nitschke, R., Kuehn, E.W., Kim, E., Burkhardt, H., Brox, T., Ronneberger, O., Gloy, J., Walz, G.: Inversin relays frizzled-8 signals to promote proximal pronephros development. PNAS 107(47), 20388–20393 (2010)\\n\\n8. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: Proc. CVPR. pp. 3431–3440 (2015)\\n\\n9. Milletari, F., Ahmadi, S., Kroll, C., Plate, A., Rozanski, V.E., Maiostre, J., Levin, J., Dietrich, O., Ertl-Wagner, B., B¨otzel, K., Navab, N.: Hough-cnn: Deep learning for segmentation of deep brain regions in MRI and ultrasound. CoRR abs/1601.07014 (2016)\\n\\n10. Nieuwkoop, P., Faber, J.: Normal Table of Xenopus laevis (Daudin)(Garland, New York) (1994)')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgvec_connection.similarity_search(\"kidney embryos\", k=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a2a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
