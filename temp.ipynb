{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ◉_◉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc, score in query_response:\n",
    "#     print(\"*\" * 40)\n",
    "#     print(doc.dict().keys())\n",
    "#     # print(doc.from_orm(doc).dict())\n",
    "#     print(\"score: %s\" % score)\n",
    "#     print(doc.page_content)\n",
    "#     print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "# Set logging for the queries\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Clean PDFS, is everything relevant?\n",
    "query = \"\"\"What are some key take aways from the agent tuning to get me started? Lets go through it step by step, and help me devise a plan for implementing some of the ideas in python code.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.44,openai_api_key=oai_sk)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db_conn.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide me with the main insights from the agent tuning process to help me kickstart my implementation? I would appreciate a step-by-step walkthrough and guidance on how to translate these ideas into Python code.', '', '2. In order to begin implementing the agent tuning ideas, could you please highlight the key lessons learned from this process? It would be great if you could break it down into steps and assist me in devising a Python code plan.', '', '3. To get started with implementing the agent tuning concepts, can you share some important takeaways? I would like to understand the process step by step and receive guidance on how to convert these concepts into Python code.']\n"
     ]
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'temp/2310.12823.pdf'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs[0].dict().keys()\n",
    "unique_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "proompt = \"\"\"Use the following bits of information and internalize them. Because, you will then be applying the knowledge in a step by step manner to help a research agent in formulating a plan to implement the ideas in python code. Remember to be concise and pragmatic in your answer, and also focus on changing the most specific thing for the most specific reason. Remember, this means a lot to us, experimentation and research are important and you are good at both.\n",
    "\n",
    "Here is the relevant information:\n",
    "{env_context}\n",
    "\n",
    "And this is the current task at hand:\n",
    "{task_description}\n",
    "\n",
    "Your answer:\"\"\"\n",
    "\n",
    "big_proompt = PromptTemplate(\n",
    "    template=proompt, input_variables=[\"env_context\", \"task_description\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.predict(\n",
    "    text=big_proompt.format_prompt(env_context=unique_docs, task_description=query).text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of .py files: 230\n",
      "Total number of functions extracted: 487\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import extract_functions_from_repo\n",
    "from pathlib import Path\n",
    "codedir = Path.cwd() / \"temprepo\"\n",
    "all_functions = extract_functions_from_repo(codedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'code': 'def doc_to_text(doc):\\n    conv = get_conversation_template(\"llama-2\")\\n    conv.set_system_message(\\n        \"You are a helpful, respectful and honest assistant.\")\\n    conv.append_message(\\n        conv.roles[0], \"Please provide a detailed step-by-step solution for the following grade school math question. \")\\n    conv.append_message(conv.roles[1], \"Ok.\")\\n    for q, a in shots:\\n        conv.append_message(conv.roles[0], q)\\n        conv.append_message(conv.roles[1], a)\\n    conv.append_message(conv.roles[0], f\"\\\\nQuestion: {doc[\\'question\\']}\")\\n    conv.append_message(conv.roles[1], None)\\n    return conv.get_prompt()\\n\\n',\n",
       "  'function_name': 'doc_to_text',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': 'def clean_answer(text):\\n    text = text.split(\"Question:\")[0]\\n    return text\\n\\n',\n",
       "  'function_name': 'clean_answer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': 'def generate_sample(prompt, ip, post_from, post_to):\\n    ip_address = f\"http://{ip}:\"\\n    controller_addr_pool = [ip_address + str(i) for i in range(post_from, post_to + 1)]\\n\\n    def request_answer(max_new_tokens):\\n        data = {\\n            \"inputs\": prompt,\\n            \"parameters\": {\\n                \"max_new_tokens\": max_new_tokens,\\n                \"do_sample\": False\\n            }\\n        }\\n        headers = {\"Content-Type\": \"application/json\"}\\n        return requests.post(\\n            random.sample(controller_addr_pool, 1)[0] + \"/generate\",\\n            headers=headers,\\n            data=json.dumps(data),\\n            timeout=120,\\n        )\\n    response = request_answer(512)\\n    answer = clean_answer(response.json()[\"generated_text\"])\\n    return answer\\n\\n',\n",
       "  'function_name': 'generate_sample',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': 'def extract_answer_hf(completion):\\n    match = ANS_RE.search(completion)\\n    if match:\\n        match_str = match.group(1).strip()\\n        match_str = match_str.replace(\",\", \"\")\\n        return eval(match_str)\\n    else:\\n        return INVALID_ANS\\n\\n',\n",
       "  'function_name': 'extract_answer_hf',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': \"def extract_answer(completion):\\n    try:\\n        last_number = re.findall(r'\\\\d+', completion)[-1]\\n        return eval(last_number)\\n    except:\\n        return INVALID_ANS\\n\\n\",\n",
       "  'function_name': 'extract_answer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': 'def is_correct(completion, answer):\\n    gold = extract_answer_hf(answer)\\n    assert gold != INVALID_ANS, \"No ground truth answer found in the document.\"\\n    return extract_answer(completion) == gold\\n\\n',\n",
       "  'function_name': 'is_correct',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_gsm8k_tgi.py'},\n",
       " {'code': 'def load_models_tokenizer(args):\\n    tokenizer = AutoTokenizer.from_pretrained(args.checkpoint_path)\\n    model = transformers.AutoModelForCausalLM.from_pretrained(\\n        args.checkpoint_path, use_safetensors=True, device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.bfloat16).eval()\\n    model.generation_config = GenerationConfig.from_pretrained(\\n        args.checkpoint_path)\\n    return model, tokenizer\\n',\n",
       "  'function_name': 'load_models_tokenizer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def format_example(line, include_answer=True):\\n    example = \\'Question: \\' + line[\\'question\\']\\n    for choice in choices:\\n        example += f\\'\\\\n{choice}. {line[f\"{choice}\"]}\\'\\n\\n    if include_answer:\\n        example += \\'\\\\nAnswer: \\' + line[\"answer\"] + \\'\\\\n\\\\n\\'\\n    else:\\n        example += \\'\\\\nAnswer:\\'\\n    return example\\n\\n',\n",
       "  'function_name': 'format_example',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def generate_few_shot_prompt(k, subject, dev_df):\\n\\n    def format_subject(subject):\\n        l = subject.split(\"_\")\\n        s = \"\"\\n        for entry in l:\\n            s += \" \" + entry\\n        return s.strip()\\n\\n    # Use llama2 template to generate answer\\n    prompt = f\"The following is a multiple-choice question about {format_subject(subject)}. Please choose the most suitable one among A, B, C and D as the answer to this question.\"\\n    conv = get_conversation_template(\"llama-2\")\\n    conv.set_system_message(f\"{prompt}\")\\n    for i in range(k):\\n        line = dev_df.iloc[i, :]\\n        conv.append_message(conv.roles[0], f\\'Question: {line[\"question\"]}\\\\n\\' + \\'\\\\n\\'.join(\\n            [f\"{choice}. {line[f\\'{choice}\\']}\" for choice in [\"A\", \"B\", \"C\", \"D\"]]))\\n        conv.append_message(conv.roles[1], \\'Answer: \\' + line[\"answer\"])\\n\\n    return conv\\n\\n',\n",
       "  'function_name': 'generate_few_shot_prompt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': \"def get_logits(tokenizer, model, inputs: List[str]):\\n    input_ids = tokenizer(inputs, padding=False)['input_ids']\\n    input_ids = torch.tensor(input_ids, device=model.device)\\n\\n    if input_ids.shape[1] > args.max_seq_len:\\n        input_ids = input_ids[:, input_ids.shape[1]-args.max_seq_len+1:]\\n    tokens = {'input_ids': input_ids}\\n\\n    outputs = model(input_ids)['logits']\\n    logits = outputs[:, -1, :]\\n    log_probs = torch.nn.functional.softmax(logits, dim=-1)\\n    return log_probs, {'tokens': tokens}\\n\\n\",\n",
       "  'function_name': 'get_logits',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def eval_subject(\\n        model,\\n        tokenizer,\\n        subject_name,\\n        test_df,\\n        k=5,\\n        dev_df=None,\\n        few_shot=False,\\n        save_result_dir=None,\\n        **kwargs\\n):\\n    result = []\\n    score = []\\n\\n    cov = generate_few_shot_prompt(\\n        k, subject_name, dev_df) if few_shot else []\\n    all_probs = {\\'prob_A\\': [], \\'prob_B\\': [], \\'prob_C\\': [], \\'prob_D\\': []}\\n\\n    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\\n        question = format_example(row, include_answer=False)\\n        cov.append_message(cov.roles[0], question.split(\"Answer:\")[0].rstrip())\\n        cov.append_message(cov.roles[1], None)\\n        full_prompt = cov.get_prompt() + \" Answer: \"\\n        cov = generate_few_shot_prompt(\\n            k, subject_name, dev_df) if few_shot else []\\n\\n        output, input_info = get_logits(tokenizer, model, [full_prompt])\\n        assert output.shape[0] == 1\\n        logits = output.flatten()\\n\\n        softval = torch.nn.functional.softmax(\\n            torch.tensor(\\n                [\\n                    logits[tokenizer(\" A\")[\\'input_ids\\'][-1]],\\n                    logits[tokenizer(\" B\")[\\'input_ids\\'][-1]],\\n                    logits[tokenizer(\" C\")[\\'input_ids\\'][-1]],\\n                    logits[tokenizer(\" D\")[\\'input_ids\\'][-1]],\\n                ]\\n            ),\\n            dim=0,\\n        )\\n        if softval.dtype in {torch.bfloat16, torch.float16}:\\n            softval = softval.to(dtype=torch.float32)\\n        probs = softval.detach().cpu().numpy()\\n\\n        for i, choice in enumerate(choices):\\n            all_probs[f\\'prob_{choice}\\'].append(probs[i])\\n        pred = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}[np.argmax(probs)]\\n\\n        if \\'answer\\' in row:\\n            correct = 1 if pred == row[\\'answer\\'] else 0\\n            score.append(correct)\\n            if args.debug:\\n                print(f\\'{question} pred: {pred} ref: {row[\"answer\"]}\\')\\n        result.append(pred)\\n\\n    if save_result_dir:\\n        test_df[\\'model_output\\'] = result\\n        for i, choice in enumerate(choices):\\n            test_df[f\\'prob_{choice}\\'] = (all_probs[f\\'prob_{choice}\\'])\\n        if score:\\n            test_df[\"correctness\"] = score\\n        os.makedirs(save_result_dir, exist_ok=True)\\n        test_df.to_csv(os.path.join(\\n            save_result_dir, f\\'{subject_name}_result.csv\\'), encoding=\"utf-8\", index=False)\\n    return score\\n\\n',\n",
       "  'function_name': 'eval_subject',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def cal_mmlu(res):\\n    acc_sum_dict = dict()\\n    acc_norm_sum_dict = dict()\\n    cnt_dict = dict()\\n    acc_sum = 0.\\n    cnt = 0\\n    hard_cnt = 0\\n    hard_acc_sum = 0.\\n\\n    for class_ in TASK_NAME_MAPPING.keys():\\n        acc_sum_dict[class_] = 0.\\n        acc_norm_sum_dict[class_] = 0.\\n        cnt_dict[class_] = 0.\\n\\n        for tt in TASK_NAME_MAPPING[class_]:\\n            acc_sum += sum(res[tt])\\n            cnt += len(res[tt])\\n\\n            acc_sum_dict[class_] += sum(res[tt])\\n            cnt_dict[class_] += len(res[tt])\\n\\n    for k in TASK_NAME_MAPPING.keys():\\n        if k in cnt_dict:\\n            print(\\'%s ACC: %.2f \\' % (\\n                k, acc_sum_dict[k] / cnt_dict[k] * 100))\\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\n    with open(f\"mmlu_eval_result_{timestamp}.json\", \"w\") as f:\\n        result = {}\\n        result[\"acc\"] = acc_sum / cnt * 100\\n        result[\"cnt\"] = cnt\\n        result[\"acc_sum_dict\"] = acc_sum_dict\\n        result[\"cnt_dict\"] = cnt_dict\\n        f.write(json.dumps(result))\\n\\n',\n",
       "  'function_name': 'cal_mmlu',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def main(args):\\n    model, tokenizer = load_models_tokenizer(args)\\n\\n    dev_result = {}\\n    for subject_name in tqdm(SUBJECTS):\\n        dev_file_path = os.path.join(\\n            args.eval_data_path, \\'dev\\', f\\'{subject_name}_dev.csv\\')\\n        test_file_path = os.path.join(\\n            args.eval_data_path, \\'test\\', f\\'{subject_name}_test.csv\\')\\n\\n        dev_df = pd.read_csv(dev_file_path, names=[\\n                             \\'question\\', \\'A\\', \\'B\\', \\'C\\', \\'D\\', \\'answer\\'])\\n        test_df = pd.read_csv(test_file_path, names=[\\n                              \\'question\\', \\'A\\', \\'B\\', \\'C\\', \\'D\\', \\'answer\\'])\\n\\n        score = eval_subject(model, tokenizer, subject_name, test_df, dev_df=dev_df, k=5, few_shot=True,\\n                             save_result_dir=f\"outs/mmlu_eval_result\")\\n        dev_result[subject_name] = score\\n    cal_mmlu(dev_result)\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mmlu_hf.py'},\n",
       " {'code': 'def run_eval(\\n    model_id,\\n    question_file,\\n    answer_file,\\n    host, \\n    port\\n):\\n    questions = load_questions(question_file, None, None)\\n    random.shuffle(questions)\\n\\n    chunk_size = len(questions)\\n    for i in range(0, len(questions), chunk_size):\\n        get_model_answers(\\n            model_id,\\n            questions[i : i + chunk_size],\\n            answer_file,\\n            host, \\n            port,\\n        )\\n',\n",
       "  'function_name': 'run_eval',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mt_bench_tgi.py'},\n",
       " {'code': 'def query_model(x):\\n    question, host, port = x\\n    choices = []\\n    for i in range(1):\\n        conv = get_conversation_template(\"llama-2\")\\n        conv.set_system_message(\\'You are a helpful, respectful and honest assistant.\\')\\n        turns = []\\n        for j in range(len(question[\"turns\"])):\\n            qs = question[\"turns\"][j]\\n            conv.append_message(conv.roles[0], qs)\\n            conv.append_message(conv.roles[1], None)\\n            prompt = conv.get_prompt()\\n            # print(\"Prompt\", prompt)\\n            temp = temperature_config[question[\"category\"]]\\n            try:\\n                resp = requests.post(\\n                    url=f\"http://{host}:{port}/generate\",\\n                    json={\\n                            \"inputs\": prompt,\\n                            \"parameters\": {\\n                                \"decoder_input_details\": True,\\n                                \"do_sample\": temp > 1e-4,\\n                                \"max_new_tokens\": 4096,\\n                                **({\"temperature\": temp} if temp > 1e-4 else {})\\n                            }\\n                        },\\n                )\\n                try:\\n                    output = resp.json()[\\'generated_text\\']\\n                except:\\n                    import traceback\\n                    print(\">>> ERROR getting \\'generated_text\\' question ID: \", question[\"question_id\"])\\n                    print(resp.json())\\n                    traceback.print_exc()\\n                    output = \"\"\\n                output = output.strip()\\n            except:\\n                print(\">>> ERROR question ID: \", question[\"question_id\"])\\n                print(output)\\n                output = \"ERROR\"\\n                import traceback\\n                traceback.print_exc()\\n\\n            turns.append(output)\\n            conv.messages[-1][-1] = output\\n        choices.append({\"index\": i, \"turns\": turns})\\n\\n    return choices, question\\n',\n",
       "  'function_name': 'query_model',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mt_bench_tgi.py'},\n",
       " {'code': 'def get_model_answers(\\n    model_id,\\n    questions,\\n    answer_file,\\n    host, \\n    port,\\n):  \\n    print(\"Evauating\", len(questions), \"questions\")\\n\\n    with mp.Pool(80) as p:\\n        to_be_testes = [(x, host, port) for x in questions]\\n        question_choices = p.imap_unordered(query_model, to_be_testes)\\n\\n        for choices, question in tqdm(question_choices):\\n            # Dump answers\\n            os.makedirs(os.path.dirname(answer_file), exist_ok=True)\\n            with open(os.path.expanduser(answer_file), \"a\") as fout:\\n                ans_json = {\\n                    \"question_id\": question[\"question_id\"],\\n                    \"answer_id\": shortuuid.uuid(),\\n                    \"model_id\": model_id,\\n                    \"choices\": choices,\\n                    \"tstamp\": time.time(),\\n                }\\n                fout.write(json.dumps(ans_json) + \"\\\\n\")\\n',\n",
       "  'function_name': 'get_model_answers',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mt_bench_tgi.py'},\n",
       " {'code': 'def reorg_answer_file(answer_file):\\n    \"\"\"Sort by question id and de-duplication\"\"\"\\n    answers = {}\\n    with open(answer_file, \"r\") as fin:\\n        for l in fin:\\n            qid = json.loads(l)[\"question_id\"]\\n            answers[qid] = l\\n\\n    qids = sorted(list(answers.keys()))\\n    with open(answer_file, \"w\") as fout:\\n        for qid in qids:\\n            fout.write(answers[qid])\\n\\n',\n",
       "  'function_name': 'reorg_answer_file',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_general/eval_mt_bench_tgi.py'},\n",
       " {'code': 'def parse_args():\\n    parser = argparse.ArgumentParser(add_help=False)\\n    group = parser.add_argument_group(\"evaluation\", \"Evaluation configurations\")\\n    group.add_argument(\"--task\", nargs=\"+\", required=True, help=\"All task config(s) to load\")\\n    group.add_argument(\"--agent\", type=str, required=True, help=\"Agent config to load\")\\n    group.add_argument(\"--output_dir\", type=str, default=\"outputs\", help=\"Output root directory\")\\n    group.add_argument(\"--workers\", type=int, default=1, help=\"Number of workers for evaluation\")\\n    group.add_argument(\"--max_new_tokens\", type=int, default=None, help=\"Maximum number of new tokens to generate\")\\n    group.add_argument(\"--no_timestamp\", action=\"store_true\", help=\"Do not use timestamp in output directory\")\\n    args = parser.parse_args()\\n    return args\\n\\n',\n",
       "  'function_name': 'parse_args',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/evaluate.py'},\n",
       " {'code': 'def find_all_task_files(all_task_config_path) -> List[str]:\\n    # print(type(all_task_config_path), all_task_config_path)\\n    tasks = []\\n    for task in all_task_config_path:\\n        if isdir(task):\\n            tasks += [relpath(path, \".\") for path in glob(join(task, \"**/*.yaml\"), recursive=True)]\\n        elif isfile(task):\\n            tasks.append(task)\\n        else:\\n            print(f\"\\'{task}\\' is not a valid file or directory, ignored.\")\\n    return tasks\\n\\n',\n",
       "  'function_name': 'find_all_task_files',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/evaluate.py'},\n",
       " {'code': 'def evaluate_all_tasks(tasks: List[Task], agent: Agent):\\n    for task in tasks:\\n        task.evaluate(agent)\\n        task.release()\\n        del task\\n\\n',\n",
       "  'function_name': 'evaluate_all_tasks',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/evaluate.py'},\n",
       " {'code': 'def main():\\n    args = parse_args()\\n    create_time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\\n    if args.no_timestamp:\\n        output_root_dir = args.output_dir\\n    else:\\n        output_root_dir = os.path.join(args.output_dir, create_time)\\n        \\n    if not os.path.exists(output_root_dir):\\n        os.makedirs(output_root_dir)\\n\\n    task_files = find_all_task_files(args.task)\\n    tasks = []\\n    task_configs = []\\n\\n    updt = {}\\n    if args.max_new_tokens is not None:\\n        updt[\"max_new_tokens\"] = args.max_new_tokens\\n    agent_config = YAMLConfig.init_from_yaml(args.agent, updt)\\n    agent = agent_config.create()\\n    \\n    print(\"> Loading task configs\")\\n    for task_config_path in task_files:\\n        updt = {\"output_root_dir\": output_root_dir, \"workers\": args.workers}\\n        print(updt)\\n        task_config = YAMLConfig.init_from_yaml(task_config_path, updt)\\n        task = task_config.create()\\n        if not task.output_root_dir:\\n            task.output_root_dir = output_root_dir\\n        os.makedirs(task.get_output_dir()) # TODO: exist_ok=True for resume\\n        config_path = os.path.join(task.get_output_dir(), \"config.json\")\\n        with open(config_path, \"w\", encoding=\\'utf-8\\') as f:\\n            f.write(json.dumps({\\n                \"agent\": args.agent,\\n                \"task\": task_config_path,\\n            }, indent=4, ensure_ascii=False))\\n        # task.workers = args.workers or task.workers\\n        print(f\"    Task \\'{task.name}\\' loaded from config {task_config_path}, output to {task.output_root_dir}\")\\n        tasks.append(task)\\n        task_configs.append(task_config)\\n    print(f\"> Successfully load {len(tasks)} task{\\'s\\' if len(tasks) > 1 else \\'\\'}\")\\n\\n    # model, tokenizer = initialize_model_and_tokenizer(args)\\n    # model = ModelForEvaluation(model, args.position_encoding_2d)\\n    \\n\\n    with open(os.path.join(output_root_dir, \"configs.json\"), \"w\") as f:\\n        json.dump({\\n            \"args\": args.__dict__,\\n            \"command_line\": sys.argv,\\n            \"create_time\": create_time,\\n            \"output_root_dir\": output_root_dir,\\n            \"tasks\": [{\\n                \"class\": str(type(task)),\\n                \"config\": serialize(task_config),\\n            } for task, task_config in zip(tasks, task_configs)],\\n            \"agent\": {\\n                \"class\": str(type(agent)),\\n                \"config\": serialize(agent_config),\\n            },\\n        }, f, indent=4)\\n\\n    start = time.time()\\n    evaluate_all_tasks(tasks, agent)\\n    print_rank_0(f\"> Finish {len(tasks)} task{\\'s\\' if len(tasks) > 1 else \\'\\'} in {time.time() - start:.1f}s\")\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/evaluate.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/4/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/4/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/4/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/4/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/7/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/7/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/7/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/7/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/5/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/5/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/5/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/5/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/dev/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/dev/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/dev/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/dev/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/2/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/2/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/2/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/2/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/1/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/1/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/1/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/1/check/size-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/3/check/containing.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/3/check/string-match.py'},\n",
       " {'code': 'def norm_newline(s):\\n  return s.replace(\"\\\\r\\\\n\", \"\\\\n\").replace(\"\\\\r\", \"\\\\n\")\\n',\n",
       "  'function_name': 'norm_newline',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/3/check/in.py'},\n",
       " {'code': 'def analysis_size(size_str):\\n    size_str = size_str.strip()\\n    availables = {\\n        \"B\": 1,\\n        \"Byte\": 1,\\n        \"K\": 1024,\\n        \"KB\": 1024,\\n        \"M\": 1024*1024,\\n        \"MB\": 1024*1024,\\n        \"G\": 1024*1024*1024,\\n        \"GB\": 1024*1024*1024,\\n        \"T\": 1024*1024*1024*1024,\\n        \"TB\": 1024*1024*1024*1024,\\n        \"P\": 1024*1024*1024*1024*1024,\\n        \"PB\": 1024*1024*1024*1024*1024,        \\n    }\\n    for size_unit in availables:\\n        if size_str.endswith(size_unit):\\n            return int(size_str[:-len(size_unit)]) * availables[size_unit]\\n    return int(size_str)\\n',\n",
       "  'function_name': 'analysis_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/data/os_interaction/scripts/3/check/size-match.py'},\n",
       " {'code': 'def serialize(obj, max_depth=5, compress=False):\\n    \"\"\"\\n        dump into json, including only basic types, list types and dict types. If other types are included, they will be converted into string.\\n    \"\"\"\\n    if max_depth <= 0:\\n        return \"...\"\\n    if isinstance(obj, (int, float, str, bool, type(None))):\\n        return obj\\n    elif isinstance(obj, list) or isinstance(obj, tuple):\\n        if not compress or len(obj) <= 5:\\n            return [serialize(item, max_depth-1, compress) for item in obj]\\n        else:\\n            return [serialize(item, max_depth-1, True) for item in obj[:5]] + [\"...(total: %d)\" % len(obj)]\\n    elif isinstance(obj, dict):\\n        if not compress or len(obj) <= 5:\\n            return {str(key): serialize(obj[key], max_depth-1, compress) for key in obj}\\n        else:\\n            ret = {str(key): serialize(obj[key], max_depth-1, True) for key in list(obj.keys())[:5]}\\n            ret[\"...total...\"] = len(obj)\\n            return ret\\n    elif hasattr(obj, \\'__dict__\\'):\\n        return serialize(obj.__dict__, max_depth, True)\\n    else:\\n        ret = str(obj)\\n        if len(ret) > 100:\\n            ret = ret[:45] + \"   ...   \" + ret[-45:]\\n        return ret\\n\\n',\n",
       "  'function_name': 'serialize',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/utils.py'},\n",
       " {'code': 'def print_rank_0(*args, **kwargs):\\n    # if torch.distributed.get_rank() == 0:\\n    print(*args, **kwargs)',\n",
       "  'function_name': 'print_rank_0',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/utils.py'},\n",
       " {'code': 'def predict(receiver):\\n    env = WebAgentTextEnv(observation_mode=\"text\", human_goals=True)\\n    while True:\\n        data_item, session, sender = receiver.recv()\\n        history = []\\n        env.reset(data_item)\\n        session.inject({\"role\": \"user\", \"content\": prompt})\\n        session.inject({\"role\": \"agent\", \"content\": \"Ok.\"})\\n\\n        # one shot\\n\\n        session.inject({\\'role\\': \\'user\\', \\'content\\': \\'Observation:\\\\n\"WebShop [SEP] Instruction: [SEP] i need a long lasting 6.76 fl oz bottle of l\\\\\\'eau d\\\\\\'issey, and price lower than 100.00 dollars [SEP] Search\"\\\\n\\\\nAvailable Actions:\\\\n{\"has_search_bar\": true, \"clickables\": [\"...\"]}\\'})\\n        session.inject({\\'role\\': \\'agent\\', \\'content\\': \\'Thought:\\\\nI think I should use the search bar to look for the product I need.\\\\n\\\\nAction:\\\\nsearch[l\\\\\\'eau d\\\\\\'issey 6.76 fl oz bottle price < 100.00]\\'})\\n        session.inject({\\'role\\': \\'user\\', \\'content\\': \\'Observation:\\\\n\"Instruction: [SEP] i need a long lasting 6.76 fl oz bottle of l\\\\\\'eau d\\\\\\'issey, and price lower than 100.00 dollars [SEP] Back to Search [SEP] Page 1 (Total results: 50) [SEP] Next > [SEP] B000VOHH8I [SEP] L\\\\\\'eau D\\\\\\'issey By Issey Miyake for MenEau De Toilette Spray, 6.7 Fl Oz Bottle [SEP] $64.98 [SEP] B000MJZOPK [SEP] L\\\\\\'eau d\\\\\\'Issey by Issey Miyake for Women 3.3 oz Eau de Toilette Spray [SEP] $49.98 [SEP] B0012S249E [SEP] L\\\\\\'eau D\\\\\\'issey By Issey Miyake For Women. Shower Cream 6.7-Ounces [SEP] $31.36 [SEP] B01H8PGKZS [SEP] L\\\\\\'eau D\\\\\\'Issey FOR MEN by Issey Miyake - 6.7 oz EDT Spray [SEP] $67.97 [SEP] B00G3C8FHE [SEP] L\\\\\\'Eau d\\\\\\'Issey pour Homme - Eau de Toilette 4.2 fl oz [SEP] $51.25 [SEP] B000R94HRG [SEP] Issey Miyake L\\\\\\'Eau D\\\\\\'Issey Pour Homme Eau De Toilette Natural Spray [SEP] $44.99 [SEP] B000C214CO [SEP] Issey Miyake L\\\\\\'eau D\\\\\\'issey Eau de Toilette Spray for Men, 4.2 Fl Oz [SEP] $53.99 [SEP] B0018SBRDC [SEP] Issey Miyake L\\\\\\'eau d\\\\\\'Issey for Women EDT, White, 0.84 Fl Oz [SEP] $27.04 [SEP] B000XEAZ9Y [SEP] L\\\\\\'eau De Issey By Issey Miyake For Men. Eau De Toilette Spray 6.7 Fl Oz [SEP] $67.08 [SEP] B079HZR2RX [SEP] L\\\\\\'eau d\\\\\\'Issey Pure by Issey Miyake for Women 3.0 oz Nectar de Parfum Spray [SEP] $71.49\"\\\\n\\\\nAvailable Actions:\\\\n{\"has_search_bar\": false, \"clickables\": [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]}\\'})\\n        session.inject({\\'role\\': \\'agent\\', \\'content\\': \\'Thought:\\\\nI think I should click on the product I need, which is B000VOHH8I.\\\\n\\\\nAction:\\\\nclick[B000VOHH8I]\\'})\\n        session.inject({\\'role\\': \\'user\\', \\'content\\': \\'Observation:\\\\n\"Instruction: [SEP] i need a long lasting 6.76 fl oz bottle of l\\\\\\'eau d\\\\\\'issey, and price lower than 100.00 dollars [SEP] Back to Search [SEP] < Prev [SEP] size [SEP] 2.5 fl oz [SEP] 6.76 fl oz (pack of 1) [SEP] L\\\\\\'eau D\\\\\\'issey By Issey Miyake for MenEau De Toilette Spray, 6.7 Fl Oz Bottle [SEP] Price: $64.98 [SEP] Rating: N.A. [SEP] Description [SEP] Features [SEP] Reviews [SEP] Buy Now\"\\\\n\\\\nAvailable Actions:\\\\n{\"has_search_bar\": false, \"clickables\": [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]}\\'})\\n        session.inject({\\'role\\': \\'agent\\', \\'content\\': \\'Thought:\\\\nI think I should click on the \\\\\\'6.76 fl oz (pack of 1)\\\\\\' option to select the size I need.\\\\n\\\\nAction:\\\\nclick[6.76 fl oz (pack of 1)]\\'})\\n        session.inject({\\'role\\': \\'user\\', \\'content\\': \\'Observation:\\\\n\"Instruction: [SEP] i need a long lasting 6.76 fl oz bottle of l\\\\\\'eau d\\\\\\'issey, and price lower than 100.00 dollars [SEP] Back to Search [SEP] < Prev [SEP] size [SEP] 2.5 fl oz [SEP] 6.76 fl oz (pack of 1) [SEP] L\\\\\\'eau D\\\\\\'issey By Issey Miyake for MenEau De Toilette Spray, 6.7 Fl Oz Bottle [SEP] Price: $64.98 [SEP] Rating: N.A. [SEP] Description [SEP] Features [SEP] Reviews [SEP] Buy Now\"\\\\n\\\\nAvailable Actions:\\\\n{\"has_search_bar\": false, \"clickables\": [\"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\", \"...\"]}\\'})\\n        session.inject({\\'role\\': \\'agent\\', \\'content\\': \\'Thought:\\\\nI think I should click on the \\\\\\'Buy Now\\\\\\' button to purchase the product.\\\\n\\\\nAction:\\\\nclick[Buy Now]\\'})\\n\\n        observation = env.observation\\n        reward = 0\\n        format_fail = False\\n        for j in range(10):\\n            available_actions = env.get_available_actions()\\n            session.inject({\"role\": \"user\", \"content\": f\"Observation:\\\\n{observation}\\\\n\\\\n\"\\n                                                       f\"Available Actions:\\\\n{available_actions}\"})\\n            response = session.action()\\n            try:\\n                action = re.search(r\"[Aa]ction: *\\\\n *((search|click)\\\\[.+?])\", response).group(1)\\n            except:\\n                format_fail = True\\n                action = None\\n            history.append({\"observation\": observation, \"available_actions\": available_actions,\\n                            \"response\": response, \"action\": action})\\n            if not action:\\n                reward = 0\\n                break\\n            observation, reward, done, info = env.step(action)\\n            history[-1][\"reward\"] = reward\\n            history[-1][\"done\"] = done\\n            if done:\\n                break\\n        sender.send({\\n            \"history\": history,\\n            \"reward\": reward,\\n            \"format_fail\": format_fail\\n        })\\n\\n',\n",
       "  'function_name': 'predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/__init__.py'},\n",
       " {'code': 'def test_parse_item_page_ws(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_item_page_ws\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n\\n    mock_desc_file = open(\"tests/transfer/mocks/mock_parse_item_page_ws_desc\", \"rb\")\\n    mock_desc_body = mock_desc_file.read()\\n    mock_desc_file.close()\\n\\n    mock_feat_file = open(\"tests/transfer/mocks/mock_parse_item_page_ws_feat\", \"rb\")\\n    mock_feat_body = mock_feat_file.read()\\n    mock_feat_file.close()\\n\\n    mock_asin = \"B09P87V3LZ\"\\n    mock_query = \"red basketball shoes\"\\n    mock_options = {}\\n\\n    # Invoke function, check response\\n    query_str = \\'+\\'.join(mock_query.split())\\n    options_str = json.dumps(mock_options)\\n    url = (\\n        f\"{WEBSHOP_URL}/item_page/{WEBSHOP_SESSION}/\"\\n        f\"{mock_asin}/{query_str}/1/{options_str}\"\\n    )\\n    url_desc = (\\n        f\"{WEBSHOP_URL}/item_sub_page/{WEBSHOP_SESSION}/\"\\n        f\"{mock_asin}/{query_str}/1/Description/{options_str}\"\\n    )\\n    url_feat = (\\n        f\"{WEBSHOP_URL}/item_sub_page/{WEBSHOP_SESSION}/\"\\n        f\"{mock_asin}/{query_str}/1/Features/{options_str}\"\\n    )\\n    print(f\"Item Page URL: {url}\")\\n    print(f\"Item Description URL: {url_desc}\")\\n    print(f\"Item Features URL: {url_feat}\")\\n\\n    kwargs[\"mock\"].get(url, content=mock_body)\\n    kwargs[\"mock\"].get(url_desc, content=mock_desc_body)\\n    kwargs[\"mock\"].get(url_feat, content=mock_feat_body)\\n\\n    output = parse_item_page_ws(mock_asin, mock_query, 1, mock_options)\\n    expected = {\\n        \\'MainImage\\': \\'https://m.media-amazon.com/images/I/51ltvkzGhGL.jpg\\',\\n        \\'Price\\': \\'100.0\\',\\n        \\'Rating\\': \\'N.A.\\',\\n        \\'Title\\': \\'PMUYBHF Womens Fashion Flat Shoes Comfortable Running Shoes \\' \\n            \\'Sneakers Tennis Athletic Shoe Casual Walking Shoes\\',\\n        \\'asin\\': mock_asin,\\n        \\'option_to_image\\': {\\n            \\'6.5\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27size%27:%20%276.5%27%7D\\',\\n            \\'7.5\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27size%27:%20%277.5%27%7D\\',\\n            \\'8\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27size%27:%20%278%27%7D\\',\\n            \\'8.5\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27size%27:%20%278.5%27%7D\\',\\n            \\'9\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27size%27:%20%279%27%7D\\',\\n            \\'black\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27color%27:%20%27black%27%7D\\',\\n            \\'purple\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27color%27:%20%27purple%27%7D\\',\\n            \\'red\\': \\'http://3.83.245.205:3000/item_page/abc/B09P87V3LZ/%5B%27red%27%2C%20%27basketball%27%2C%20%27shoes%27%5D/1/%7B%27color%27:%20%27red%27%7D\\'\\n        },\\n        \\'options\\': {\\n            \\'color\\': [\\'black\\', \\'purple\\', \\'red\\'],\\n            \\'size\\': [\\'6.5\\', \\'7.5\\', \\'8\\', \\'8.5\\', \\'9\\']\\n        },\\n        \\'BulletPoints\\': \\'Pure Running Shoe\\\\nComfort Flat Sneakers\\\\n[FEATURES]: Soles with unique non-slip pattern, it has great \\' \\n                \\'abrasion resistant and provide protection when you walking or running. (Pure Running Shoe Mesh Walking Shoes Fashion \\' \\n                \\'Sneakers Slip On Sneakers Wedge Platform Loafers Modern Walking Shoes Sock Sneakers Platform Loafers Shoes Non Slip \\' \\n                \\'Running Shoes Athletic Tennis Shoes Blade Type Sneakers Lace-up Sneaker) sole\\\\n[WIDE ANKLE DESIGN]: Perfect accord with human body \\' \\n                \\'engineering, green, healthy concept design make the walking shoes wear more comfortable, wide width wlking shoes. (Low \\' \\n                \\'Top Walking Shoes Fashion Canvas Sneakers Slip On Shoes Casual Walking Shoes Hidden Wedge Sneaker Low Top Canvas \\' \\n                \\'Sneakers Lace-up Classic Casual Shoes Walking Tennis Shoes Lightweight Casual Sneakers Slip on Sock Sneakers Air \\' \\n                \\'Cushion Platform Loafers Slip-On Mule Sneaker )\\\\n[CUSHION WITH ARCH SUPPORT]: Gives you a comfort for all day \\' \\n                \\'long. Wear these lightweight walking shoes, let every step of moving on a comfortable feeling. (Fashion Casual Shoes \\' \\n                \\'Athletic Workout Shoes Fitness Sneaker Athletic Running Shoes Air Cushion Sneakers Stylish Athletic Shoes Lace Up \\' \\n                \\'Canvas Shoes Slip on Walking Shoe Fashion Sneakers Low Top Classic Sneakers Comfort Fall Shoes Memory Foam Slip On \\' \\n                \\'Sneakers Air Cushion Sneakers Running Walking Shoes)\\\\n[NON-SLIP SOLE]: Made from ultra soft and lightweight RUBBER \\' \\n                \\'material,with the function of shock absorbing and cushioning,offering the best durability and traction. (Wedge \\' \\n                \\'Sneakers Walking Tennis Shoes Slip On Running Shoes Lightweight Fashion Sneakers Fashion Travel Shoes Walking \\' \\n                \\'Running Shoes Non Slip Running Shoes Athletic Tennis Sneakers Sports Walking Shoes Platform Fashion Sneaker \\' \\n                \\'Memory Foam Tennis Sneakers Running Jogging Shoes Sock Sneakers Canvas Fashion Sneakers)\\\\n[OCCASIONS]: Ultra lightweight design provides actual \\' \\n                \\'feelings of being barefooted and like walking on the feather, perfect for walking, hiking, bike riding, working, \\' \\n                \\'shopping, indoor, outdoor, casual, sports, travel, exercise, vacation, and etc. (Flat Fashion Sneakers Lightweight \\' \\n                \\'Walking Sneakers Platform Loafers Sport Running Shoes Casual Flat Loafers Slip-On Sneaker Casual Walking Shoes High Top \\' \\n                \\'Canvas Sneakers Lace up Sneakers Workout Walking Shoes Tennis Fitness Sneaker)\\\\n\\' \\n                \\'[Customers Are Our Priority]: We follow the principle of customer first, so if you encounter any problems after \\' \\n                \\'buying shoes, we will try our best to solve them for you. (Breathable Air Cushion Sneakers Walking Tennis Shoes Air \\' \\n                \\'Athletic Running Shoes Air Cushion Shoes Mesh Sneakers Fashion Tennis Shoes Jogging Walking Sneakers Breathable \\' \\n                \\'Casual Sneakers Fashion Walking Shoes Athletic Running Sneakers Walking Work Shoes Air Running Shoes Slip on \\' \\n                \\'Sneakers Mesh Walking Shoes)\\',\\n        \\'Description\\': \\'Here Are The Things You Want To Knowa─=≡Σ(((つ̀ώ)つSTORE INTRODUCTION:>>>>Our store helps our customers improve their \\' \\n               \\'quality of life~As a distributor, we value quality and service.Focus on the high quality and durability of the \\' \\n               \\'product.Committed to creating a store that satisfies and reassures our customers.TIPS:>>>>1. Please allow minor errors \\' \\n               \\'in the data due to manual measurements.2. Due to the color settings of the display, the actual color may be slightly \\' \\n               \\'different from the online image.QUALITY PROMISE:>>>>Our goal is to continuously provide a range of quality products.We \\' \\n               \\'place a huge emphasis on the values of quality and reliability.We have always insisted on fulfilling this \\' \\n               \\'commitment.In short, we want our customers to have the same great product experience every time and be trusted to deliver \\' \\n               \\'on this commitment.Please give us a chance to serve you.OTHER:>>>>athletic sneaker laces athletic sneakers white \\' \\n               \\'athletic sneakers for women clearance leather Sneaker leather sneakers women leather sneakers for menleather sneaker laces \\' \\n               \\'leather sneaker platform basketball shoes basketball shoes for men basketball shoe laces basketball shoe grip basketball \\' \\n               \\'shoes for women fitness shoes for men fitness shoes women workout fitness shoes women fitness shoes women size 5 \\' \\n               \\'fitness shoes men workout fitness shoes for men high top sneakers for women walking shoes sneakers with arch support for women\\'\\n    }\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_item_page_ws',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_parse_item_page_ebay(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_item_page_ebay\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n    mock_asin = \"403760625150\"\\n\\n    # Invoke function, check response\\n    kwargs[\"mock\"].get(f\"https://www.ebay.com/itm/{mock_asin}\", content=mock_body)\\n    output = parse_item_page_ebay(mock_asin)\\n    expected = {\\n        \\'BulletPoints\\': \\'Item specifics Condition:New without box: A brand-new, \\' \\n            \\'unused, and unworn item (including handmade items) that is \\' \\n            \\'not in ...  Read moreabout the conditionNew without box: A \\' \\n            \\'brand-new, unused, and unworn item (including handmade \\' \\n            \\'items) that is not in original packaging or may be missing \\' \\n            \\'original packaging materials (such as the original box or \\' \\n            \\'bag). The original tags may not be attached. For example, \\' \\n            \\'new shoes (with absolutely no signs of wear) that are no \\' \\n            \\'longer in their original box fall into this category.  See \\' \\n            \\'all condition definitionsopens in a new window or tab  \\' \\n            \\'Closure:Lace Up US Shoe Size:10 Occasion:Activewear, Casual \\' \\n            \\'Silhouette:Puma Fabric Type:Mesh Vintage:No Cushioning \\' \\n            \\'Level:Moderate Department:Men Style:Sneaker Outsole \\' \\n            \\'Material:Rubber Features:Breathable, Comfort, Cushioned, \\' \\n            \\'Performance Season:Fall, Spring, Summer, Winter \\' \\n            \\'Idset_Mpn:193990-21 Shoe Shaft Style:Low Top Style \\' \\n            \\'Code:193990-16 Pattern:Solid Character:J. Cole Lining \\' \\n            \\'Material:Synthetic Color:Red Brand:PUMA Type:Athletic \\' \\n            \\'Customized:No Model:RS-Dreamer Theme:Sports Shoe \\' \\n            \\'Width:Standard Upper Material:Textile Insole \\' \\n            \\'Material:Synthetic Performance/Activity:Basketball Product \\' \\n            \\'Line:Puma Dreamer\\',\\n        \\'Description\\': \\'N/A\\',\\n        \\'MainImage\\': \\'https://i.ebayimg.com/images/g/4ggAAOSwpk1ioTWz/s-l500.jpg\\',\\n        \\'Price\\': \\'N/A\\',\\n        \\'Rating\\': None,\\n        \\'Title\\': \"Puma RS-Dreamer J. Cole Basketball Shoes Red 193990-16 Men\\'s Size 10.0\",\\n        \\'asin\\': \\'403760625150\\',\\n        \\'option_to_image\\': {},\\n        \\'options\\': {},\\n    }\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_item_page_ebay',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_parse_item_page_amz(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_item_page_amz\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n    mock_asin = \"B073WRF565\"\\n\\n    # Invoke function, check response\\n    kwargs[\"mock\"].get(f\"https://www.amazon.com/dp/{mock_asin}\", content=mock_body)\\n    output = parse_item_page_amz(mock_asin)\\n    expected = {\\n        \\'asin\\': \\'B073WRF565\\',\\n        \\'Title\\': \\'Amazon Basics Foldable 14\" Black Metal Platform Bed Frame with Tool-Free Assembly No Box Spring Needed - Full\\',\\n        \\'Price\\': \\'N/A\\',\\n        \\'Rating\\': \\'4.8 out of 5 stars\\',\\n        \\'BulletPoints\\': \\' \\\\n About this item    \\' \\n            \\'Product dimensions: 75\" L x 54\" W x 14\" H | Weight: 41.4 pounds    \\' \\n            \\'Designed for sleepers up to 250 pounds    Full size platform bed frame offers a quiet, noise-free, \\' \\n            \\'supportive foundation for a mattress. No box spring needed    Folding mechanism makes the frame easy \\' \\n            \\'to store and move in tight spaces    Provides extra under-the-bed storage space with a vertical clea\\' \\n            \\'rance of about 13 inches    \\\\n › See more product details \\',\\n        \\'Description\\': \\'Amazon Basics Foldable, 14\" Black Metal Platform Bed Frame with Tool-Free Assembly, No Box Spring Needed - Full   Amazon Basics\\',\\n        \\'MainImage\\': \\'https://images-na.ssl-images-amazon.com/images/I/41WIGwt-asL.__AC_SY300_SX300_QL70_FMwebp_.jpg\\',\\n        \\'options\\': {\\'size\\': [\\'Twin\\', \\'Full\\', \\'Queen\\', \\'King\\'],\\n        \\'style\\': [\\'14-Inch\\', \\'18-Inch\\']},\\n        \\'option_to_image\\': {}\\n    }\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_item_page_amz',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_parse_results_ebay(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_results_ebay\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n    mock_query = \"red basketball shoes\"\\n    \\n    # Invoke function, check response\\n    query = mock_query.replace(\" \", \"+\")\\n    kwargs[\"mock\"].get(f\\'https://www.ebay.com/sch/i.html?_nkw={query}&_pgn=1\\', content=mock_body)\\n    output = parse_results_ebay(mock_query, 1)\\n    expected = [{\\n\\t\\t\\'Price\\': [\\'100.00\\', \\'150.00\\'],\\n\\t\\t\\'Title\\': \"Reebok Answer IV Men\\'s Basketball Shoes\",\\n\\t\\t\\'asin\\': \\'175065123030\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$119.90\\',\\n\\t\\t\\'Title\\': \"Air Jordan Stay Loyal Shoes Black Red White DB2884-001 Men\\'s Multi \"\\n\\t\\t\\'Size NEW\\',\\n\\t\\t\\'asin\\': \\'265672133690\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$100.00\\',\\n\\t\\t\\'Title\\': \"Fila Men\\'s Stackhouse Spaghetti Basketball Shoes Black Red White \"\\n\\t\\t\\'1BM01788-113\\',\\n\\t\\t\\'asin\\': \\'175282509234\\'\\n\\t}, {\\n\\t\\t\\'Price\\': [\\'61.99\\',\\n\\t\\t\\t\\'85.99\\'\\n\\t\\t],\\n\\t\\t\\'Title\\': \\'Puma Disc Rebirth 19481203 Mens Black Red Synthetic Athletic \\'\\n\\t\\t\\'Basketball Shoes\\',\\n\\t\\t\\'asin\\': \\'313944854658\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$0.01\\',\\n\\t\\t\\'Title\\': \"Puma RS-Dreamer J. Cole Basketball Shoes Red 193990-16 Men\\'s Size \"\\n\\t\\t\\'10.0\\',\\n\\t\\t\\'asin\\': \\'403760625150\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$45.00\\',\\n\\t\\t\\'Title\\': \\'Nike Mens 9.5 PG 5  Maroon Red White Basketball Shoes Sneaker DM \\'\\n\\t\\t\\'5045–601￼ Flaw\\',\\n\\t\\t\\'asin\\': \\'115456853186\\'\\n\\t}, {\\n\\t\\t\\'Price\\': [\\'114.90\\',\\n\\t\\t\\t\\'119.90\\'\\n\\t\\t],\\n\\t\\t\\'Title\\': \"Air Jordan Stay Loyal Shoes White Black Red DB2884-106 Men\\'s Multi \"\\n\\t\\t\\'Size NEW\\',\\n\\t\\t\\'asin\\': \\'155046831159\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$8.99\\',\\n\\t\\t\\'Title\\': \"Harden Volume 3 Men\\'s Basketball Shoes Size 9.5\",\\n\\t\\t\\'asin\\': \\'175342407862\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'$59.97\\',\\n\\t\\t\\'Title\\': \"Men\\'s Nike Precision 5 Basketball Shoes Gym Red Black Grey Bred \"\\n\\t\\t\\'Multi Size NEW\\',\\n\\t\\t\\'asin\\': \\'134149634710\\'\\n\\t}]\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_results_ebay',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_parse_results_amz(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_results_amz\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n    mock_query = \"red basketball shoes\"\\n    \\n    # Invoke function, check response\\n    query = mock_query.replace(\" \", \"+\")\\n    kwargs[\"mock\"].get(f\"https://www.amazon.com/s?k={query}&page=1\", content=mock_body)\\n    output = parse_results_amz(mock_query, 1)\\n    expected = [{\\n\\t\\t\\'Price\\': \\'59.49\\',\\n\\t\\t\\'Title\\': \\'High Top Mens Basketball Shoes Lou Williams Streetball Master \\' \\n\\t\\t\\t\\'Breathable Non Slip Outdoor Sneakers Cushioning Workout Shoes for \\' \\n\\t\\t\\t\\'Fitness\\',\\n\\t\\t\\'asin\\': \\'B083QCWF61\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'45.99\\',\\n\\t\\t\\'Title\\': \\'Kids Basketball Shoes High-top Sports Shoes Sneakers Durable \\'\\n\\t\\t\\'Lace-up Non-Slip Running Shoes Secure for Little Kids Big Kids and \\'\\n\\t\\t\\'Boys Girls\\',\\n\\t\\t\\'asin\\': \\'B08FWWWQ11\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'64.99\\',\\n\\t\\t\\'Title\\': \\'Unisex-Adult Lockdown 5 Basketball Shoe\\',\\n\\t\\t\\'asin\\': \\'B0817BFNC4\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'63.75\\',\\n\\t\\t\\'Title\\': \\'Unisex-Child Team Hustle D 9 (Gs) Sneaker\\',\\n\\t\\t\\'asin\\': \\'B07HHTS79M\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'74.64\\',\\n\\t\\t\\'Title\\': \\'Unisex-Adult D.O.N. Issue 3 Basketball Shoe\\',\\n\\t\\t\\'asin\\': \\'B08N8DQLS2\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'104.90\\',\\n\\t\\t\\'Title\\': \"Men\\'s Lebron Witness IV Basketball Shoes\",\\n\\t\\t\\'asin\\': \\'B07TKMMHVB\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'36.68\\',\\n\\t\\t\\'Title\\': \"Unisex-Child Pre-School Jet \\'21 Basketball Shoe\",\\n\\t\\t\\'asin\\': \\'B08N6VRHV4\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'59.98\\',\\n\\t\\t\\'Title\\': \"Men\\'s Triple Basketball Shoe\",\\n\\t\\t\\'asin\\': \\'B08QCL8VKM\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'45.98\\',\\n\\t\\t\\'Title\\': \\'Unisex-Child Pre School Lockdown 4 Basketball Shoe\\',\\n\\t\\t\\'asin\\': \\'B07HKP12DH\\'\\n\\t}, {\\n\\t\\t\\'Price\\': \\'143.72\\',\\n\\t\\t\\'Title\\': \"Men\\'s Basketball Shoes\",\\n\\t\\t\\'asin\\': \\'B07SNR7HRF\\'\\n\\t}]\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_results_amz',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_parse_results_ws(**kwargs):\\n    # Read mock response data\\n    mock_file = open(\"tests/transfer/mocks/mock_parse_results_ws\", \"rb\")\\n    mock_body = mock_file.read()\\n    mock_file.close()\\n    mock_query = \"red basketball shoes\"\\n    \\n    # Invoke function, check response\\n    query_str = mock_query.replace(\" \", \"+\")\\n    url = (\\n        f\\'{WEBSHOP_URL}/search_results/{WEBSHOP_SESSION}/\\'\\n        f\\'{query_str}/1\\'\\n    )\\n    kwargs[\"mock\"].get(url, content=mock_body)\\n    output = parse_results_ws(mock_query, 1)\\n    expected = [{\\n        \\'Price\\': [24.49, 39.99],\\n        \\'Title\\': \"BinGoDug Men\\'s Basketball Shoes, Men\\'s Fashion Sneakers, Air \"\\n        \\'Basketball Shoes for Men, Womens Basketball Shoes, Mens Basketball \\'\\n        \\'Shoes, Boys Basketball Shoes, Youth Basketball Shoes Men Women\\',\\n        \\'asin\\': \\'B09GKFNQWT\\'\\n    }, {\\n        \\'Price\\': [1.89, 7.58],\\n        \\'Title\\': \"RQWEIN Comfortable Mesh Sneakers Men\\'s Roading Running Shoes \"\\n        \\'Tennis Shoes Casual Fashion Sneakers Outdoor Non Slip Gym Athletic \\'\\n        \\'Sport Shoes\\',\\n        \\'asin\\': \\'B09BFY2R3R\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \\'PMUYBHF Womens Fashion Flat Shoes Comfortable Running Shoes \\'\\n        \\'Sneakers Tennis Athletic Shoe Casual Walking Shoes\\',\\n        \\'asin\\': \\'B09P87V3LZ\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \\'PMUYBHF Fashion Travel Shoes Jogging Walking Sneakers Air Cushion \\'\\n        \\'Platform Loafers Air Cushion Mesh Shoes Walking Dance Shoes\\',\\n        \\'asin\\': \\'B09N6SNKC1\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \"PMUYBHF Women\\'s Ballet Flats Walking Flats Shoes Dressy Work Low \"\\n        \\'Wedge Arch Suport Flats Shoes Slip On Dress Shoes\\',\\n        \\'asin\\': \\'B09N6X5S74\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \"PWKSELW High-top Men\\'s Basketball Shoes Outdoor Sports Shoes \"\\n        \\'Cushioning Training Shoes Casual Running Shoes\\',\\n        \\'asin\\': \\'B09MDB9V5W\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \"Women\\'s Flat Shoes Classic Round Toe Slip Office Black Ballet \"\\n        \\'Flats Walking Flats Shoes Casual Ballet Flats\\',\\n        \\'asin\\': \\'B09N6PDFRF\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \"Women\\'s Mid-Calf Boots Wide Calf Boots for Women Fashion Zipper \"\\n        \\'Womens Shoes Pu Leather Casual Boots Womens Slip-On Womens Flat \\'\\n        \"Shoes Med Heel Womens\\' Boots Winter Snow Boot Comfy Boots(,5.5)\",\\n        \\'asin\\': \\'B09N8ZHFNM\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \\'PMUYBHF Womens Leisure Fitness Running Sport Warm Sneakers Shoes \\'\\n        \\'Slip-On Mule Sneakers Womens Mules\\',\\n        \\'asin\\': \\'B09P87DWGR\\'\\n    }, {\\n        \\'Price\\': 100.0,\\n        \\'Title\\': \\'Men Dress Shoes Leather Modern Classic Business Shoes Lace Up \\'\\n        \\'Classic Office Shoes Business Formal Shoes for Men\\',\\n        \\'asin\\': \\'B09R9MMTKR\\'\\n    }]\\n    assert output == expected\\n',\n",
       "  'function_name': 'test_parse_results_ws',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_convert_dict_to_actions():\\n    # Test RESULTS page type\\n    asin = \"334490012932\"\\n    page_num = 2\\n    products = [{\\n        \\'asin\\': \\'125331076844\\',\\n        \\'Title\\': \\'Modern Tall Torchiere Floor Lamp Brushed Nickel Chrome Metal Decor Living Room\\',\\n        \\'Price\\': \\'$129.95\\'\\n    }, {\\n        \\'asin\\': \\'125109985453\\',\\n        \\'Title\\': \\'Floor Lamps Set of 2 Polished Steel Crystal Glass for Living Room Bedroom\\',\\n        \\'Price\\': \\'$179.99\\'\\n    }, {\\n        \\'asin\\': \\'125265434055\\',\\n        \\'Title\\': \\'Floor Lamp Nickel/Polished Concrete Finish with Off-White Linen Fabric Shade\\',\\n        \\'Price\\': \\'$130.68\\'\\n    }, {\\n        \\'asin\\': \\'195197281169\\',\\n        \\'Title\\': \\'New ListingVintage Mid Century Modern Glass Amber Globe Tension Pole Floor Lamp Light\\',\\n        \\'Price\\': \\'$165.00\\'\\n    }, {\\n        \\'asin\\': \\'195197512929\\',\\n        \\'Title\\': \\'New ListingVTG Brass Floor Lamp Glass Shade 63.5\" Tall 12\" Diameter Glass Shade Original\\',\\n        \\'Price\\': \\'$279.45\\'\\n    }, {\\n        \\'asin\\': \\'304550250934\\',\\n        \\'Title\\': \\'Vintage Mid Century Modern 3 Light Tension Pole Floor Lamp glass shades atomic a\\',\\n        \\'Price\\': \\'$149.99\\'\\n    }, {\\n        \\'asin\\': \\'175338033811\\',\\n        \\'Title\\': \\'Antique FOSTORIA Ornate Brass Piano  Adjustable Floor Oil Lamp up to 76\" Tall !!\\',\\n        \\'Price\\': \\'$1,995.00\\'\\n    }, {\\n        \\'asin\\': \\'334490012932\\',\\n        \\'Title\\': \\'Vintage Mid Century Glass Shade Amber Globe 3 Tension Pole Floor Lamp Light MCM\\',\\n        \\'Price\\': \\'$128.00\\'\\n    }, {\\n        \\'asin\\': \\'185433933521\\',\\n        \\'Title\\': \\'Brass & Pink Glass Lotus 6 Petal Lamp Shades Set Of Two Replacement Parts As Is\\',\\n        \\'Price\\': \\'$90.00\\'\\n    }]\\n\\n    actions = convert_dict_to_actions(Page.RESULTS, products, asin, page_num)\\n\\n    assert actions[\\'valid\\'] == [\\n        \\'click[back to search]\\',\\n        \\'click[< prev]\\',\\n        \\'click[item - Modern Tall Torchiere Floor Lamp Brushed Nickel Chrome Metal Decor Living Room]\\',\\n        \\'click[item - Floor Lamps Set of 2 Polished Steel Crystal Glass for Living Room Bedroom]\\',\\n        \\'click[item - Floor Lamp Nickel/Polished Concrete Finish with Off-White Linen Fabric Shade]\\',\\n        \\'click[item - New ListingVintage Mid Century Modern Glass Amber Globe Tension Pole Floor Lamp Light]\\',\\n        \\'click[item - New ListingVTG Brass Floor Lamp Glass Shade 63.5\" Tall 12\" Diameter Glass Shade Original]\\',\\n        \\'click[item - Vintage Mid Century Modern 3 Light Tension Pole Floor Lamp glass shades atomic a]\\',\\n        \\'click[item - Antique FOSTORIA Ornate Brass Piano  Adjustable Floor Oil Lamp up to 76\" Tall !!]\\',\\n        \\'click[item - Vintage Mid Century Glass Shade Amber Globe 3 Tension Pole Floor Lamp Light MCM]\\',\\n        \\'click[item - Brass & Pink Glass Lotus 6 Petal Lamp Shades Set Of Two Replacement Parts As Is]\\'\\n    ]\\n\\n    # Test ITEM_PAGE page type\\n    asin = \"224636269803\"\\n    products = {\\n        \\'224636269803\\': {\\n            \\'asin\\': \\'224636269803\\',\\n            \\'Title\\': \\'Sony SRS-XB01 EXTRA BASS Portable Water-Resistant  Wireless Bluetooth Speaker\\',\\n            \\'Price\\': \\'24.99\\',\\n            \\'MainImage\\': \\'https://i.ebayimg.com/images/g/jVEAAOSwCLBhXLuD/s-l500.jpg\\',\\n            \\'Rating\\': None,\\n            \\'options\\': {\\n                \\'Color\\': [\\'Black\\', \\'White\\', \\'Red\\', \\'Blue\\']\\n            },\\n            \\'option_to_image\\': {},\\n            \\'Description\\': \"eBay Sony EXTRA BASS Portable Water-Resistant Wireless Bluetooth SpeakerBRAND NEW ITEMFREE SHIPPING WITHIN USA30 DAY RETURN POLICYKey FeaturesEXTRA BASS for deep, punchy soundCompact portable designUp to 6 hours of battery lifeWater resistant for worry-free useSupplied with color-coordinated strap What\\'s in the Box?Sony EXTRA BASS Portable Bluetooth SpeakerPower supplyUser manual HIGHLIGHTSMUSIC THAT TRAVELSSmall size but mighty in volume to deliver powerful beats wherever you travelHANDS FREE CALLINGWith the built-in microphone, taking calls from your smartphone is easy. SPLASHPROOF CASINGTake to the pool or beach without worrying about water damaging the speaker unit UPGRADE THE AUDIOWirelessly connects 2 speakers and achieve stereo sound with speaker add function LONGER BATTERY LIFELonger Virtual Happy Hours with this rechargeable speaker\\'s 6 hour battery life Technical SpecsFeatureValueBrandSonyTypePortable speakerModel NumberSRSXB01BluetoothYesFrequency range2.4 GHzMax. Communication Range32 ftBattery LifeApprox. 6 hrsWater ProtectionIPX5Input and Output TerminalsStereo Mini Jack (IN)Dimensions (W x H x D)Approx. 3 1/4 × 2 3/8 × 2 1/4 inWeightApprox. 5.65 oz\",\\n            \\'BulletPoints\\': \"Item specifics Condition:New: A brand-new, unused, unopened, undamaged item in its original packaging (where packaging is ...  Read moreabout the conditionNew: A brand-new, unused, unopened, undamaged item in its original packaging (where packaging is applicable). Packaging should be the same as what is found in a retail store, unless the item is handmade or was packaged by the manufacturer in non-retail packaging, such as an unprinted box or plastic bag. See the seller\\'s listing for full details. See all condition definitionsopens in a new window or tab  Model:EXTRA BASS Connectivity:Bluetooth, Wireless Type:Portable Speaker System Compatible Model:EXTRA BASS, Portable Water-Resistant Features:Bluetooth, Water-Resistant MPN:SRS-XB01/B, SRS-XB01/L, SRS-XB01/R, SRS-XB01/W Brand:Sony\"\\n        }\\n    }\\n\\n    actions = convert_dict_to_actions(Page.ITEM_PAGE, products, asin, 1)\\n\\n    assert actions[\\'valid\\'] == [\\'click[back to search]\\', \\'click[< prev]\\', \\'click[description]\\', \\'click[features]\\', \\'click[buy now]\\', \\'click[Black]\\', \\'click[White]\\', \\'click[Red]\\', \\'click[Blue]\\']\\n\\n    # Test SUB_PAGE page type\\n    actions = convert_dict_to_actions(Page.SUB_PAGE, {}, \"12345\", 1)\\n    \\n    assert actions[\\'valid\\'] == [\\'click[back to search]\\', \\'click[< prev]\\']',\n",
       "  'function_name': 'test_convert_dict_to_actions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/transfer/test_predict_help.py'},\n",
       " {'code': 'def test_random_idx():\\n    random.seed(24)\\n    weights = [random.randint(0, 10) for _ in range(0, 50)]\\n    cml_weights = [0]\\n    for w in weights:\\n        cml_weights.append(cml_weights[-1] + w)\\n    idx_1, expected_1 = random_idx(cml_weights), 44\\n    idx_2, expected_2 = random_idx(cml_weights), 15\\n    idx_3, expected_3 = random_idx(cml_weights), 36\\n    assert idx_1 == expected_1\\n    assert idx_2 == expected_2\\n    assert idx_3 == expected_3\\n',\n",
       "  'function_name': 'test_random_idx',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/test_utils.py'},\n",
       " {'code': 'def test_setup_logger():\\n    LOG_DIR = \\'user_session_logs_test/\\'\\n    user_log_dir = Path(LOG_DIR)\\n    user_log_dir.mkdir(parents=True, exist_ok=True)\\n    session_id = \"ABC\"\\n\\n    logger = setup_logger(session_id, user_log_dir)\\n    log_file = Path(LOG_DIR + \"/\" + session_id + \".jsonl\")\\n    assert Path(log_file).is_file()\\n    assert logger.level == logging.INFO\\n\\n    content = \"Hello there\"\\n    logger.info(content)\\n    assert log_file.read_text().strip(\"\\\\n\") == content\\n\\n    shutil.rmtree(LOG_DIR)\\n',\n",
       "  'function_name': 'test_setup_logger',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/test_utils.py'},\n",
       " {'code': \"def test_generate_mturk_code():\\n    suite = [\\n        ('', 'DA39A3EE5E'),\\n        ('ABC', '3C01BDBB26'),\\n        ('123', '40BD001563'),\\n        ('1A1', '10E7DB0A44'),\\n        ('$%^ABC', '5D5607D24E')\\n    ]\\n    for session_id, expected in suite:\\n        output = generate_mturk_code(session_id)\\n        assert type(expected) is str\\n        assert output == expected\",\n",
       "  'function_name': 'test_generate_mturk_code',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/test_utils.py'},\n",
       " {'code': 'def test_normalize_color():\\n    suite = [\\n        (\"\", \"\"),\\n        (\"black forest\", \"black\"),\\n        (\"violet lavender\", \"lavender\"),\\n        (\"steelivy fuchsia\", \"fuchsia\"),\\n        (\"123alabaster\", \"alabaster\"),\\n        (\"webshop\", \"webshop\")\\n    ]\\n    for color_string, expected in suite:\\n        output = normalize_color(color_string)\\n        assert type(output) is str\\n        assert output == expected\\n',\n",
       "  'function_name': 'test_normalize_color',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_normalize.py'},\n",
       " {'code': 'def test_normalize_color_size():\\n    product_prices = {\\n        (1, \"black forest\", \"3 meter\"): 10.29,\\n        (2, \"violet lavender\", \"xx-large\"): 23.42,\\n        (3, \"steelivy fuchsia\", \"random value\"): 193.87,\\n        (4, \"123alabaster\", \"40cm plus\"): 67.23,\\n        (5, \"webshop\", \"142\"): 1.02,\\n        (6, \"webshopsteel\", \"2 petite\"): 57.99,\\n        (7, \"leather black\", \"91ft walnut feet\"): 6.20,\\n    }\\n    color_mapping_expected = {\\n        \\'N.A.\\': \\'not_matched\\',\\n        \"black forest\": \"black\",\\n        \"violet lavender\": \"lavender\",\\n        \"steelivy fuchsia\": \"fuchsia\",\\n        \"123alabaster\": \"alabaster\",\\n        \"webshop\": \"not_matched\",\\n        \"webshopsteel\": \"steel\",\\n        \"leather black\": \"black\"\\n    }\\n    size_mapping_expected = {\\n        \\'N.A.\\': \\'not_matched\\',\\n        \"3 meter\": \\'(.*)meter\\',\\n        \"xx-large\": \\'xx-large\\',\\n        \"random value\": \"not_matched\",\\n        \"40cm plus\": \\'(.*)plus\\',\\n        \"142\": \"numeric_size\",\\n        \"2 petite\": \"(.*)petite\",\\n        \"91ft walnut feet\": \\'(.*)ft\\',\\n    }\\n\\n    color_mapping, size_mapping = normalize_color_size(product_prices)\\n    assert type(color_mapping) == dict\\n    assert type(size_mapping)  == dict\\n    assert color_mapping == color_mapping_expected\\n    assert size_mapping  == size_mapping_expected\\n',\n",
       "  'function_name': 'test_normalize_color_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_normalize.py'},\n",
       " {'code': 'def test_get_type_reward():\\n    # Exact Match\\n    goal = {\\n        \\'query\\': \"Query 1\",\\n        \\'product_category\\': \"a › b › c\",\\n        \\'name\\': \"Name 1\"\\n    }\\n    purchased = {\\n        \\'query\\': \"Query 1\",\\n        \\'product_category\\': \"a › b › c\",\\n        \\'name\\': \"Name 1\"\\n    }\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'r_type\\'] == 1.\\n    assert result[\\'query_match\\'] == True\\n    assert result[\\'category_match\\'] == True\\n    assert result[\\'title_score\\'] == 1\\n\\n    # Query Mismatch\\n    purchased[\\'query\\'] = \\'Query 2\\'\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'query_match\\'] == False\\n\\n    # Out of order / non-matching / partially matching / duplicate categories\\n    purchased[\\'product_category\\'] = \"b › c › a\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'category_match\\'] == True\\n    purchased[\\'product_category\\'] = \"d › e › f\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'category_match\\'] == False\\n    purchased[\\'product_category\\'] = \"a › d › b\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'category_match\\'] == True\\n    purchased[\\'product_category\\'] = \"a › a › b\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'category_match\\'] == True\\n    purchased[\\'product_category\\'] = \"a › a › d\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'category_match\\'] == False\\n\\n    # Similar product names\\n    goal[\\'name\\'] = \"Mens D.O.N. Issue 2 Gca Basketball Sneakers Shoes Casual - Off White\"\\n    purchased[\\'name\\'] = \"PEAK High Top Mens Basketball Shoes Lou Williams Streetball Master Breathable Non Slip Outdoor Sneakers\"\\n    result = get_type_reward(purchased, goal)\\n    assert isclose(result[\\'title_score\\'], 0.333, abs_tol=1e-2)\\n\\n    # Slightly similar product names\\n    goal[\\'name\\'] = \"Saireed UL Listed 2 Prong Power Cord for JBL Bar 3.1 Bar 2.1 Channel 4K Ultra HD Soundbar Home Theater System Subwoofer\"\\n    purchased[\\'name\\'] = \"BRST AC Power Cord Outlet Socket Cable Plug Lead for Panasonic SC-HT830V DVD/VCR Combo Home Theater System\"\\n    result = get_type_reward(purchased, goal)\\n    assert isclose(result[\\'title_score\\'], 0.3, abs_tol=1e-2)\\n\\n    goal[\\'name\\'] = \"Saireed UL Listed 2 Prong Power Cord for JBL Bar 3.1 Bar 2.1 Channel 4K Ultra HD Soundbar\"\\n    purchased[\\'name\\'] = \"BRST AC Power Cord Outlet Socket Cable Plug Lead for Panasonic SC-HT830V DVD/VCR Combo Home Theater System\"\\n    result = get_type_reward(purchased, goal)\\n    assert isclose(result[\\'title_score\\'], 0.15, abs_tol=1e-2)\\n\\n    # Completely different product names\\n    goal[\\'name\\'] = \"Rusticware 921ORB Kitchen and Bath Cabinet Knob\"\\n    purchased[\\'name\\'] = \"Minkissy 2pcs Stainless Steel Eyebrow Tweezers Blackhead Acne Remover Portable Makeup Tweezers (Silver)\"\\n    result = get_type_reward(purchased, goal)\\n    assert result[\\'title_score\\'] < 0.05\\n',\n",
       "  'function_name': 'test_get_type_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_goal.py'},\n",
       " {'code': 'def test_get_attribute_reward():\\n    # Exact Match\\n    goal = {\\n        \\'attributes\\': [\"tea tree\", \"essential oils\", \"natural ingredients\"],\\n    }\\n    purchased = {\\n        \\'Attributes\\': [\"tea tree\", \"essential oil\", \"natural ingredients\"]\\n    }\\n    r_attr, num_attr_matches = get_attribute_reward(purchased, goal)\\n    assert r_attr == 1\\n    assert num_attr_matches == 3\\n\\n    # Partial Match\\n    goal = {\\n        \\'attributes\\': [\"tea tree\", \"essential oils\", \"natural ingredients\"]\\n    }\\n    purchased = {\\n        \\'Attributes\\': [\"essential oil\", \"natural ingredients\"],\\n        \\'Title\\': \"\",\\n        \\'BulletPoints\\': [],\\n        \\'Description\\': \"\"\\n    }\\n    r_attr, num_attr_matches = get_attribute_reward(purchased, goal)\\n    assert r_attr == 2./3.\\n    assert num_attr_matches == 2\\n\\n    # Goal attributes found in purchased non-goals\\n    goal = {\\n        \\'attributes\\': [\"tea tree\", \"essential oils\", \"natural ingredients\"]\\n    }\\n    purchased = {\\n        \\'Attributes\\': [],\\n        \\'Title\\': \"\",\\n        \\'BulletPoints\\': [\"This shampoo has essential oils and smells like lemons\"],\\n        \\'Description\\': \"Best shampoo on the market, made with natural ingredients\"\\n    }\\n    r_attr, num_attr_matches = get_attribute_reward(purchased, goal)\\n    assert r_attr == 2./3.\\n    assert num_attr_matches == 2\\n\\n    # No match\\n    goal = {\\n        \\'attributes\\': [\"tea tree\", \"essential oils\", \"natural ingredients\"]\\n    }\\n    purchased = {\\n        \\'Attributes\\': [\"tea bag\", \"earl gray\", \"lipton\"],\\n        \\'Title\\': \"English tea for breakfast\",\\n        \\'BulletPoints\\': [\"Soothing aroma\", \"Calming, great feeling\"],\\n        \\'Description\\': \"Best tea made by Lipton, great to pair with breakfast\"\\n    }\\n    r_attr, num_attr_matches = get_attribute_reward(purchased, goal)\\n    assert r_attr == 0\\n    assert num_attr_matches == 0\\n',\n",
       "  'function_name': 'test_get_attribute_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_goal.py'},\n",
       " {'code': 'def test_get_option_reward():\\n    # Exact Match\\n    goal = [\"grey\", \"XL\", \"pack of 12\"]\\n    purchased = [\"pack of 12\", \"grey\", \"XL\"]\\n    r_option, matches = get_option_reward(purchased, goal)\\n    assert matches == len(goal)\\n    assert r_option == 1\\n\\n    # Partial Match\\n    goal = [\"grey\", \"XL\", \"pack of 12\"]\\n    purchased = [\"pack of 12\", \"blue\", \"XL\"]\\n    r_option, matches = get_option_reward(purchased, goal)\\n    assert matches == len(goal) - 1\\n    assert r_option == 2./3.\\n\\n    # Fuzzy Match\\n    goal = [\"cool powder snow\", \"XL\", \"pack of 12\"]\\n    purchased = [\"pack of 12\", \"powder snow\", \"XL\"]\\n    r_option, matches = get_option_reward(purchased, goal)\\n    assert matches == len(goal)\\n    assert r_option == 1\\n\\n    # Empty Goal Options\\n    goal = []\\n    purchased = [\"goal 1\", \"goal 2\"]\\n    r_option, matches = get_option_reward(purchased, goal)\\n    assert matches == 0\\n    assert r_option == None\\n\\n    # Empty Purchased Options\\n    goal = [\"goal 1\", \"goal 2\"]\\n    purchased = []\\n    r_option, matches = get_option_reward(purchased, goal)\\n    assert matches == 0\\n    assert r_option == 0\\n',\n",
       "  'function_name': 'test_get_option_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_goal.py'},\n",
       " {'code': 'def test_get_reward():\\n    # Exact Match\\n    goal = {\\n        \\'query\\': \"Query 1\",\\n        \\'product_category\\': \"a › b › c\",\\n        \\'name\\': \"Mens D.O.N. Issue 2 Gca Basketball Sneakers Shoes Casual - Off White\",\\n        \\'attributes\\': [\"tea tree\", \"essential oils\", \"natural ingredients\"],\\n        \\'goal_options\\': {\"color\": \"grey\", \"size\": \"XL\"},\\n        \\'price_upper\\': 40.00\\n    }\\n    purchased = {\\n        \\'query\\': \"Query 1\",\\n        \\'product_category\\': \"a › b › c\",\\n        \\'name\\': \"Mens D.O.N. Issue 2 Gca Basketball Sneakers Shoes Casual - Off White\",\\n        \\'Attributes\\': [\"tea tree\", \"essential oil\", \"natural ingredients\"],\\n        \\'Title\\': \"\",\\n        \\'BulletPoints\\': [],\\n        \\'Description\\': \"\",\\n        \\'goal_options\\': {\"color\": \"grey\", \"size\": \"XL\"}\\n    }\\n    total_reward = get_reward(purchased, goal, 35, purchased[\\'goal_options\\'])\\n    assert total_reward == 1\\n\\n    # Variation in r_attributes reward\\n    purchased[\\'Attributes\\'] = []\\n    purchased[\\'Title\\'] = \"\"\\n    purchased[\\'BulletPoints\\'] = \"This shampoo has essential oils and smells like lemons\"\\n    purchased[\\'Description\\'] = \"Best shampoo on the market, made with natural ingredients\"\\n    total_reward = get_reward(purchased, goal, 35, purchased[\\'goal_options\\'])\\n    assert isclose(total_reward, 2./3., abs_tol=1e-2)\\n\\n    # Variation in r_option reward\\n    goal[\\'goal_options\\'] = {\"color\": \"grey\", \"size\": \"XL\", \"amount\": \"pack of 12\"}\\n    total_reward = get_reward(purchased, goal, 35, purchased[\\'goal_options\\'])\\n    assert isclose(total_reward, 0.5714, abs_tol=1e-2)\\n\\n    # Variation in r_type reward\\n    goal[\\'name\\'] = \"Saireed UL Listed 2 Prong Power Cord for JBL Bar 3.1 Bar 2.1 Channel 4K Ultra HD Soundbar\"\\n    purchased[\\'name\\'] = \"BRST AC Power Cord Outlet Socket Cable Plug Lead for Panasonic SC-HT830V DVD/VCR Combo Home Theater System\"\\n    purchased[\\'query\\'] = \"Query 2\"\\n    purchased[\\'product_category\\'] = \"a › d › e\"\\n    total_reward = get_reward(purchased, goal, 35, purchased[\\'goal_options\\'])\\n    assert isclose(total_reward, 0.2857, abs_tol=1e-2)',\n",
       "  'function_name': 'test_get_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/tests/web-agent-site/engine/test_goal.py'},\n",
       " {'code': 'def home():\\n    return redirect(url_for(\\'index\\', session_id=\"abc\"))\\n',\n",
       "  'function_name': 'home',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': \"def index(session_id):\\n    global user_log_dir\\n    global all_products, product_item_dict, \\\\\\n           product_prices, attribute_to_asins, \\\\\\n           search_engine, \\\\\\n           goals, weights, user_sessions\\n\\n    if search_engine is None:\\n        all_products, product_item_dict, product_prices, attribute_to_asins = \\\\\\n            load_products(\\n                filepath=DEFAULT_FILE_PATH,\\n                num_products=DEBUG_PROD_SIZE\\n            )\\n        search_engine = init_search_engine(num_products=DEBUG_PROD_SIZE)\\n        goals = get_goals(all_products, product_prices)\\n        random.seed(233)\\n        random.shuffle(goals)\\n        weights = [goal['weight'] for goal in goals]\\n\\n    if session_id not in user_sessions and 'fixed' in session_id:\\n        goal_dix = int(session_id.split('_')[-1])\\n        goal = goals[goal_dix]\\n        instruction_text = goal['instruction_text']\\n        user_sessions[session_id] = {'goal': goal, 'done': False}\\n        if user_log_dir is not None:\\n            setup_logger(session_id, user_log_dir)\\n    elif session_id not in user_sessions:\\n        goal = random.choices(goals, weights)[0]\\n        instruction_text = goal['instruction_text']\\n        user_sessions[session_id] = {'goal': goal, 'done': False}\\n        if user_log_dir is not None:\\n            setup_logger(session_id, user_log_dir)\\n    else:\\n        instruction_text = user_sessions[session_id]['goal']['instruction_text']\\n\\n    if request.method == 'POST' and 'search_query' in request.form:\\n        keywords = request.form['search_query'].lower().split(' ')\\n        return redirect(url_for(\\n            'search_results',\\n            session_id=session_id,\\n            keywords=keywords,\\n            page=1,\\n        ))\\n    if user_log_dir is not None:\\n        logger = logging.getLogger(session_id)\\n        logger.info(json.dumps(dict(\\n            page='index',\\n            url=request.url,\\n            goal=user_sessions[session_id]['goal'],\\n        )))\\n    return map_action_to_html(\\n        'start',\\n        session_id=session_id,\\n        instruction_text=instruction_text,\\n    )\\n\\n\",\n",
       "  'function_name': 'index',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': \"def search_results(session_id, keywords, page):\\n    instruction_text = user_sessions[session_id]['goal']['instruction_text']\\n    page = convert_web_app_string_to_var('page', page)\\n    keywords = convert_web_app_string_to_var('keywords', keywords)\\n    top_n_products = get_top_n_product_from_keywords(\\n        keywords,\\n        search_engine,\\n        all_products,\\n        product_item_dict,\\n        attribute_to_asins,\\n    )\\n    products = get_product_per_page(top_n_products, page)\\n    html = map_action_to_html(\\n        'search',\\n        session_id=session_id,\\n        products=products,\\n        keywords=keywords,\\n        page=page,\\n        total=len(top_n_products),\\n        instruction_text=instruction_text,\\n    )\\n    logger = logging.getLogger(session_id)\\n    logger.info(json.dumps(dict(\\n        page='search_results',\\n        url=request.url,\\n        goal=user_sessions[session_id]['goal'],\\n        content=dict(\\n            keywords=keywords,\\n            search_result_asins=[p['asin'] for p in products],\\n            page=page,\\n        )\\n    )))\\n    return html\\n\\n\",\n",
       "  'function_name': 'search_results',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': \"def item_page(session_id, asin, keywords, page, options):\\n    options = literal_eval(options)\\n    product_info = product_item_dict[asin]\\n\\n    goal_instruction = user_sessions[session_id]['goal']['instruction_text']\\n    product_info['goal_instruction'] = goal_instruction\\n\\n    html = map_action_to_html(\\n        'click',\\n        session_id=session_id,\\n        product_info=product_info,\\n        keywords=keywords,\\n        page=page,\\n        asin=asin,\\n        options=options,\\n        instruction_text=goal_instruction,\\n        show_attrs=SHOW_ATTRS_TAB,\\n    )\\n    logger = logging.getLogger(session_id)\\n    logger.info(json.dumps(dict(\\n        page='item_page',\\n        url=request.url,\\n        goal=user_sessions[session_id]['goal'],\\n        content=dict(\\n            keywords=keywords,\\n            page=page,\\n            asin=asin,\\n            options=options,\\n        )\\n    )))\\n    return html\\n\\n\",\n",
       "  'function_name': 'item_page',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': \"def item_sub_page(session_id, asin, keywords, page, sub_page, options):\\n    options = literal_eval(options)\\n    product_info = product_item_dict[asin]\\n\\n    goal_instruction = user_sessions[session_id]['goal']['instruction_text']\\n    product_info['goal_instruction'] = goal_instruction\\n\\n    html = map_action_to_html(\\n        f'click[{sub_page}]',\\n        session_id=session_id,\\n        product_info=product_info,\\n        keywords=keywords,\\n        page=page,\\n        asin=asin,\\n        options=options,\\n        instruction_text=goal_instruction\\n    )\\n    logger = logging.getLogger(session_id)\\n    logger.info(json.dumps(dict(\\n        page='item_sub_page',\\n        url=request.url,\\n        goal=user_sessions[session_id]['goal'],\\n        content=dict(\\n            keywords=keywords,\\n            page=page,\\n            asin=asin,\\n            options=options,\\n        )\\n    )))\\n    return html\\n\\n\",\n",
       "  'function_name': 'item_sub_page',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': \"def done(session_id, asin, options):\\n    options = literal_eval(options)\\n    goal = user_sessions[session_id]['goal']\\n    purchased_product = product_item_dict[asin]\\n    price = product_prices[asin]\\n\\n    reward, reward_info = get_reward(\\n        purchased_product,\\n        goal,\\n        price=price,\\n        options=options,\\n        verbose=True\\n    )\\n    user_sessions[session_id]['done'] = True\\n    user_sessions[session_id]['reward'] = reward\\n    print(user_sessions)\\n\\n    logger = logging.getLogger(session_id)\\n    logger.info(json.dumps(dict(\\n        page='done',\\n        url=request.url,\\n        goal=goal,\\n        content=dict(\\n            asin=asin,\\n            options=options,\\n            price=price,\\n        ),\\n        reward=reward,\\n        reward_info=reward_info,\\n    )))\\n    del logging.root.manager.loggerDict[session_id]\\n    \\n    return map_action_to_html(\\n        f'click[{END_BUTTON}]',\\n        session_id=session_id,\\n        reward=reward,\\n        asin=asin,\\n        options=options,\\n        reward_info=reward_info,\\n        query=purchased_product['query'],\\n        category=purchased_product['category'],\\n        product_category=purchased_product['product_category'],\\n        goal_attrs=user_sessions[session_id]['goal']['attributes'],\\n        purchased_attrs=purchased_product['Attributes'],\\n        goal=goal,\\n        mturk_code=generate_mturk_code(session_id),\\n    )\\n\\n\",\n",
       "  'function_name': 'done',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/app.py'},\n",
       " {'code': 'def random_idx(cum_weights):\\n    \"\"\"Generate random index by sampling uniformly from sum of all weights, then\\n    selecting the `min` between the position to keep the list sorted (via bisect)\\n    and the value of the second to last index\\n    \"\"\"\\n    pos = random.uniform(0, cum_weights[-1])\\n    idx = bisect.bisect(cum_weights, pos)\\n    idx = min(idx, len(cum_weights) - 2)\\n    return idx\\n',\n",
       "  'function_name': 'random_idx',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/utils.py'},\n",
       " {'code': 'def setup_logger(session_id, user_log_dir):\\n    \"\"\"Creates a log file and logging object for the corresponding session ID\"\"\"\\n    logger = logging.getLogger(session_id)\\n    formatter = logging.Formatter(\\'%(message)s\\')\\n    file_handler = logging.FileHandler(\\n        user_log_dir / f\\'{session_id}.jsonl\\',\\n        mode=\\'w\\'\\n    )\\n    file_handler.setFormatter(formatter)\\n    logger.setLevel(logging.INFO)\\n    logger.addHandler(file_handler)\\n    return logger\\n',\n",
       "  'function_name': 'setup_logger',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/utils.py'},\n",
       " {'code': 'def generate_mturk_code(session_id: str) -> str:\\n    \"\"\"Generates a redeem code corresponding to the session ID for an MTurk\\n    worker once the session is completed\\n    \"\"\"\\n    sha = hashlib.sha1(session_id.encode())\\n    return sha.hexdigest()[:10].upper()',\n",
       "  'function_name': 'generate_mturk_code',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/utils.py'},\n",
       " {'code': 'def annotate(attr_path):\\n    with open(attr_path) as f:\\n        attrs_by_cat = yaml.safe_load(f)\\n\\n    unique_attrs = set()\\n    all_attrs = []\\n    for _, attrs in attrs_by_cat.items():\\n        attrs = [a.split(\\'|\\')[0].strip() for a in attrs]\\n        unique_attrs.update(attrs)\\n        all_attrs += attrs\\n    print(f\\'Total unique attributes: {len(unique_attrs)}\\')\\n    total = len(all_attrs)\\n    num_left = len(all_attrs)\\n\\n    annotated_attrs_by_cat = dict()\\n    for category, attrs in attrs_by_cat.items():\\n        print(\\n            f\\'Category: [ {category} ] | \\'\\n            f\\'Number of attributes: {len(attrs)}\\\\n\\'\\n        )\\n        annotated_attrs = []\\n        for i, attr in enumerate(attrs):\\n            attr, score = attr.split(\\' | \\')\\n            print(\\n                f\\'{\"[\" + str(i) + \"]\":<5} \\'\\n                f\\'[bold green]{attr:<30}[/bold green] | \\'\\n                f\\'[red]{category}[/red] | \\'\\n                f\\'{score}\\'\\n            )\\n            tags = input(\\n                \\'Annotate [1: ITEM, 2: PROP, 3: USE, \\'\\n                \\'⎵: next example, q: next category] > \\'\\n            )\\n            print(\\'\\\\n\\')\\n            tags = tags.strip()\\n            annotated_attrs.append(f\\'{attr} | {score} | {tags}\\')\\n            if \\'q\\' in tags:\\n                break\\n        \\n        num_left -= len(attrs)\\n        print(f\\'{num_left} / {total} total attributes left.\\')\\n\\n        ans = input(\\'Starting the next category... [y/n] > \\')\\n        if ans == \\'n\\':\\n            break\\n',\n",
       "  'function_name': 'annotate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/annotate.py'},\n",
       " {'code': 'def main():\\n    for attr_path in ATTR_PATHS:\\n        annotate(attr_path)\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/annotate.py'},\n",
       " {'code': 'def get_stop_words():\\n    extra_stop_words = set([str(i) for i in range(1000)])\\n    stop_words = sk_text.ENGLISH_STOP_WORDS.union(extra_stop_words)\\n    return stop_words\\n\\n',\n",
       "  'function_name': 'get_stop_words',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': 'def load_products(num=None):\\n    \"\"\"\\n    Loads products from the `items.json` file and combine them with reviews\\n    through `asin`.\\n    Return: dict[asin, product]\\n    \"\"\"\\n    with open(ITEMS_PATH) as f:\\n        all_products = json.load(f)\\n        if num is not None:\\n            random.shuffle(all_products)\\n            all_products = all_products[:num]\\n        products = dict()\\n        asins = set()\\n        for p in all_products:\\n            asin = p[\\'asin\\']\\n            if asin in asins:\\n                continue\\n            asins.add(asin)\\n            products[asin] = p\\n\\n    with open(REVIEWS_PATH) as f:\\n        reviews = json.load(f)\\n        reviews = {r[\\'asin\\']: r for r in reviews}\\n\\n    for asin, p in products.items():\\n        if asin in reviews:\\n            p[\\'review\\'] = reviews[asin]\\n        else:\\n            p[\\'review\\'] = None\\n    return products\\n\\n',\n",
       "  'function_name': 'load_products',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': \"def get_top_attrs(attributes, k):\\n    attr_to_asins = defaultdict(list)\\n\\n    for asin, attr_scores in attributes.items():\\n        top_attr_scoress = attr_scores[:k]\\n        for attr, score in top_attr_scoress:\\n            attr_to_asins[attr].append(asin)\\n    total = len([asin for asin, _ in attributes.items()])\\n    \\n    top_attrs = [\\n        (attr, len(asins) / total)\\n        for attr, asins in attr_to_asins.items()\\n    ]\\n    top_attrs = sorted(top_attrs, key=lambda x: -x[1])\\n    top_attrs = [f'{attr} | {score:.4f}' for attr, score in top_attrs]\\n    return top_attrs\\n\\n\",\n",
       "  'function_name': 'get_top_attrs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': 'def get_corpus(\\n        products,\\n        keys=(\\'name\\', \\'small_description\\'),\\n        category_type=\\'category\\'\\n    ):\\n    \"\"\"\\n    keys: `name`, `small_description`, `review`\\n    category_type: `category`, `query`\\n    \"\"\"\\n    all_products = list(products.values())\\n    \\n    asins_by_cat = defaultdict(set)\\n    corpus_by_cat = defaultdict(list)\\n    for p in all_products:\\n        category = p[category_type]\\n        asin = p[\\'asin\\']\\n        if asin in asins_by_cat[category]:\\n            continue\\n        asins_by_cat[category].add(asin)\\n\\n        text = []\\n        for key in keys:\\n            if key == \\'review\\':\\n                rs = p[\\'review\\'][\\'reviews\\']\\n                if r is not None:\\n                    text_ = \\' \\'.join([r[\\'review\\'].lower() for r in rs])\\n                else:\\n                    text_ = \\'\\'\\n            else:\\n                text_ = p[key].lower()\\n            text.append(text_)\\n        text = \\' \\'.join(text)\\n        corpus_by_cat[category].append((asin, text))\\n    return corpus_by_cat\\n\\n',\n",
       "  'function_name': 'get_corpus',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': 'def generate_ngram_attrs(corpus_by_cat, ngram_range, k, attrs):\\n    vectorizer = TfidfVectorizer(\\n        stop_words=get_stop_words(),\\n        ngram_range=ngram_range,\\n        max_features=1000,\\n    )\\n\\n    top_attrs_by_cat = dict()\\n    for category, corpus in tqdm(corpus_by_cat.items(),\\n                                 total=len(corpus_by_cat)):\\n        asins = [_[0] for _ in corpus]\\n        texts = [_[1] for _ in corpus]\\n        vec = vectorizer.fit_transform(texts).todense()\\n        df = pd.DataFrame(vec, columns=vectorizer.get_feature_names_out())\\n\\n        attrs_by_cat = dict()\\n        for asin, (row_name, row) in zip(asins, df.iterrows()):\\n            attr_scores = sorted(\\n                list(zip(row.index, row)),\\n                key=lambda x: -x[1]\\n            )\\n            attrs_by_cat[asin] = attr_scores\\n            attrs[asin] = attr_scores\\n        top_attrs_by_cat[category.lower()] = get_top_attrs(attrs_by_cat, k=k)\\n    print(top_attrs_by_cat.keys())\\n    return top_attrs_by_cat\\n\\n',\n",
       "  'function_name': 'generate_ngram_attrs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': \"def generate_attrs(corpus_by_cat, k, save_name):\\n    attrs = dict()\\n    for n in range(1, 3):\\n        ngram_range = (n, n)\\n        top_attrs_by_cat = \\\\\\n            generate_ngram_attrs(corpus_by_cat, ngram_range, k, attrs)\\n\\n        if save_name is not None:\\n            save_path = Path(ATTR_DIR) / f'{save_name}_{n}-gram.yaml'\\n            with open(save_path, 'w') as f:\\n                yaml.dump(top_attrs_by_cat, f, default_flow_style=False)\\n            print(f'Saved: {save_path}')\\n\\n    save_path = Path(ATTR_DIR) / f'{save_name}_attrs_unfiltered.json'\\n    with open(save_path, 'w') as f:\\n        json.dump(attrs, f)\\n    print(f'Saved: {save_path}')\\n\\n\",\n",
       "  'function_name': 'generate_attrs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/attributes/generate_attrs.py'},\n",
       " {'code': 'def tag_visible(element):\\n    \"\"\"Helper method to strip HTML block of extraneous tags\"\"\"\\n    ignore = {\\'style\\', \\'script\\', \\'head\\', \\'title\\', \\'meta\\', \\'[document]\\'}\\n    return (\\n        element.parent.name not in ignore and not isinstance(element, Comment)\\n    )\\n',\n",
       "  'function_name': 'tag_visible',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/envs/web_agent_site_env.py'},\n",
       " {'code': \"def tag_visible(element):\\n    ignore = {'style', 'script', 'head', 'title', 'meta', '[document]'}\\n    return (\\n        element.parent.name not in ignore and not isinstance(element, Comment)\\n    )\\n\\n\",\n",
       "  'function_name': 'tag_visible',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/envs/web_agent_text_env.py'},\n",
       " {'code': \"def map_action_to_html(action, **kwargs):\\n    action_name, action_arg = parse_action(action)\\n    if action_name == 'start':\\n        path = os.path.join(TEMPLATE_DIR, 'search_page.html')\\n        html = render_template_string(\\n            read_html_template(path=path),\\n            session_id=kwargs['session_id'],\\n            instruction_text=kwargs['instruction_text'],\\n        )\\n    elif action_name == 'search':\\n        path = os.path.join(TEMPLATE_DIR, 'results_page.html')\\n        html = render_template_string(\\n            read_html_template(path=path),\\n            session_id=kwargs['session_id'],\\n            products=kwargs['products'],\\n            keywords=kwargs['keywords'],\\n            page=kwargs['page'],\\n            total=kwargs['total'],\\n            instruction_text=kwargs['instruction_text'],\\n        )\\n    elif action_name == 'click' and action_arg == END_BUTTON:\\n        path = os.path.join(TEMPLATE_DIR, 'done_page.html')\\n        html = render_template_string(\\n            read_html_template(path),\\n            session_id=kwargs['session_id'],\\n            reward=kwargs['reward'],\\n            asin=kwargs['asin'],\\n            options=kwargs['options'],\\n            reward_info=kwargs.get('reward_info'),\\n            goal_attrs=kwargs.get('goal_attrs'),\\n            purchased_attrs=kwargs.get('purchased_attrs'),\\n            goal=kwargs.get('goal'),\\n            mturk_code=kwargs.get('mturk_code'),\\n            query=kwargs.get('query'),\\n            category=kwargs.get('category'),\\n            product_category=kwargs.get('product_category'),\\n        )\\n    elif action_name == 'click' and action_arg in ACTION_TO_TEMPLATE:\\n        path = os.path.join(TEMPLATE_DIR, ACTION_TO_TEMPLATE[action_arg])\\n        html = render_template_string(\\n            read_html_template(path),\\n            session_id=kwargs['session_id'],\\n            product_info=kwargs['product_info'],\\n            keywords=kwargs['keywords'],\\n            page=kwargs['page'],\\n            asin=kwargs['asin'],\\n            options=kwargs['options'],\\n            instruction_text=kwargs.get('instruction_text')\\n        )\\n    elif action_name == 'click':\\n        path = os.path.join(TEMPLATE_DIR, 'item_page.html')\\n        html = render_template_string(\\n            read_html_template(path),\\n            session_id=kwargs['session_id'],\\n            product_info=kwargs['product_info'],\\n            keywords=kwargs['keywords'],\\n            page=kwargs['page'],\\n            asin=kwargs['asin'],\\n            options=kwargs['options'],\\n            instruction_text=kwargs.get('instruction_text'),\\n            show_attrs=kwargs['show_attrs']\\n        )\\n    else:\\n        raise ValueError('Action name not recognized.')\\n    return html\\n\\n\",\n",
       "  'function_name': 'map_action_to_html',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': 'def read_html_template(path):\\n    with open(path) as f:\\n        template = f.read()\\n    return template\\n\\n',\n",
       "  'function_name': 'read_html_template',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': 'def parse_action(action):\\n    \"\"\"\\n    Parse action string to action name and its arguments.\\n    \"\"\"\\n    pattern = re.compile(r\\'(.+)\\\\[(.+)\\\\]\\')\\n    m = re.match(pattern, action)\\n    if m is None:\\n        action_name = action\\n        action_arg = None\\n    else:\\n        action_name, action_arg = m.groups()\\n    return action_name, action_arg\\n\\n',\n",
       "  'function_name': 'parse_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': \"def convert_web_app_string_to_var(name, string):\\n    if name == 'keywords':\\n        keywords = string\\n        if keywords.startswith('['):\\n            keywords = literal_eval(keywords)\\n        else:\\n            keywords = [keywords]\\n        var = keywords\\n    elif name == 'page':\\n        page = string\\n        page = int(page)\\n        var = page\\n    else:\\n        raise ValueError('Name of variable not recognized.')\\n    return var\\n\\n\",\n",
       "  'function_name': 'convert_web_app_string_to_var',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': \"def get_top_n_product_from_keywords(\\n        keywords,\\n        search_engine,\\n        all_products,\\n        product_item_dict,\\n        attribute_to_asins=None,\\n    ):\\n    if keywords[0] == '<r>':\\n        top_n_products = random.sample(all_products, k=SEARCH_RETURN_N)\\n    elif keywords[0] == '<a>':\\n        attribute = ' '.join(keywords[1:]).strip()\\n        asins = attribute_to_asins[attribute]\\n        top_n_products = [p for p in all_products if p['asin'] in asins]\\n    elif keywords[0] == '<c>':\\n        category = keywords[1].strip()\\n        top_n_products = [p for p in all_products if p['category'] == category]\\n    elif keywords[0] == '<q>':\\n        query = ' '.join(keywords[1:]).strip()\\n        top_n_products = [p for p in all_products if p['query'] == query]\\n    else:\\n        keywords = ' '.join(keywords)\\n        hits = search_engine.search(keywords, k=SEARCH_RETURN_N)\\n        docs = [search_engine.doc(hit.docid) for hit in hits]\\n        top_n_asins = [json.loads(doc.raw())['id'] for doc in docs]\\n        top_n_products = [product_item_dict[asin] for asin in top_n_asins if asin in product_item_dict]\\n    return top_n_products\\n\\n\",\n",
       "  'function_name': 'get_top_n_product_from_keywords',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': 'def get_product_per_page(top_n_products, page):\\n    return top_n_products[(page - 1) * PRODUCT_WINDOW:page * PRODUCT_WINDOW]\\n\\n',\n",
       "  'function_name': 'get_product_per_page',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': \"def generate_product_prices(all_products):\\n    product_prices = dict()\\n    for product in all_products:\\n        asin = product['asin']\\n        pricing = product['pricing']\\n        if not pricing:\\n            price = 100.0\\n        elif len(pricing) == 1:\\n            price = pricing[0]\\n        else:\\n            price = random.uniform(*pricing[:2])\\n        product_prices[asin] = price\\n    return product_prices\\n\\n\",\n",
       "  'function_name': 'generate_product_prices',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': \"def init_search_engine(num_products=None):\\n    if num_products == 100:\\n        indexes = 'indexes_100'\\n    elif num_products == 1000:\\n        indexes = 'indexes_1k'\\n    elif num_products == 100000:\\n        indexes = 'indexes_100k'\\n    elif num_products is None:\\n        indexes = 'indexes'\\n    else:\\n        raise NotImplementedError(f'num_products being {num_products} is not supported yet.')\\n    search_engine = LuceneSearcher(os.path.join(BASE_DIR, f'../search_engine/{indexes}'))\\n    return search_engine\\n\\n\",\n",
       "  'function_name': 'init_search_engine',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': \"def clean_product_keys(products):\\n    for product in products:\\n        product.pop('product_information', None)\\n        product.pop('brand', None)\\n        product.pop('brand_url', None)\\n        product.pop('list_price', None)\\n        product.pop('availability_quantity', None)\\n        product.pop('availability_status', None)\\n        product.pop('total_reviews', None)\\n        product.pop('total_answered_questions', None)\\n        product.pop('seller_id', None)\\n        product.pop('seller_name', None)\\n        product.pop('fulfilled_by_amazon', None)\\n        product.pop('fast_track_message', None)\\n        product.pop('aplus_present', None)\\n        product.pop('small_description_old', None)\\n    print('Keys cleaned.')\\n    return products\\n\\n\",\n",
       "  'function_name': 'clean_product_keys',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': 'def load_products(filepath, num_products=None, human_goals=True):\\n    # TODO: move to preprocessing step -> enforce single source of truth\\n    with open(filepath) as f:\\n        products = json.load(f)\\n    print(\\'Products loaded.\\')\\n    products = clean_product_keys(products)\\n    \\n    # with open(DEFAULT_REVIEW_PATH) as f:\\n    #     reviews = json.load(f)\\n    all_reviews = dict()\\n    all_ratings = dict()\\n    # for r in reviews:\\n    #     all_reviews[r[\\'asin\\']] = r[\\'reviews\\']\\n    #     all_ratings[r[\\'asin\\']] = r[\\'average_rating\\']\\n\\n    if human_goals:\\n        with open(HUMAN_ATTR_PATH) as f:\\n            human_attributes = json.load(f)\\n    with open(DEFAULT_ATTR_PATH) as f:\\n        attributes = json.load(f)\\n    with open(HUMAN_ATTR_PATH) as f:\\n        human_attributes = json.load(f)\\n    print(\\'Attributes loaded.\\')\\n\\n    asins = set()\\n    all_products = []\\n    attribute_to_asins = defaultdict(set)\\n    if num_products is not None:\\n        # using item_shuffle.json, we assume products already shuffled\\n        products = products[:num_products]\\n    for i, p in tqdm(enumerate(products), total=len(products)):\\n        asin = p[\\'asin\\']\\n        if asin == \\'nan\\' or len(asin) > 10:\\n            continue\\n\\n        if asin in asins:\\n            continue\\n        else:\\n            asins.add(asin)\\n\\n        products[i][\\'category\\'] = p[\\'category\\']\\n        products[i][\\'query\\'] = p[\\'query\\']\\n        products[i][\\'product_category\\'] = p[\\'product_category\\']\\n\\n        products[i][\\'Title\\'] = p[\\'name\\']\\n        products[i][\\'Description\\'] = p[\\'full_description\\']\\n        products[i][\\'Reviews\\'] = all_reviews.get(asin, [])\\n        products[i][\\'Rating\\'] = all_ratings.get(asin, \\'N.A.\\')\\n        for r in products[i][\\'Reviews\\']:\\n            if \\'score\\' not in r:\\n                r[\\'score\\'] = r.pop(\\'stars\\')\\n            if \\'review\\' not in r:\\n                r[\\'body\\'] = \\'\\'\\n            else:\\n                r[\\'body\\'] = r.pop(\\'review\\')\\n        products[i][\\'BulletPoints\\'] = p[\\'small_description\\'] \\\\\\n            if isinstance(p[\\'small_description\\'], list) else [p[\\'small_description\\']]\\n\\n        pricing = p.get(\\'pricing\\')\\n        if pricing is None or not pricing:\\n            pricing = [100.0]\\n            price_tag = \\'$100.0\\'\\n        else:\\n            pricing = [\\n                float(Decimal(re.sub(r\\'[^\\\\d.]\\', \\'\\', price)))\\n                for price in pricing.split(\\'$\\')[1:]\\n            ]\\n            if len(pricing) == 1:\\n                price_tag = f\"${pricing[0]}\"\\n            else:\\n                price_tag = f\"${pricing[0]} to ${pricing[1]}\"\\n                pricing = pricing[:2]\\n        products[i][\\'pricing\\'] = pricing\\n        products[i][\\'Price\\'] = price_tag\\n\\n        options = dict()\\n        customization_options = p[\\'customization_options\\']\\n        option_to_image = dict()\\n        if customization_options:\\n            for option_name, option_contents in customization_options.items():\\n                if option_contents is None:\\n                    continue\\n                option_name = option_name.lower()\\n\\n                option_values = []\\n                for option_content in option_contents:\\n                    option_value = option_content[\\'value\\'].strip().replace(\\'/\\', \\' | \\').lower()\\n                    option_image = option_content.get(\\'image\\', None)\\n\\n                    option_values.append(option_value)\\n                    option_to_image[option_value] = option_image\\n                options[option_name] = option_values\\n        products[i][\\'options\\'] = options\\n        products[i][\\'option_to_image\\'] = option_to_image\\n\\n        # without color, size, price, availability\\n        # if asin in attributes and \\'attributes\\' in attributes[asin]:\\n        #     products[i][\\'Attributes\\'] = attributes[asin][\\'attributes\\']\\n        # else:\\n        #     products[i][\\'Attributes\\'] = [\\'DUMMY_ATTR\\']\\n        # products[i][\\'instruction_text\\'] = \\\\\\n        #     attributes[asin].get(\\'instruction\\', None)\\n        # products[i][\\'instruction_attributes\\'] = \\\\\\n        #     attributes[asin].get(\\'instruction_attributes\\', None)\\n\\n        # without color, size, price, availability\\n        if asin in attributes and \\'attributes\\' in attributes[asin]:\\n            products[i][\\'Attributes\\'] = attributes[asin][\\'attributes\\']\\n        else:\\n            products[i][\\'Attributes\\'] = [\\'DUMMY_ATTR\\']\\n            \\n        if human_goals:\\n            if asin in human_attributes:\\n                products[i][\\'instructions\\'] = human_attributes[asin]\\n        else:\\n            products[i][\\'instruction_text\\'] = \\\\\\n                attributes[asin].get(\\'instruction\\', None)\\n\\n            products[i][\\'instruction_attributes\\'] = \\\\\\n                attributes[asin].get(\\'instruction_attributes\\', None)\\n\\n        products[i][\\'MainImage\\'] = p[\\'images\\'][0]\\n        products[i][\\'query\\'] = p[\\'query\\'].lower().strip()\\n\\n        all_products.append(products[i])\\n\\n    for p in all_products:\\n        for a in p[\\'Attributes\\']:\\n            attribute_to_asins[a].add(p[\\'asin\\'])\\n\\n    product_item_dict = {p[\\'asin\\']: p for p in all_products}\\n    product_prices = generate_product_prices(all_products)\\n    return all_products, product_item_dict, product_prices, attribute_to_asins\\n',\n",
       "  'function_name': 'load_products',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/engine.py'},\n",
       " {'code': 'def get_goals(all_products, product_prices, human_goals=True):\\n    if human_goals:\\n        return get_human_goals(all_products, product_prices)\\n    else:\\n        return get_synthetic_goals(all_products, product_prices)\\n    ',\n",
       "  'function_name': 'get_goals',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': \"def get_human_goals(all_products, product_prices):\\n    goals = []\\n    cnt_atts = defaultdict(int)\\n    cnt = 0\\n    for item in all_products:\\n        asin = item['asin']\\n        if 'instructions' not in item: continue\\n        for product in item['instructions']:\\n            attributes = product['instruction_attributes']\\n            if len(attributes) == 0: \\n                cnt += 1\\n                continue\\n\\n            if product_prices is not None:\\n                price = product_prices[asin]\\n                price_range = [p for p in PRICE_RANGE if p > price][:4]\\n                if len(price_range) >= 2:\\n                    _, price_upper = sorted(random.sample(price_range, 2))\\n                    price_text = \\\\\\n                        f', and price lower than {price_upper:.2f} dollars'\\n                else:\\n                    price_upper = 1000000\\n                    price_text = ''\\n            else:\\n                price_upper = 1000000\\n\\n            goals.append({\\n                'asin': asin,\\n                'category': item['category'],\\n                'query': item['query'],\\n                'name': item['name'],\\n                'product_category': item['product_category'],\\n                'instruction_text': product['instruction'].strip('.') + price_text,\\n                'attributes': attributes,\\n                'price_upper': price_upper,\\n                'goal_options': product['instruction_options'],\\n            })\\n            for att in attributes:\\n                cnt_atts[att] += 1\\n            # goals += product_goals\\n    for goal in goals:\\n        goal['weight'] = 1\\n    print(cnt, 'skipped')\\n    return goals\\n\\n\",\n",
       "  'function_name': 'get_human_goals',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': \"def get_synthetic_goals(all_products, product_prices):\\n    goals = []\\n    cnt_atts = defaultdict(int)\\n    for product in all_products:\\n        if ('instruction_text' not in product or \\n            product['instruction_text'] is None):\\n            continue\\n        product_goals = []        \\n        asin = product['asin']\\n        attributes = product['instruction_attributes']\\n        assert len(attributes) > 0\\n\\n        if product_prices is not None:\\n            price = product_prices[asin]\\n            price_range = [p for p in PRICE_RANGE if p > price][:4]\\n            if len(price_range) >= 2:\\n                _, price_upper = sorted(random.sample(price_range, 2))\\n                price_text = \\\\\\n                    f', and price lower than {price_upper:.2f} dollars'\\n            else:\\n                price_upper = 1000000\\n                price_text = ''\\n        else:\\n            price_upper = 1000000\\n            price_text = ''\\n\\n        instruction_text = product['instruction_text']\\n\\n        options = product['options']\\n        option_names = sorted(options)\\n        combinations = list(itertools.product(\\n            *(options[option_name] for option_name in option_names)\\n        ))\\n        for combination in combinations:\\n            goal_options = dict()\\n            for i, o in enumerate(combination):\",\n",
       "  'function_name': 'get_synthetic_goals',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': 'def get_type_reward(purchased_product, goal):\\n    \"\"\"Determines the type reward - captures whether chosen product is in the same category\"\"\"\\n    query_match = purchased_product[\\'query\\'] == goal[\\'query\\']\\n\\n    # Check number of unique categories that match, ignoring order\\n    purchased_product_category = [x.strip() for x in purchased_product[\\'product_category\\'].split(\\'›\\')]\\n    goal_product_category = [x.strip() for x in goal[\\'product_category\\'].split(\\'›\\')]\\n    category_match = len(set(purchased_product_category) & set(goal_product_category)) >= 2\\n\\n    # Determine whether types align based on product name similarity\\n    purchased_type = purchased_product[\\'name\\']\\n    desired_type = goal[\\'name\\']\\n\\n    purchased_type_parse = nlp(purchased_type)\\n    desired_type_parse = nlp(desired_type)\\n\\n    purchased_type_parse = [t.text.lower() for t in purchased_type_parse if t.pos_ in (\\'PNOUN\\', \\'NOUN\\', \\'PROPN\\')]\\n    desired_type_parse = [t.text.lower() for t in desired_type_parse if t.pos_ in (\\'PNOUN\\', \\'NOUN\\', \\'PROPN\\')]\\n\\n    n_intersect_type = len(\\n        set(purchased_type_parse) & set(desired_type_parse)\\n    )\\n    if len(desired_type_parse) == 0:\\n        title_score = 0.2\\n    else:\\n        title_score = n_intersect_type / len(desired_type_parse)\\n\\n    r_type = 1.0\\n\\n    # Adjust r_type score based on query, category title matching/scores\\n    match = query_match or category_match or title_score > 0.2\\n    if not match:\\n        r_type = 0.5\\n\\n    if title_score < 0.1:\\n        r_type = 0.1\\n    \\n    if title_score == 0.0:\\n        r_type = 0.0\\n\\n    return dict(\\n        r_type=r_type,\\n        query_match=query_match,\\n        category_match=category_match,\\n        title_score=title_score,\\n    )\\n\\n',\n",
       "  'function_name': 'get_type_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': 'def get_attribute_reward(purchased_product, goal):\\n    \"\"\"Determines whether purchased products shares same attributes as goal\"\"\"\\n    purchased_attrs = purchased_product[\\'Attributes\\']\\n    goal_attrs = goal[\\'attributes\\']\\n\\n    num_attr_matches = 0\\n    for g_attr in goal_attrs:\\n        matched = False\\n        # Check whether goal attribute found in purchased product attribute list\\n        for p_attr in purchased_attrs:\\n            score = fuzz.token_set_ratio(p_attr, g_attr)\\n            if score > 85:\\n                num_attr_matches += 1\\n                matched = True\\n                break\\n        # If not in purchased attrs, check Title, Bullet Points (Features), Desc\\n        if (\\n            not matched and\\n            (\\n                g_attr in purchased_product[\\'Title\\'].lower() or\\n                g_attr in \\' \\'.join(purchased_product[\\'BulletPoints\\']).lower() or\\n                g_attr in purchased_product[\\'Description\\'].lower()\\n            )\\n        ):\\n            num_attr_matches += 1\\n            matched = True\\n    \\n    r_attr = num_attr_matches / len(goal_attrs)\\n    return r_attr, num_attr_matches\\n\\n',\n",
       "  'function_name': 'get_attribute_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': 'def get_option_reward(purchased_options, goal_options):\\n    \"\"\"Calculate reward for purchased product\\'s options w.r.t. goal options\"\"\"\\n    purchased_options = [normalize_color(o) for o in purchased_options]\\n    goal_options = [normalize_color(o) for o in goal_options]\\n\\n    # Perform fuzzy matching of each purchased option against each goal option\\n    num_option_matches = 0\\n    for g_option in goal_options:\\n        for p_option in purchased_options:\\n            score = fuzz.token_set_ratio(p_option, g_option)\\n            if score > 85:\\n                num_option_matches += 1\\n                break\\n    \\n    # Calculate option reward as fraction of goal options hit\\n    r_option = num_option_matches / len(goal_options) if len(goal_options) > 0 else None\\n    return r_option, num_option_matches\\n\\n',\n",
       "  'function_name': 'get_option_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': 'def get_reward(purchased_product, goal, price, options, **kwargs):\\n    \"\"\"Get cumulative reward score for purchased product and goal\"\"\"\\n    r_type_dict = get_type_reward(purchased_product, goal)\\n\\n    r_price = (\\n        price <= goal[\\'price_upper\\']\\n    ) if goal[\\'price_upper\\'] > 0 else None\\n\\n    r_att, num_attr_matches = get_attribute_reward(purchased_product, goal)\\n\\n    r_option, num_option_matches = get_option_reward(\\n        list(options.values()),\\n        goal[\\'goal_options\\'].items()\\n        if isinstance(goal[\\'goal_options\\'], dict)\\n        else goal[\\'goal_options\\']\\n    )\\n\\n    total_reward = (\\n        (num_attr_matches + num_option_matches + r_price) \\\\\\n            / (len(goal[\\'attributes\\']) + len(goal[\\'goal_options\\']) + 1)\\n    )\\n\\n    total_reward *= r_type_dict[\\'r_type\\']\\n\\n    # If verbose flag enabled, store score sub-components into dictionary\\n    if kwargs.get(\\'verbose\\', False):\\n        info =  {\\n            \\'r_type\\': r_type_dict[\\'r_type\\'],\\n            \\'r_att\\': r_att,\\n            \\'w_att\\': len(goal[\\'attributes\\']) / (len(goal[\\'attributes\\']) + len(goal[\\'goal_options\\']) + 1),\\n            \\'query_match\\': r_type_dict[\\'query_match\\'],\\n            \\'category_match\\': r_type_dict[\\'category_match\\'],\\n            \\'title_score\\': r_type_dict[\\'title_score\\'],\\n        }\\n        if r_option is not None:\\n            info[\\'r_option\\'] = r_option\\n            info[\\'w_option\\'] = len(goal[\\'goal_options\\']) / (len(goal[\\'attributes\\']) + len(goal[\\'goal_options\\']) + 1)\\n        if r_price is not None:\\n            info[\\'r_price\\'] = r_price\\n            info[\\'w_price\\'] = 1 / (len(goal[\\'attributes\\']) + len(goal[\\'goal_options\\']) + 1)\\n        return total_reward, info\\n    return total_reward\\n',\n",
       "  'function_name': 'get_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/goal.py'},\n",
       " {'code': 'def normalize_color(color_string: str) -> str:\\n    \"\"\"Extracts the first color found if exists\"\"\"\\n    for norm_color in COLOR_SET:\\n        if norm_color in color_string:\\n            return norm_color\\n    return color_string\\n',\n",
       "  'function_name': 'normalize_color',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/normalize.py'},\n",
       " {'code': 'def normalize_color_size(product_prices: dict) -> Tuple[dict, dict]:\\n    \"\"\"Get mappings of all colors, sizes to corresponding values in COLOR_SET, SIZE_PATTERNS\"\"\"\\n    \\n    # Get all colors, sizes from list of all products\\n    all_colors, all_sizes = set(), set()\\n    for (_, color, size), _ in product_prices.items():\\n        all_colors.add(color.lower())\\n        all_sizes.add(size.lower())\\n    \\n    # Create mapping of each original color value to corresponding set value\\n    color_mapping = {\\'N.A.\\': \\'not_matched\\'} \\n    for c in all_colors:\\n        matched = False\\n        for base in COLOR_SET:\\n            if base in c:\\n                color_mapping[c] = base\\n                matched = True\\n                break\\n        if not matched:\\n            color_mapping[c] = \\'not_matched\\'\\n\\n    # Create mapping of each original size value to corresponding set value\\n    size_mapping = {\\'N.A.\\': \\'not_matched\\'}\\n    for s in all_sizes:\\n        matched = False\\n        for pattern in SIZE_PATTERNS:\\n            m = re.search(pattern, s)\\n            if m is not None:\\n                matched = True\\n                size_mapping[s] = pattern.pattern\\n                break\\n        if not matched:\\n            if s.replace(\\'.\\', \\'\\', 1).isdigit():\\n                size_mapping[s] = \\'numeric_size\\'\\n                matched= True\\n        if not matched:\\n            size_mapping[s] = \\'not_matched\\'\\n    \\n    return color_mapping, size_mapping\\n    \\n',\n",
       "  'function_name': 'normalize_color_size',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/web_agent_site/engine/normalize.py'},\n",
       " {'code': 'def worker(log_file, idx, rnge):\\n    with InteractionLog(log_file, idx):\\n        env = WebAgentTextEnv(observation_mode=\"text\", human_goals=True)\\n        print(\"total goals:\", len(env.server.goals))\\n        print(\"ranging:\", rnge)\\n        scores = []\\n        for i in range(*rnge):\\n            env.reset(i)\\n            print(f\"=== Episode #{i} ===\")\\n\\n            policy = eval(model_exec)\\n\\n            observation = env.observation\\n            for j in range(100):\\n                print(observation)\\n                available_actions = env.get_available_actions()\\n                print(\\'Available actions:\\', available_actions)\\n                action = policy.forward(observation, available_actions)\\n                if not action:\\n                    reward = 0\\n                    break\\n                observation, reward, done, info = env.step(action)\\n                print(f\\'Taking action \"{escape(action)}\" -> Reward = {reward}\\')\\n                if done:\\n                    break\\n            else:\\n                reward = 0\\n            print(f\"#{i} {reward}\")\\n            scores.append(reward)\\n\\n        print(f\"#Average: {sum(scores) / len(scores)}\")\\n\\n',\n",
       "  'function_name': 'worker',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/run_envs/run_web_agent_text_env.py'},\n",
       " {'code': 'def discount_reward(transitions, last_values, gamma):\\n    returns, advantages = [], []\\n    R = last_values.detach()  # always detached\\n    for t in reversed(range(len(transitions))):\\n        _, _, rewards, values, _, dones = transitions[t]\\n        R = torch.FloatTensor(rewards).to(device) + gamma * R * (1 - torch.FloatTensor(dones).to(device))\\n        baseline = values\\n        adv = R - baseline\\n        returns.append(R)\\n        advantages.append(adv)\\n    return returns[::-1], advantages[::-1]\\n\\n',\n",
       "  'function_name': 'discount_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/agent.py'},\n",
       " {'code': 'def process_str(s):\\n    s = s.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\").strip()\\n    return s\\n\\n',\n",
       "  'function_name': 'process_str',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_search_il.py'},\n",
       " {'code': 'def process_goal(state):\\n    state = state.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\")\\n    state = state.replace(\\'amazon shopping game\\\\ninstruction:\\', \\'\\').replace(\\'webshop\\\\ninstruction:\\', \\'\\')\\n    state = state.replace(\\'\\\\n[button] search [button_]\\', \\'\\').strip()\\n    if \\', and price lower than\\' in state:\\n        state = state.split(\\', and price lower than\\')[0]\\n    return state\\n',\n",
       "  'function_name': 'process_goal',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_search_il.py'},\n",
       " {'code': 'def get_data(split):\\n    data = json.load(open(PATH))\\n    goals, searches = [], []\\n    for goal, search_list in data.items():\\n        goal = process_goal(goal)\\n        for search in search_list:\\n            search = process_str(search)\\n            goals.append(goal)\\n            searches.append(search)\\n    n = len(goals)\\n\\n    human_goals = json.load(open(HUMAN_GOAL_PATH, \\'r\\'))\\n    goal_range = range(len(human_goals))\\n    if split == \\'train\\':\\n        goal_range = range(500, len(human_goals))\\n    elif split == \\'validation\\':\\n        goal_range = range(500, 1500)\\n    elif split == \\'test\\':\\n        goal_range = range(0, 500)\\n    elif split == \"all\":  # all human instructions, but without groundtruth search queries\\n        all_data = json.load(open(GOAL_PATH))\\n        all_goals = []\\n        all_goals_processed = []\\n        for ins_list in all_data.values():\\n            for ins in ins_list:\\n                ins = ins[\\'instruction\\']\\n                all_goals.append(ins)\\n                all_goals_processed.append(process_str(ins))\\n        return all_goals_processed, all_goals\\n    \\n    goals_, searches_ = [], []\\n    for goal, search in zip(goals, searches):\\n        if goal in human_goals and human_goals.index(goal) in goal_range:\\n            goals_.append(goal)\\n            searches_.append(search)\\n    return goals_, searches_\\n\\n',\n",
       "  'function_name': 'get_data',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_search_il.py'},\n",
       " {'code': 'def get_dataset(name, flip=False, variant=None, size=None):\\n    fname = name + \"-flip\" if flip else name\\n    fpath = os.path.join(os.path.dirname(__file__), fname)\\n    d = {}\\n    splits = [\"train\", \"validation\", \"test\"]\\n    if name == \"web_search\":\\n        splits = [\"train\", \"validation\", \"test\", \"all\"]\\n    for split in splits:\\n        input, output = get_data(split) if name != \"nl2bash\" else get_data(\\n            split, variant=variant)\\n        l = len(input) if size is None else int(len(input) * size)\\n        print(\"{} size: {}\".format(split, l))\\n        if flip:\\n            input, output = output, input\\n        input, output = input[:l], output[:l]\\n        d[split] = process_dataset(input, output)\\n    d = DatasetDict(d)\\n    return d\\n\\n',\n",
       "  'function_name': 'get_dataset',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_search_il.py'},\n",
       " {'code': \"def process_dataset(input, output, max_len=256):\\n    input_encodings = tokenizer(input, padding='max_length',\\n                                max_length=max_len, truncation=True, return_tensors='pt')\\n    output_encodings = tokenizer(\\n        output, padding='max_length', max_length=max_len, truncation=True, return_tensors='pt')\\n    labels = output_encodings['input_ids']\\n    decoder_input_ids = shift_tokens_right(labels, PAD_TOKEN_ID, EOS_TOKEN_ID)\\n    labels[labels[:, :] == PAD_TOKEN_ID] = -100\\n    dataset = Dataset.from_dict({\\n        'input_ids': input_encodings['input_ids'],\\n        'attention_mask': input_encodings['attention_mask'],\\n        'decoder_input_ids': decoder_input_ids,\\n        'labels': labels,\\n    })\\n    dataset.set_format(type='torch', columns=[\\n                       'input_ids', 'labels', 'decoder_input_ids', 'attention_mask'])\\n    return dataset\\n\\n\",\n",
       "  'function_name': 'process_dataset',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_search_il.py'},\n",
       " {'code': \"def configure_logger(log_dir, wandb):\\n    logger.configure(log_dir, format_strs=['log'])\\n    global tb\\n    type_strs = ['json', 'stdout']\\n    if wandb: type_strs += ['wandb']\\n    tb = logger.Logger(log_dir, [logger.make_output_format(type_str, log_dir) for type_str in type_strs])\\n    global log\\n    log = logger.log\\n\\n\",\n",
       "  'function_name': 'configure_logger',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': 'def evaluate(agent, env, split, nb_episodes=10):\\n    with torch.no_grad():\\n        total_score = 0\\n        for method in [\\'greedy\\']:\\n            for ep in range(nb_episodes):\\n                log(\"Starting {} episode {}\".format(split, ep))\\n                if split == \\'eval\\':\\n                    score = evaluate_episode(agent, env, split, method)\\n                elif split == \\'test\\':\\n                    score = evaluate_episode(agent, env, split, method, idx=ep)\\n                log(\"{} episode {} ended with score {}\\\\n\\\\n\".format(split, ep, score))\\n                total_score += score\\n        avg_score = total_score / nb_episodes\\n        return avg_score\\n\\n',\n",
       "  'function_name': 'evaluate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': 'def evaluate_episode(agent, env, split, method=\\'greedy\\', idx=None):\\n    step = 0\\n    done = False\\n    ob, info = env.reset(idx)\\n    state = agent.build_state(ob, info)\\n    log(\\'Obs{}: {}\\'.format(step, ob.encode(\\'utf-8\\')))\\n    while not done:\\n        valid_acts = info[\\'valid\\']\\n        with torch.no_grad():\\n            action_str = agent.act([state], [valid_acts], method=method)[0][0]\\n        log(\\'Action{}: {}\\'.format(step, action_str))\\n        ob, rew, done, info = env.step(action_str)\\n        log(\"Reward{}: {}, Score {}, Done {}\".format(step, rew, info[\\'score\\'], done))\\n        step += 1\\n        log(\\'Obs{}: {}\\'.format(step, ob.encode(\\'utf-8\\')))\\n        state = agent.build_state(ob, info)\\n    tb.logkv_mean(f\\'{split}Score\\', info[\\'score\\'])\\n    # category = env.session[\\'goal\\'][\\'category\\']\\n    # tb.logkv_mean(f\\'{split}Score_{category}\\', rew)\\n    if \\'verbose\\' in info:\\n        for k, v in info[\\'verbose\\'].items():\\n            if k.startswith(\\'r\\'):\\n                tb.logkv_mean(f\\'{split}_\\' + k, v)\\n    return info[\\'score\\']\\n\\n',\n",
       "  'function_name': 'evaluate_episode',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': 'def agg(envs, attr):\\n    res = defaultdict(int)\\n    for env in envs:\\n        for k, v in getattr(env, attr).items():\\n            res[k] += v\\n    return res\\n\\n',\n",
       "  'function_name': 'agg',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': \"def train(agent, eval_env, test_env, envs, args):\\n    start = time.time()\\n    states, valids, transitions = [], [], []\\n    state0 = None\\n    for env in envs:\\n        ob, info = env.reset()\\n        if state0 is None:\\n            state0 = (ob, info)\\n        states.append(agent.build_state(ob, info))\\n        valids.append(info['valid'])\\n\\n    for step in range(1, args.max_steps + 1):\\n        # get actions from policy\\n        action_strs, action_ids, values = agent.act(states, valids, method=args.exploration_method)\\n        \\n        # log envs[0]\\n        with torch.no_grad():\\n            action_values, _ = agent.network.rl_forward(states[:1], agent.encode_valids(valids[:1]))\\n        actions = sorted(zip(state0[1]['valid'], action_values.tolist()), key=lambda x: - x[1])\\n        log('State  {}: {}'.format(step, state0[0].lower().encode('utf-8')))\\n        log('Goal   {}: {}'.format(step, state0[1]['goal'].lower().encode('utf-8')))\\n        log('Actions{}: {}'.format(step, actions))\\n        log('>> Values{}: {}'.format(step, float(values[0])))\\n        log('>> Action{}: {}'.format(step, action_strs[0]))\\n        state0 = None\\n\\n        # step in envs\\n        next_states, next_valids, rewards, dones = [], [], [], []\\n        for env, action_str, action_id, state in zip(envs, action_strs, action_ids, states):\\n            ob, reward, done, info = env.step(action_str)\\n            if state0 is None:  # first state\\n                state0 = (ob, info)\\n                r_att = r_opt = 0\\n                if 'verbose' in info:\\n                    r_att = info['verbose'].get('r_att', 0)\\n                    r_option = info['verbose'].get('r_option ', 0)\\n                    r_price = info['verbose'].get('r_price', 0)\\n                    r_type = info['verbose'].get('r_type', 0)\\n                    w_att = info['verbose'].get('w_att', 0)\\n                    w_option = info['verbose'].get('w_option', 0)\\n                    w_price = info['verbose'].get('w_price', 0)\\n                    reward_str = f'{reward/10:.2f} = ({r_att:.2f} * {w_att:.2f} + {r_option:.2f} * {w_option:.2f} + {r_price:.2f} * {w_price:.2f}) * {r_type:.2f}'\\n                else:\\n                    reward_str = str(reward)\\n                log('Reward{}: {}, Done {}\\\\n'.format(step, reward_str, done))\\n            next_state = agent.build_state(ob, info)\\n            next_valid = info['valid']\\n            next_states, next_valids, rewards, dones = \\\\\\n                next_states + [next_state], next_valids + [next_valid], rewards + [reward], dones + [done]\\n            if done:\\n                tb.logkv_mean('EpisodeScore', info['score'])\\n                category = env.session['goal']['category']\\n                tb.logkv_mean(f'EpisodeScore_{category}', info['score'])\\n                if 'verbose' in info:\\n                    for k, v in info['verbose'].items():\\n                        if k.startswith('r'):\\n                            tb.logkv_mean(k, v)\\n\\n        # RL update\\n        transitions.append(TransitionPG(states, action_ids, rewards, values, agent.encode_valids(valids), dones))\\n        if len(transitions) >= args.bptt:\\n            _, _, last_values = agent.act(next_states, next_valids, method='softmax')\\n            stats = agent.update(transitions, last_values, step=step)\\n            for k, v in stats.items():\\n                tb.logkv_mean(k, v)\\n            del transitions[:]\\n            torch.cuda.empty_cache()\\n\\n        # handle done\\n        for i, env in enumerate(envs):\\n            if dones[i]:               \\n                ob, info = env.reset()\\n                if i == 0:\\n                    state0 = (ob, info)\\n                next_states[i] = agent.build_state(ob, info)\\n                next_valids[i] = info['valid']\\n        states, valids = next_states, next_valids\\n\\n        if step % args.eval_freq == 0:\\n            evaluate(agent, eval_env, 'eval')\\n\\n        if step % args.test_freq == 0:\\n            evaluate(agent, test_env, 'test', 500)\\n\\n        if step % args.log_freq == 0:\\n            tb.logkv('Step', step)\\n            tb.logkv('FPS', int((step * len(envs)) / (time.time() - start)))\\n            for k, v in agg(envs, 'stats').items():\\n                tb.logkv(k, v)\\n            items_clicked = agg(envs, 'items_clicked')\\n            tb.logkv('ItemsClicked', len(items_clicked))\\n            tb.dumpkvs()\\n\\n        if step % args.ckpt_freq == 0:\\n            agent.save()\\n\\n\",\n",
       "  'function_name': 'train',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': 'def parse_args():\\n    parser = argparse.ArgumentParser()\\n    # logging\\n    parser.add_argument(\\'--seed\\', default=0, type=int)\\n    parser.add_argument(\\'--output_dir\\', default=\\'logs\\')\\n    parser.add_argument(\\'--ckpt_freq\\', default=10000, type=int)\\n    parser.add_argument(\\'--eval_freq\\', default=500, type=int)\\n    parser.add_argument(\\'--test_freq\\', default=5000, type=int)\\n    parser.add_argument(\\'--log_freq\\', default=100, type=int)\\n    parser.add_argument(\\'--wandb\\', default=1, type=int)\\n\\n    # rl\\n    parser.add_argument(\\'--num_envs\\', default=4, type=int)\\n    parser.add_argument(\\'--step_limit\\', default=100, type=int)\\n    parser.add_argument(\\'--max_steps\\', default=300000, type=int)\\n    parser.add_argument(\\'--learning_rate\\', default=1e-5, type=float)\\n    parser.add_argument(\\'--gamma\\', default=.9, type=float)\\n    parser.add_argument(\\'--clip\\', default=10, type=float)\\n    parser.add_argument(\\'--bptt\\', default=8, type=int)\\n    parser.add_argument(\\'--exploration_method\\', default=\\'softmax\\', type=str, choices=[\\'eps\\', \\'softmax\\'])\\n    parser.add_argument(\\'--w_pg\\', default=1, type=float)\\n    parser.add_argument(\\'--w_td\\', default=1, type=float)\\n    parser.add_argument(\\'--w_il\\', default=0, type=float)\\n    parser.add_argument(\\'--w_en\\', default=1, type=float)\\n\\n    # model\\n    parser.add_argument(\\'--network\\', default=\\'bert\\', type=str, choices=[\\'bert\\', \\'rnn\\'])\\n    parser.add_argument(\\'--bert_path\\', default=\"\", type=str, help=\\'which bert to load\\')\\n    parser.add_argument(\\'--embedding_dim\\', default=128, type=int)\\n    parser.add_argument(\\'--hidden_dim\\', default=128, type=int)\\n    parser.add_argument(\\'--grad_encoder\\', default=1, type=int)\\n    parser.add_argument(\\'--get_image\\', default=0, type=int, help=\\'use image in models\\')\\n\\n    # env\\n    parser.add_argument(\\'--num\\', default=None, type=int)\\n    parser.add_argument(\\'--click_item_name\\', default=1, type=int)\\n    parser.add_argument(\\'--state_format\\', default=\\'text_rich\\', type=str)\\n    parser.add_argument(\\'--human_goals\\', default=1, type=int, help=\\'use human goals\\')\\n    parser.add_argument(\\'--num_prev_obs\\', default=0, type=int, help=\\'number of previous observations\\')\\n    parser.add_argument(\\'--num_prev_actions\\', default=0, type=int, help=\\'number of previous actions\\')\\n    parser.add_argument(\\'--extra_search_path\\', default=\"./data/goal_query_predict.json\", type=str, help=\\'path for extra search queries\\')\\n    \\n\\n    # experimental \\n    parser.add_argument(\\'--ban_buy\\', default=0, type=int, help=\\'ban buy action before selecting options\\')\\n    parser.add_argument(\\'--score_handicap\\', default=0, type=int, help=\\'provide score in state\\')\\n    parser.add_argument(\\'--go_to_item\\', default=0, type=int)\\n    parser.add_argument(\\'--go_to_search\\', default=0, type=int)\\n    parser.add_argument(\\'--harsh_reward\\', default=0, type=int)\\n\\n\\n    parser.add_argument(\\'--debug\\', default=0, type=int, help=\\'debug mode\\')\\n    parser.add_argument(\"--f\", help=\"a dummy argument to fool ipython\", default=\"1\")\\n\\n    return parser.parse_known_args()\\n\\n',\n",
       "  'function_name': 'parse_args',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': 'def main():\\n    args, unknown = parse_args()\\n    if args.debug:\\n        args.num_envs = 2\\n        args.wandb = 0\\n        args.human_goals = 0\\n        args.num = 100\\n    print(unknown)\\n    print(args)\\n    configure_logger(args.output_dir, args.wandb)\\n    agent = Agent(args)\\n    train_env = WebEnv(args, split=\\'train\\', id=\\'train_\\')\\n    server = train_env.env.server\\n    eval_env = WebEnv(args, split=\\'eval\\', id=\\'eval_\\', server=server)\\n    test_env = WebEnv(args, split=\\'test\\', id=\\'test_\\', server=server)\\n    envs = [WebEnv(args, split=\\'train\\', server=server, id=f\\'train{i}_\\') for i in range(args.num_envs)]\\n    print(\"loaded\")\\n    train(agent, eval_env, test_env, envs, args)\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_rl.py'},\n",
       " {'code': \"def make_output_format(format, ev_dir, log_suffix='', args=None):\\n    os.makedirs(ev_dir, exist_ok=True)\\n    if format == 'stdout':\\n        return HumanOutputFormat(sys.stdout)\\n    elif format == 'log':\\n        return HumanOutputFormat(osp.join(ev_dir, 'log%s.txt' % log_suffix))\\n    elif format == 'json':\\n        return JSONOutputFormat(osp.join(ev_dir, 'progress%s.json' % log_suffix))\\n    elif format == 'csv':\\n        return CSVOutputFormat(osp.join(ev_dir, 'progress%s.csv' % log_suffix))\\n    elif format == 'tensorboard':\\n        return TensorBoardOutputFormat(osp.join(ev_dir, 'tb%s' % log_suffix))\\n    elif format == 'wandb':\\n        return WandBOutputFormat(ev_dir)\\n    else:\\n        raise ValueError('Unknown format specified: %s' % (format,))\\n\\n\",\n",
       "  'function_name': 'make_output_format',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def logkv(key, val):\\n    \"\"\"\\n    Log a value of some diagnostic\\n    Call this once for each diagnostic quantity, each iteration\\n    If called many times, last value will be used.\\n    \"\"\"\\n    Logger.CURRENT.logkv(key, val)\\n\\n',\n",
       "  'function_name': 'logkv',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def logkv_mean(key, val):\\n    \"\"\"\\n    The same as logkv(), but if called many times, values averaged.\\n    \"\"\"\\n    Logger.CURRENT.logkv_mean(key, val)\\n\\n',\n",
       "  'function_name': 'logkv_mean',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def logkvs(d):\\n    \"\"\"\\n    Log a dictionary of key-value pairs\\n    \"\"\"\\n    for (k, v) in d.items():\\n        logkv(k, v)\\n\\n',\n",
       "  'function_name': 'logkvs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def dumpkvs():\\n    \"\"\"\\n    Write all of the diagnostics from the current iteration\\n\\n    level: int. (see logger.py docs) If the global logger level is higher than\\n                the level argument here, don\\'t print to stdout.\\n    \"\"\"\\n    Logger.CURRENT.dumpkvs()\\n\\n',\n",
       "  'function_name': 'dumpkvs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def getkvs():\\n    return Logger.CURRENT.name2val\\n\\n',\n",
       "  'function_name': 'getkvs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def log(*args, level=INFO):\\n    \"\"\"\\n    Write the sequence of args, with no separators, to the console and output files (if you\\'ve configured an output file).\\n    \"\"\"\\n    Logger.CURRENT.log(*args, level=level)\\n\\n',\n",
       "  'function_name': 'log',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def debug(*args):\\n    log(*args, level=DEBUG)\\n\\n',\n",
       "  'function_name': 'debug',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def info(*args):\\n    log(*args, level=INFO)\\n\\n',\n",
       "  'function_name': 'info',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def warn(*args):\\n    log(*args, level=WARN)\\n\\n',\n",
       "  'function_name': 'warn',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def error(*args):\\n    log(*args, level=ERROR)\\n\\n',\n",
       "  'function_name': 'error',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def set_level(level):\\n    \"\"\"\\n    Set logging threshold on current logger.\\n    \"\"\"\\n    Logger.CURRENT.set_level(level)\\n\\n',\n",
       "  'function_name': 'set_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def get_dir():\\n    \"\"\"\\n    Get directory that log files are being written to.\\n    will be None if there is no output directory (i.e., if you didn\\'t call start)\\n    \"\"\"\\n    return Logger.CURRENT.get_dir()\\n\\n',\n",
       "  'function_name': 'get_dir',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def profile(n):\\n    \"\"\"\\n    Usage:\\n    @profile(\"my_func\")\\n    def my_func(): code\\n    \"\"\"\\n\\n    def decorator_with_name(func):\\n        def func_wrapper(*args, **kwargs):\\n            with ProfileKV(n):\\n                return func(*args, **kwargs)\\n\\n        return func_wrapper\\n\\n    return decorator_with_name\\n\\n',\n",
       "  'function_name': 'profile',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def configure(dir=None, format_strs=None):\\n    if dir is None:\\n        dir = os.getenv(\\'OPENAI_LOGDIR\\')\\n    if dir is None:\\n        dir = osp.join(tempfile.gettempdir(),\\n                       datetime.datetime.now().strftime(\"openai-%Y-%m-%d-%H-%M-%S-%f\"))\\n    assert isinstance(dir, str)\\n    os.makedirs(dir, exist_ok=True)\\n\\n    log_suffix = \\'\\'\\n    rank = 0\\n    # check environment variables here instead of importing mpi4py\\n    # to avoid calling MPI_Init() when this module is imported\\n    for varname in [\\'PMI_RANK\\', \\'OMPI_COMM_WORLD_RANK\\']:\\n        if varname in os.environ:\\n            rank = int(os.environ[varname])\\n    if rank > 0:\\n        log_suffix = \"-rank%03i\" % rank\\n\\n    if format_strs is None:\\n        if rank == 0:\\n            format_strs = os.getenv(\\'OPENAI_LOG_FORMAT\\', \\'stdout,log,csv\\').split(\\',\\')\\n        else:\\n            format_strs = os.getenv(\\'OPENAI_LOG_FORMAT_MPI\\', \\'log\\').split(\\',\\')\\n    format_strs = filter(None, format_strs)\\n    output_formats = [make_output_format(f, dir, log_suffix) for f in format_strs]\\n\\n    Logger.CURRENT = Logger(dir=dir, output_formats=output_formats)\\n    log(\\'Logging to %s\\' % dir)\\n\\n',\n",
       "  'function_name': 'configure',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': \"def _configure_default_logger():\\n    format_strs = None\\n    # keep the old default of only writing to stdout\\n    if 'OPENAI_LOG_FORMAT' not in os.environ:\\n        format_strs = ['stdout']\\n    configure(format_strs=format_strs)\\n    Logger.DEFAULT = Logger.CURRENT\\n\\n\",\n",
       "  'function_name': '_configure_default_logger',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': \"def reset():\\n    if Logger.CURRENT is not Logger.DEFAULT:\\n        Logger.CURRENT.close()\\n        Logger.CURRENT = Logger.DEFAULT\\n        log('Reset logger')\\n\\n\",\n",
       "  'function_name': 'reset',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def _demo():\\n    info(\"hi\")\\n    debug(\"shouldn\\'t appear\")\\n    set_level(DEBUG)\\n    debug(\"should appear\")\\n    dir = \"/tmp/testlogging\"\\n    if os.path.exists(dir):\\n        shutil.rmtree(dir)\\n    configure(dir=dir)\\n    logkv(\"a\", 3)\\n    logkv(\"b\", 2.5)\\n    dumpkvs()\\n    logkv(\"b\", -2.5)\\n    logkv(\"a\", 5.5)\\n    dumpkvs()\\n    info(\"^^^ should see a = 5.5\")\\n    logkv_mean(\"b\", -22.5)\\n    logkv_mean(\"b\", -44.4)\\n    logkv(\"a\", 5.5)\\n    dumpkvs()\\n    info(\"^^^ should see b = 33.3\")\\n\\n    logkv(\"b\", -2.5)\\n    dumpkvs()\\n\\n    logkv(\"a\", \"longasslongasslongasslongasslongasslongassvalue\")\\n    dumpkvs()\\n\\n',\n",
       "  'function_name': '_demo',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': \"def read_json(fname):\\n    import pandas\\n    ds = []\\n    with open(fname, 'rt') as fh:\\n        for line in fh:\\n            ds.append(json.loads(line))\\n    return pandas.DataFrame(ds)\\n\\n\",\n",
       "  'function_name': 'read_json',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': \"def read_csv(fname):\\n    import pandas\\n    return pandas.read_csv(fname, index_col=None, comment='#')\\n\\n\",\n",
       "  'function_name': 'read_csv',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': 'def read_tb(path):\\n    \"\"\"\\n    path : a tensorboard file OR a directory, where we will find all TB files\\n           of the form events.*\\n    \"\"\"\\n    import pandas\\n    import numpy as np\\n    from glob import glob\\n    from collections import defaultdict\\n    import tensorflow as tf\\n    if osp.isdir(path):\\n        fnames = glob(osp.join(path, \"events.*\"))\\n    elif osp.basename(path).startswith(\"events.\"):\\n        fnames = [path]\\n    else:\\n        raise NotImplementedError(\"Expected tensorboard file or directory containing them. Got %s\" % path)\\n    tag2pairs = defaultdict(list)\\n    maxstep = 0\\n    for fname in fnames:\\n        for summary in tf.train.summary_iterator(fname):\\n            if summary.step > 0:\\n                for v in summary.summary.value:\\n                    pair = (summary.step, v.simple_value)\\n                    tag2pairs[v.tag].append(pair)\\n                maxstep = max(summary.step, maxstep)\\n    data = np.empty((maxstep, len(tag2pairs)))\\n    data[:] = np.nan\\n    tags = sorted(tag2pairs.keys())\\n    for (colidx, tag) in enumerate(tags):\\n        pairs = tag2pairs[tag]\\n        for (step, value) in pairs:\\n            data[step - 1, colidx] = value\\n    return pandas.DataFrame(data, columns=tags)\\n\\n',\n",
       "  'function_name': 'read_tb',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/logger.py'},\n",
       " {'code': \"def bart_predict(input, model, skip_special_tokens=True, **kwargs):\\n    input_ids = bart_tokenizer(input)['input_ids']\\n    input_ids = torch.tensor(input_ids).unsqueeze(0)\\n    output = model.generate(input_ids, max_length=512, **kwargs)\\n    return bart_tokenizer.batch_decode(output.tolist(), skip_special_tokens=skip_special_tokens)\\n\\n\",\n",
       "  'function_name': 'bart_predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/test.py'},\n",
       " {'code': 'def predict(obs, info, model, softmax=False, rule=False, bart_model=None):\\n    valid_acts = info[\\'valid\\']\\n    if valid_acts[0].startswith(\\'search[\\'):\\n        if bart_model is None:\\n            return valid_acts[-1]\\n        else:\\n            goal = process_goal(obs)\\n            query = bart_predict(goal, bart_model, num_return_sequences=5, num_beams=5)\\n            # query = random.choice(query)  # in the paper, we sample from the top-5 generated results.\\n            query = query[0]  #... but use the top-1 generated search will lead to better results than the paper results.\\n            return f\\'search[{query}]\\'\\n            \\n    if rule:\\n        item_acts = [act for act in valid_acts if act.startswith(\\'click[item - \\')]\\n        if item_acts:\\n            return item_acts[0]\\n        else:\\n            assert \\'click[buy now]\\' in valid_acts\\n            return \\'click[buy now]\\'\\n                \\n    state_encodings = tokenizer(process(obs), max_length=512, truncation=True, padding=\\'max_length\\')\\n    action_encodings = tokenizer(list(map(process, valid_acts)), max_length=512, truncation=True,  padding=\\'max_length\\')\\n    batch = {\\n        \\'state_input_ids\\': state_encodings[\\'input_ids\\'],\\n        \\'state_attention_mask\\': state_encodings[\\'attention_mask\\'],\\n        \\'action_input_ids\\': action_encodings[\\'input_ids\\'],\\n        \\'action_attention_mask\\': action_encodings[\\'attention_mask\\'],\\n        \\'sizes\\': len(valid_acts),\\n        \\'images\\': info[\\'image_feat\\'].tolist() if \"image_feat\" in info else None,\\n        \\'labels\\': 0\\n    }\\n    batch = data_collator([batch])\\n    # make batch cuda\\n    batch = {k: v.cuda() for k, v in batch.items() if v is not None}\\n    outputs = model(**batch)\\n    if softmax:\\n        idx = torch.multinomial(F.softmax(outputs.logits[0], dim=0), 1)[0].item()\\n    else:\\n        idx = outputs.logits[0].argmax(0).item()\\n    return valid_acts[idx]\\n\\n\\n',\n",
       "  'function_name': 'predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/test.py'},\n",
       " {'code': \"def episode(model, idx=None, verbose=False, softmax=False, rule=False, bart_model=None):\\n    obs, info = env.reset(idx)\\n    if verbose:\\n        print(info['goal'])\\n    for i in range(100):\\n        action = predict(obs, info, model, softmax=softmax, rule=rule, bart_model=bart_model)\\n        if verbose:\\n            print(action)\\n        obs, reward, done, info = env.step(action)\\n        if done:\\n            return reward\\n    return 0\\n\\n\\n\",\n",
       "  'function_name': 'episode',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/test.py'},\n",
       " {'code': 'def parse_args():\\n    parser = argparse.ArgumentParser(description=\"Finetune a transformers model on a text classification task\")\\n    parser.add_argument(\"--model_path\", type=str, default=\"./ckpts/web_click/epoch_9/model.pth\", help=\"Where to store the final model.\")\\n    parser.add_argument(\"--mem\", type=int, default=0, help=\"State with memory\")\\n    parser.add_argument(\"--bart_path\", type=str, default=\\'./ckpts/web_search/checkpoint-800\\', help=\"BART model path if using it\")\\n    parser.add_argument(\"--bart\", type=bool, default=True, help=\"Flag to specify whether to use bart or not (default: True)\")\\n    parser.add_argument(\"--image\", type=bool, default=False, help=\"Flag to specify whether to use image or not (default: True)\")\\n    parser.add_argument(\"--softmax\", type=bool, default=True, help=\"Flag to specify whether to use softmax sampling or not (default: True)\")\\n\\n    args = parser.parse_args()\\n\\n    return args\\n\\n\\n',\n",
       "  'function_name': 'parse_args',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/test.py'},\n",
       " {'code': 'def process(s):\\n    s = s.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\").strip()\\n    s = s.replace(\\'[sep]\\', \\'[SEP]\\')\\n    return s\\n\\n',\n",
       "  'function_name': 'process',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': 'def process_goal(state):\\n    state = state.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\")\\n    state = state.replace(\\'amazon shopping game\\\\ninstruction:\\', \\'\\').replace(\\'webshop\\\\ninstruction:\\', \\'\\')\\n    state = state.replace(\\'\\\\n[button] search [button_]\\', \\'\\').strip()\\n    if \\', and price lower than\\' in state:\\n        state = state.split(\\', and price lower than\\')[0]\\n    return state\\n\\n',\n",
       "  'function_name': 'process_goal',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': \"def get_data(split, mem=False, filter_search=True):\\n    path = MEM_PATH if mem else PATH\\n    print('Loading data from {}'.format(path))\\n    with open(path, 'r') as json_file:\\n        json_list = list(json_file)\\n\\n    human_goals = json.load(open(HUMAN_GOAL_PATH, 'r'))\\n\\n    random.seed(233)\\n    random.shuffle(json_list)\\n\\n    # if split == 'train':\\n    #     json_list = json_list[:int(len(json_list) * 0.9)]\\n    # elif split == 'eval':\\n    #     json_list = json_list[int(len(json_list) * 0.9):]\\n    # elif split == 'all':\\n    #     pass\\n\\n    # split by human goal index\\n    goal_range = range(len(human_goals))\\n    if split == 'train':\\n        goal_range = range(1500, len(human_goals))\\n    elif split == 'eval':\\n        goal_range = range(500, 1500)\\n    elif split == 'test':\\n        goal_range = range(0, 500)\\n\\n    bad = cnt = 0\\n    state_list, action_list, idx_list, size_list = [], [], [], []\\n    image_list = []\\n    num_trajs = 0\\n    for json_str in json_list:\\n        result = json.loads(json_str)\\n        s = process_goal(result['states'][0])\\n        assert s in human_goals, s\\n        goal_idx = human_goals.index(s)\\n        if goal_idx not in goal_range:\\n            continue\\n        num_trajs += 1\\n        if 'images' not in result:\\n            result['images'] = [0] * len(result['states'])\\n        for state, valid_acts, idx, image in zip(result['states'], result['available_actions'], result['action_idxs'], result['images']):\\n            cnt += 1\\n            if filter_search and idx == -1:\\n                continue\\n            state_list.append(state)\\n            image_list.append([0.] * 512 if image == 0 else image)\\n            if len(valid_acts) > 20:  # do some action space reduction...\\n                bad += 1\\n                new_idxs = list(range(6)) + \\\\\\n                    random.sample(range(6, len(valid_acts)), 10)\\n                if idx not in new_idxs:\\n                    new_idxs += [idx]\\n                new_idxs = sorted(new_idxs)\\n                valid_acts = [valid_acts[i] for i in new_idxs]\\n                idx = new_idxs.index(idx)\\n                # print(valid_acts)\\n            action_list.extend(valid_acts)\\n            idx_list.append(idx)\\n            size_list.append(len(valid_acts))\\n    print('num of {} trajs: {}'.format(split, num_trajs))\\n    print('total transitions and bad transitions: {} {}'.format(cnt, bad))\\n    state_list, action_list = list(\\n        map(process, state_list)), list(map(process, action_list))\\n    return state_list, action_list, idx_list, size_list, image_list\\n\\n\",\n",
       "  'function_name': 'get_data',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': \"def get_dataset(split, mem=False):\\n    states, actions, idxs, sizes, images = get_data(split, mem)\\n    state_encodings = tokenizer(\\n        states, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\\n    action_encodings = tokenizer(\\n        actions, padding='max_length', max_length=128, truncation=True, return_tensors='pt')\\n    dataset = {\\n        'state_input_ids': state_encodings['input_ids'],\\n        'state_attention_mask': state_encodings['attention_mask'],\\n        'action_input_ids': action_encodings['input_ids'].split(sizes),\\n        'action_attention_mask': action_encodings['attention_mask'].split(sizes),\\n        'sizes': sizes,\\n        'images': torch.tensor(images),\\n        'labels': idxs,\\n    }\\n    return Dataset.from_dict(dataset)\\n\\n\",\n",
       "  'function_name': 'get_dataset',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': \"def data_collator(batch):\\n    state_input_ids, state_attention_mask, action_input_ids, action_attention_mask, sizes, labels, images = [\\n    ], [], [], [], [], [], []\\n    for sample in batch:\\n        state_input_ids.append(sample['state_input_ids'])\\n        state_attention_mask.append(sample['state_attention_mask'])\\n        action_input_ids.extend(sample['action_input_ids'])\\n        action_attention_mask.extend(sample['action_attention_mask'])\\n        sizes.append(sample['sizes'])\\n        labels.append(sample['labels'])\\n        images.append(sample['images'])\\n    max_state_len = max(sum(x) for x in state_attention_mask)\\n    max_action_len = max(sum(x) for x in action_attention_mask)\\n    return {\\n        'state_input_ids': torch.tensor(state_input_ids)[:, :max_state_len],\\n        'state_attention_mask': torch.tensor(state_attention_mask)[:, :max_state_len],\\n        'action_input_ids': torch.tensor(action_input_ids)[:, :max_action_len],\\n        'action_attention_mask': torch.tensor(action_attention_mask)[:, :max_action_len],\\n        'sizes': torch.tensor(sizes),\\n        'images': torch.tensor(images) if images and images[0] else None,\\n        'labels': torch.tensor(labels),\\n    }\\n\\n\",\n",
       "  'function_name': 'data_collator',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': 'def parse_args():\\n    parser = argparse.ArgumentParser(\\n        description=\"Finetune a transformers model on a text classification task\")\\n    parser.add_argument(\\n        \"--task_name\",\\n        type=str,\\n        default=\"mprc\",\\n        help=\"The name of the glue task to train on.\",\\n        choices=list(task_to_keys.keys()),\\n    )\\n    parser.add_argument(\\n        \"--train_file\", type=str, default=None, help=\"A csv or a json file containing the training data.\"\\n    )\\n    parser.add_argument(\\n        \"--validation_file\", type=str, default=None, help=\"A csv or a json file containing the validation data.\"\\n    )\\n    parser.add_argument(\\n        \"--max_length\",\\n        type=int,\\n        default=128,\\n        help=(\\n            \"The maximum total input sequence length after tokenization. Sequences longer than this will be truncated,\"\\n            \" sequences shorter will be padded if `--pad_to_max_lengh` is passed.\"\\n        ),\\n    )\\n    parser.add_argument(\\n        \"--pad_to_max_length\",\\n        action=\"store_true\",\\n        help=\"If passed, pad all samples to `max_length`. Otherwise, dynamic padding is used.\",\\n    )\\n    parser.add_argument(\\n        \"--model_name_or_path\",\\n        default=\"bert-base-uncased\",\\n        type=str,\\n        help=\"Path to pretrained model or model identifier from huggingface.co/models.\",\\n    )\\n    parser.add_argument(\\n        \"--use_slow_tokenizer\",\\n        action=\"store_true\",\\n        help=\"If passed, will use a slow tokenizer (not backed by the 🤗 Tokenizers library).\",\\n    )\\n    parser.add_argument(\\n        \"--per_device_train_batch_size\",\\n        type=int,\\n        default=1,\\n        help=\"Batch size (per device) for the training dataloader.\",\\n    )\\n    parser.add_argument(\\n        \"--per_device_eval_batch_size\",\\n        type=int,\\n        default=8,\\n        help=\"Batch size (per device) for the evaluation dataloader.\",\\n    )\\n    parser.add_argument(\\n        \"--learning_rate\",\\n        type=float,\\n        default=2e-5,\\n        help=\"Initial learning rate (after the potential warmup period) to use.\",\\n    )\\n    parser.add_argument(\"--weight_decay\", type=float,\\n                        default=0.0, help=\"Weight decay to use.\")\\n    parser.add_argument(\"--num_train_epochs\", type=int, default=10,\\n                        help=\"Total number of training epochs to perform.\")\\n    parser.add_argument(\\n        \"--max_train_steps\",\\n        type=int,\\n        default=None,\\n        help=\"Total number of training steps to perform. If provided, overrides num_train_epochs.\",\\n    )\\n    parser.add_argument(\\n        \"--gradient_accumulation_steps\",\\n        type=int,\\n        default=32,\\n        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\\n    )\\n    parser.add_argument(\\n        \"--lr_scheduler_type\",\\n        type=SchedulerType,\\n        default=\"linear\",\\n        help=\"The scheduler type to use.\",\\n        choices=[\"linear\", \"cosine\", \"cosine_with_restarts\",\\n                 \"polynomial\", \"constant\", \"constant_with_warmup\"],\\n    )\\n    parser.add_argument(\\n        \"--num_warmup_steps\", type=int, default=0, help=\"Number of steps for the warmup in the lr scheduler.\"\\n    )\\n    parser.add_argument(\"--output_dir\", type=str, default=\"./ckpts/web_click\",\\n                        help=\"Where to store the final model.\")\\n    parser.add_argument(\"--seed\", type=int, default=None,\\n                        help=\"A seed for reproducible training.\")\\n    parser.add_argument(\"--push_to_hub\", action=\"store_true\",\\n                        help=\"Whether or not to push the model to the Hub.\")\\n    parser.add_argument(\\n        \"--hub_model_id\", type=str, help=\"The name of the repository to keep in sync with the local `output_dir`.\"\\n    )\\n    parser.add_argument(\"--hub_token\", type=str,\\n                        help=\"The token to use to push to the Model Hub.\")\\n    parser.add_argument(\\n        \"--checkpointing_steps\",\\n        type=str,\\n        default=\"epoch\",\\n        help=\"Whether the various states should be saved at the end of every n steps, or \\'epoch\\' for each epoch.\",\\n    )\\n    parser.add_argument(\\n        \"--resume_from_checkpoint\",\\n        type=str,\\n        default=None,\\n        help=\"If the training should continue from a checkpoint folder.\",\\n    )\\n    parser.add_argument(\\n        \"--with_tracking\",\\n        type=int,\\n        default=1,\\n        help=\"Whether to load in all available experiment trackers from the environment and use them for logging.\",\\n    )\\n\\n    parser.add_argument(\"--mem\", type=int, default=0, help=\"State with memory\")\\n    parser.add_argument(\"--image\", type=int, default=1,\\n                        help=\"State with image\")\\n    parser.add_argument(\"--pretrain\", type=int, default=1,\\n                        help=\"Pretrained BERT or not\")\\n\\n    parser.add_argument(\"--logging_steps\", type=int,\\n                        default=10, help=\"Logging in training\")\\n\\n    args = parser.parse_args()\\n\\n    # Sanity checks\\n    if args.task_name is None and args.train_file is None and args.validation_file is None:\\n        raise ValueError(\\n            \"Need either a task name or a training/validation file.\")\\n    else:\\n        if args.train_file is not None:\\n            extension = args.train_file.split(\".\")[-1]\\n            assert extension in [\\n                \"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\\n        if args.validation_file is not None:\\n            extension = args.validation_file.split(\".\")[-1]\\n            assert extension in [\\n                \"csv\", \"json\"], \"`validation_file` should be a csv or a json file.\"\\n\\n    if args.push_to_hub:\\n        assert args.output_dir is not None, \"Need an `output_dir` to create a repo when `--push_to_hub` is passed.\"\\n\\n    return args\\n\\n',\n",
       "  'function_name': 'parse_args',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': 'def main():\\n    args = parse_args()\\n\\n    # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\\n    # If we\\'re using tracking, we also need to initialize it here and it will pick up all supported trackers in the environment\\n    # accelerator = Accelerator(log_with=\"wandb\", logging_dir=args.output_dir) if args.with_tracking else Accelerator()\\n    accelerator = Accelerator()\\n    # Make one log on every process with the configuration for debugging.\\n\\n    wandb.init(project=\"bert_il\", config=args, name=args.output_dir)\\n\\n    logging.basicConfig(\\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\\n        level=logging.INFO,\\n    )\\n    logger.info(accelerator.state, main_process_only=False)\\n    if accelerator.is_local_main_process:\\n        datasets.utils.logging.set_verbosity_warning()\\n        transformers.utils.logging.set_verbosity_info()\\n    else:\\n        datasets.utils.logging.set_verbosity_error()\\n        transformers.utils.logging.set_verbosity_error()\\n\\n    # If passed along, set the training seed now.\\n    if args.seed is not None:\\n        set_seed(args.seed)\\n\\n    # Load pretrained model and tokenizer\\n    #\\n    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\\n    # download model & vocab.\\n    # tokenizer = AutoTokenizer.from_pretrained(\\'bert-base-uncased\\')\\n    config = BertConfigForWebshop(\\n        image=args.image, pretrain_bert=args.pretrain)\\n    model = BertModelForWebshop(config)\\n    # model.bert.resize_token_embeddings(len(tokenizer))\\n\\n    train_dataset = get_dataset(\"train\", mem=args.mem)\\n    eval_dataset = get_dataset(\"eval\", mem=args.mem)\\n\\n    # Log a few random samples from the training set:\\n    for index in random.sample(range(len(train_dataset)), 3):\\n        logger.info(\\n            f\"Sample {index} of the training set: {train_dataset[index]}.\")\\n\\n    # DataLoaders creation:\\n    train_dataloader = DataLoader(\\n        train_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size\\n    )\\n    eval_dataloader = DataLoader(\\n        eval_dataset, collate_fn=data_collator, batch_size=args.per_device_eval_batch_size)\\n\\n    # Optimizer\\n    # Split weights in two groups, one with weight decay and the other not.\\n    no_decay = [\"bias\", \"LayerNorm.weight\"]\\n    optimizer_grouped_parameters = [\\n        {\\n            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\\n            \"weight_decay\": args.weight_decay,\\n        },\\n        {\\n            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\\n            \"weight_decay\": 0.0,\\n        },\\n    ]\\n    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate)\\n\\n    # Scheduler and math around the number of training steps.\\n    num_update_steps_per_epoch = math.ceil(\\n        len(train_dataloader) / args.gradient_accumulation_steps)\\n    if args.max_train_steps is None:\\n        args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\\n    else:\\n        args.num_train_epochs = math.ceil(\\n            args.max_train_steps / num_update_steps_per_epoch)\\n\\n    lr_scheduler = get_scheduler(\\n        name=args.lr_scheduler_type,\\n        optimizer=optimizer,\\n        num_warmup_steps=args.num_warmup_steps,\\n        num_training_steps=args.max_train_steps,\\n    )\\n\\n    # Prepare everything with our `accelerator`.\\n    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\\n        model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\\n    )\\n\\n    # We need to recalculate our total training steps as the size of the training dataloader may have changed.\\n    num_update_steps_per_epoch = math.ceil(\\n        len(train_dataloader) / args.gradient_accumulation_steps)\\n    args.max_train_steps = args.num_train_epochs * num_update_steps_per_epoch\\n\\n    # Figure out how many steps we should save the Accelerator states\\n    if hasattr(args.checkpointing_steps, \"isdigit\"):\\n        checkpointing_steps = args.checkpointing_steps\\n        if args.checkpointing_steps.isdigit():\\n            checkpointing_steps = int(args.checkpointing_steps)\\n    else:\\n        checkpointing_steps = None\\n\\n    # We need to initialize the trackers we use, and also store our configuration\\n    if args.with_tracking:\\n        experiment_config = vars(args)\\n        # TensorBoard cannot log Enums, need the raw value\\n        experiment_config[\"lr_scheduler_type\"] = experiment_config[\"lr_scheduler_type\"].value\\n        accelerator.init_trackers(\"glue_no_trainer\", experiment_config)\\n\\n    # Get the metric function\\n    metric = load_metric(\"accuracy\")\\n\\n    # Train!\\n    total_batch_size = args.per_device_train_batch_size * \\\\\\n        accelerator.num_processes * args.gradient_accumulation_steps\\n\\n    logger.info(\"***** Running training *****\")\\n    logger.info(f\"  Num examples = {len(train_dataset)}\")\\n    logger.info(f\"  Num Epochs = {args.num_train_epochs}\")\\n    logger.info(\\n        f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\\n    logger.info(\\n        f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\\n    logger.info(\\n        f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\\n    logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\\n    # Only show the progress bar once on each machine.\\n    progress_bar = tqdm(range(args.max_train_steps),\\n                        disable=not accelerator.is_local_main_process)\\n    completed_steps = 0\\n    starting_epoch = 0\\n    # Potentially load in the weights and states from a previous save\\n    if args.resume_from_checkpoint:\\n        if args.resume_from_checkpoint is not None or args.resume_from_checkpoint != \"\":\\n            accelerator.print(\\n                f\"Resumed from checkpoint: {args.resume_from_checkpoint}\")\\n            accelerator.load_state(args.resume_from_checkpoint)\\n            path = os.path.basename(args.resume_from_checkpoint)\\n        else:\\n            # Get the most recent checkpoint\\n            dirs = [f.name for f in os.scandir(os.getcwd()) if f.is_dir()]\\n            dirs.sort(key=os.path.getctime)\\n            # Sorts folders by date modified, most recent checkpoint is the last\\n            path = dirs[-1]\\n        # Extract `epoch_{i}` or `step_{i}`\\n        training_difference = os.path.splitext(path)[0]\\n\\n        if \"epoch\" in training_difference:\\n            starting_epoch = int(training_difference.replace(\"epoch_\", \"\")) + 1\\n            resume_step = None\\n        else:\\n            resume_step = int(training_difference.replace(\"step_\", \"\"))\\n            starting_epoch = resume_step // len(train_dataloader)\\n            resume_step -= starting_epoch * len(train_dataloader)\\n\\n    for epoch in range(starting_epoch, args.num_train_epochs):\\n        model.train()\\n        if args.with_tracking:\\n            total_loss = total_step = 0\\n\\n        for step, batch in enumerate(train_dataloader):\\n            # We need to skip steps until we reach the resumed step\\n            if args.resume_from_checkpoint and epoch == starting_epoch:\\n                if resume_step is not None and step < resume_step:\\n                    completed_steps += 1\\n                    continue\\n            outputs = model(**batch)\\n            loss = outputs.loss\\n            # We keep track of the loss at each epoch\\n            if args.with_tracking:\\n                total_loss += loss.detach().float()\\n                total_step += 1\\n            loss = loss / args.gradient_accumulation_steps\\n            accelerator.backward(loss)\\n\\n            metric.add_batch(\\n                predictions=torch.stack([logit.argmax(dim=0)\\n                                        for logit in outputs.logits]),\\n                references=batch[\"labels\"]\\n            )\\n\\n            if step % args.gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\\n                optimizer.step()\\n                lr_scheduler.step()\\n                optimizer.zero_grad()\\n                progress_bar.update(1)\\n                completed_steps += 1\\n\\n                if args.with_tracking and args.logging_steps > 0 and completed_steps % args.logging_steps == 0:\\n                    train_metric = metric.compute()\\n                    wandb.log(\\n                        {\\n                            \"train_accuracy\": train_metric,\\n                            \"train_loss\": total_loss / total_step,\\n                            \"train_step\": completed_steps,\\n                        },\\n                    )\\n                    total_loss = total_step = 0\\n\\n            if isinstance(checkpointing_steps, int):\\n                if completed_steps % checkpointing_steps == 0:\\n                    output_dir = f\"step_{completed_steps }\"\\n                    if args.output_dir is not None:\\n                        output_dir = os.path.join(args.output_dir, output_dir)\\n                    accelerator.save_state(output_dir)\\n\\n            if completed_steps >= args.max_train_steps:\\n                break\\n\\n        model.eval()\\n        samples_seen = 0\\n        total_loss = total_step = 0\\n        if len(metric) > 0:\\n            metric.compute()\\n\\n        for step, batch in enumerate(eval_dataloader):\\n            with torch.no_grad():\\n                outputs = model(**batch)\\n            predictions = torch.stack([logit.argmax(dim=0)\\n                                      for logit in outputs.logits])\\n            predictions, references = accelerator.gather(\\n                (predictions, batch[\"labels\"]))\\n            # If we are in a multiprocess environment, the last batch has duplicates\\n            if accelerator.num_processes > 1:\\n                if step == len(eval_dataloader):\\n                    predictions = predictions[: len(\\n                        eval_dataloader.dataset) - samples_seen]\\n                    references = references[: len(\\n                        eval_dataloader.dataset) - samples_seen]\\n                else:\\n                    samples_seen += references.shape[0]\\n            metric.add_batch(\\n                predictions=predictions,\\n                references=references,\\n            )\\n\\n            total_loss += outputs.loss.detach().float()\\n            total_step += 1\\n\\n        eval_metric = metric.compute()\\n        logger.info(f\"epoch {epoch}: {eval_metric}\")\\n\\n        if args.with_tracking:\\n            wandb.log(\\n                {\\n                    \"eval_accuracy\": eval_metric,\\n                    \"eval_loss\": total_loss / total_step,\\n                    \"epoch\": epoch,\\n                    \"epoch_step\": completed_steps,\\n                },\\n            )\\n\\n        if args.checkpointing_steps == \"epoch\":\\n            output_dir = f\"epoch_{epoch}\"\\n            if args.output_dir is not None:\\n                output_dir = os.path.join(args.output_dir, output_dir)\\n            os.makedirs(output_dir, exist_ok=True)\\n            unwrapped_model = accelerator.unwrap_model(model)\\n            torch.save(unwrapped_model.state_dict(),\\n                       os.path.join(output_dir, \"model.pth\"))\\n\\n            # accelerator.save_state(output_dir)\\n\\n    if args.output_dir is not None:\\n        with open(os.path.join(args.output_dir, \"all_results.json\"), \"w\") as f:\\n            json.dump({\"eval_accuracy\": eval_metric[\"accuracy\"]}, f)\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/train_choice_il.py'},\n",
       " {'code': 'def duplicate(output, mask, lens, act_sizes):\\n    \"\"\"\\n    Duplicate the output based on the action sizes.\\n    \"\"\"\\n    output = torch.cat([output[i:i+1].repeat(j, 1, 1) for i, j in enumerate(act_sizes)], dim=0)\\n    mask = torch.cat([mask[i:i+1].repeat(j, 1) for i, j in enumerate(act_sizes)], dim=0)\\n    lens = list(itertools.chain.from_iterable([lens[i:i+1] * j for i, j in enumerate(act_sizes)]))\\n    return output, mask, lens\\n\\n',\n",
       "  'function_name': 'duplicate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/models/modules.py'},\n",
       " {'code': 'def get_aggregated(output, lens, method):\\n    \"\"\"\\n    Get the aggregated hidden state of the encoder.\\n    B x D\\n    \"\"\"\\n    if method == \\'mean\\':\\n        return torch.stack([output[i, :j, :].mean(0) for i, j in enumerate(lens)], dim=0)\\n    elif method == \\'last\\':\\n        return torch.stack([output[i, j-1, :] for i, j in enumerate(lens)], dim=0)\\n    elif method == \\'first\\':\\n        return output[:, 0, :]\\n\\n',\n",
       "  'function_name': 'get_aggregated',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/baseline_models/models/modules.py'},\n",
       " {'code': 'def process_str(s):\\n    s = s.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\").strip()\\n    s = s.replace(\\'[sep]\\', \\'[SEP]\\')\\n    return s\\n\\n',\n",
       "  'function_name': 'process_str',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': 'def process_goal(state):\\n    state = state.lower().replace(\\'\"\\', \\'\\').replace(\"\\'\", \"\")\\n    state = state.replace(\\'amazon shopping game\\\\ninstruction:\\', \\'\\').replace(\\'webshop\\\\ninstruction:\\', \\'\\')\\n    state = state.replace(\\'\\\\n[button] search [button_]\\', \\'\\').strip()\\n    if \\', and price lower than\\' in state:\\n        state = state.split(\\', and price lower than\\')[0]\\n    return state\\n\\n',\n",
       "  'function_name': 'process_goal',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': \"def data_collator(batch):\\n    state_input_ids, state_attention_mask, action_input_ids, action_attention_mask, sizes, labels, images = [], [], [], [], [], [], []\\n    for sample in batch:\\n        state_input_ids.append(sample['state_input_ids'])\\n        state_attention_mask.append(sample['state_attention_mask'])\\n        action_input_ids.extend(sample['action_input_ids'])\\n        action_attention_mask.extend(sample['action_attention_mask'])\\n        sizes.append(sample['sizes'])\\n        labels.append(sample['labels'])\\n        images.append(sample['images'])\\n    max_state_len = max(sum(x) for x in state_attention_mask)\\n    max_action_len = max(sum(x) for x in action_attention_mask)\\n    return {\\n        'state_input_ids': torch.tensor(state_input_ids)[:, :max_state_len],\\n        'state_attention_mask': torch.tensor(state_attention_mask)[:, :max_state_len],\\n        'action_input_ids': torch.tensor(action_input_ids)[:, :max_action_len],\\n        'action_attention_mask': torch.tensor(action_attention_mask)[:, :max_action_len],\\n        'sizes': torch.tensor(sizes),\\n        'images': torch.tensor(images),\\n        'labels': torch.tensor(labels),\\n    }\\n\\n\",\n",
       "  'function_name': 'data_collator',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': \"def bart_predict(input):\\n    input_ids = bart_tokenizer(input)['input_ids']\\n    input_ids = torch.tensor(input_ids).unsqueeze(0)\\n    output = bart_model.generate(input_ids, max_length=512, num_return_sequences=5, num_beams=5)\\n    return bart_tokenizer.batch_decode(output.tolist(), skip_special_tokens=True)[0]\\n\\n\",\n",
       "  'function_name': 'bart_predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': \"def bert_predict(obs, info, softmax=True):\\n    valid_acts = info['valid']\\n    assert valid_acts[0].startswith('click[')\\n    state_encodings = bert_tokenizer(process_str(obs), max_length=512, truncation=True, padding='max_length')\\n    action_encodings = bert_tokenizer(list(map(process_str, valid_acts)), max_length=512, truncation=True,  padding='max_length')\\n    batch = {\\n        'state_input_ids': state_encodings['input_ids'],\\n        'state_attention_mask': state_encodings['attention_mask'],\\n        'action_input_ids': action_encodings['input_ids'],\\n        'action_attention_mask': action_encodings['attention_mask'],\\n        'sizes': len(valid_acts),\\n        'images': info['image_feat'].tolist(),\\n        'labels': 0\\n    }\\n    batch = data_collator([batch])\\n    outputs = bert_model(**batch)\\n    if softmax:\\n        idx = torch.multinomial(torch.nn.functional.softmax(outputs.logits[0], dim=0), 1)[0].item()\\n    else:\\n        idx = outputs.logits[0].argmax(0).item()\\n    return valid_acts[idx]\\n\",\n",
       "  'function_name': 'bert_predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': 'def get_return_value(env, asin, options, search_terms, page_num, product):\\n    asin_url = None\\n\\n    # Determine product URL + options based on environment\\n    if env == \\'webshop\\':\\n        query_str = \"+\".join(search_terms.split())\\n        options_str = json.dumps(options)\\n        asin_url = (\\n            f\\'{WEBSHOP_URL}/item_page/{WEBSHOP_SESSION}/\\'\\n            f\\'{asin}/{query_str}/{page_num}/{options_str}\\'\\n        )\\n    else:\\n        asin_url = f\"https://www.ebay.com/itm/{asin}\" if env == \\'ebay\\' else \\\\\\n            f\"https://www.amazon.com/dp/{asin}\"\\n    \\n    # Extract relevant fields for product\\n    product_reduced = {k: v for k, v in product.items() if k in [\"asin\", \"Title\", \"Description\", \"BulletPoints\"]}\\n    product_reduced[\"Description\"] = product_reduced[\"Description\"][:100] + \"...\"\\n    product_reduced[\"Features\"] = product_reduced.pop(\"BulletPoints\")\\n    product_reduced[\"Features\"] = product_reduced[\"Features\"][:100] + \"...\"\\n\\n    # Create HTML to show link to product\\n    html = \"\"\"<!DOCTYPE html><html><head><title>Chosen Product</title></head><body>\"\"\"\\n    html += f\"\"\"Product Image:<img src=\"{product[\"MainImage\"]}\" height=\"50px\" /><br>\"\"\" if len(product[\"MainImage\"]) > 0 else \"\"\\n    html += f\"\"\"Link to Product:\\n        <a href=\"{asin_url}\" style=\"color:blue;text-decoration:underline;\" target=\"_blank\">{asin_url}</a>\\n        </body></html>\"\"\"\\n\\n    return product_reduced, options if len(options) > 0 else \"None Selected\", html\\n        \\n',\n",
       "  'function_name': 'get_return_value',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': 'def predict(obs, info):\\n    \"\"\"\\n    Given WebShop environment observation and info, predict an action.\\n    \"\"\"\\n    valid_acts = info[\\'valid\\']\\n    if valid_acts[0].startswith(\\'click[\\'):\\n        return bert_predict(obs, info)\\n    else:\\n        return \"search[\" + bart_predict(process_goal(obs)) + \"]\"\\n',\n",
       "  'function_name': 'predict',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': 'def run_episode(goal, env, verbose=True):\\n    \"\"\"\\n    Interact with amazon to find a product given input goal.\\n    Input: text goal\\n    Output: a url of found item on amazon.\\n    \"\"\"\\n    env = env.lower()\\n    if env not in ENVIRONMENTS:\\n        print(f\"[ERROR] Environment {env} not recognized\")\\n        \\n    obs = \"Amazon Shopping Game\\\\nInstruction:\" + goal + \"\\\\n[button] search [button]\"\\n    info = {\\'valid\\': [\\'search[stuff]\\'], \\'image_feat\\': torch.zeros(512)}\\n    product_map = {}\\n    title_to_asin_map = {}\\n    search_results_cache = {}\\n    visited_asins, clicked_options = set(), set()\\n    sub_page_type, page_type, page_num = None, None, None\\n    search_terms, prod_title, asin = None, None, None\\n    options = {}\\n    \\n    for i in range(100):\\n        # Run prediction\\n        action = predict(obs, info)\\n        if verbose:\\n            print(\"====\")\\n            print(action)\\n        \\n        # Previous Page Type, Action -> Next Page Type\\n        action_content = action[action.find(\"[\")+1:action.find(\"]\")]\\n        prev_page_type = page_type\\n        if action.startswith(\\'search[\\'):\\n            page_type = Page.RESULTS\\n            search_terms = action_content\\n            page_num = 1\\n        elif action.startswith(\\'click[\\'):\\n            if action.startswith(\\'click[item -\\'):\\n                prod_title = action_content[len(\"item -\"):].strip()\\n                found = False\\n                for key in title_to_asin_map:\\n                    if prod_title == key:\\n                        asin = title_to_asin_map[key]\\n                        page_type = Page.ITEM_PAGE\\n                        visited_asins.add(asin)\\n                        found = True\\n                        break\\n                if not found:\\n                    raise Exception(\"Product to click not found\")\\n                    \\n            elif any(x.value in action for x in [Page.DESC, Page.FEATURES, Page.REVIEWS]):\\n                page_type = Page.SUB_PAGE\\n                sub_page_type = Page(action_content.lower())\\n                \\n            elif action == \\'click[< prev]\\':\\n                if sub_page_type is not None:\\n                    page_type, sub_page_type = Page.ITEM_PAGE, None\\n                elif prev_page_type == Page.ITEM_PAGE:\\n                    page_type = Page.RESULTS\\n                    options, clicked_options = {}, set()\\n                elif prev_page_type == Page.RESULTS and page_num > 1:\\n                    page_type = Page.RESULTS\\n                    page_num -= 1\\n                    \\n            elif action == \\'click[next >]\\':\\n                page_type = Page.RESULTS\\n                page_num += 1\\n                \\n            elif action.lower() == \\'click[back to search]\\':\\n                page_type = Page.SEARCH\\n                \\n            elif action == \\'click[buy now]\\':\\n                return get_return_value(env, asin, options, search_terms, page_num, product_map[asin])\\n            \\n            elif prev_page_type == Page.ITEM_PAGE:\\n                found = False\\n                for opt_name, opt_values in product_map[asin][\"options\"].items():\\n                    if action_content in opt_values:\\n                        options[opt_name] = action_content\\n                        page_type = Page.ITEM_PAGE\\n                        clicked_options.add(action_content)\\n                        found = True\\n                        break\\n                if not found:\\n                    raise Exception(\"Unrecognized action: \" + action)\\n        else:\\n            raise Exception(\"Unrecognized action:\" + action)\\n        \\n        if verbose:\\n            print(f\"Parsing {page_type.value} page...\")\\n        \\n        # URL -> Real HTML -> Dict of Info\\n        if page_type == Page.RESULTS:\\n            if search_terms in search_results_cache:\\n                data = search_results_cache[search_terms]\\n                if verbose:\\n                    print(f\"Loading cached results page for \\\\\"{search_terms}\\\\\"\")\\n            else:\\n                begin = time.time()\\n                if env == \\'amazon\\':\\n                    data = parse_results_amz(search_terms, page_num, verbose)\\n                if env == \\'webshop\\':\\n                    data = parse_results_ws(search_terms, page_num, verbose)\\n                if env == \\'ebay\\':\\n                    data = parse_results_ebay(search_terms, page_num, verbose)\\n                end = time.time()\\n                if verbose:\\n                    print(f\"Parsing search results took {end-begin} seconds\")\\n\\n                search_results_cache[search_terms] = data\\n                for d in data:\\n                    title_to_asin_map[d[\\'Title\\']] = d[\\'asin\\']\\n        elif page_type == Page.ITEM_PAGE or page_type == Page.SUB_PAGE:\\n            if asin in product_map:\\n                if verbose:\\n                    print(\"Loading cached item page for\", asin)\\n                data = product_map[asin]\\n            else:\\n                begin = time.time()\\n                if env == \\'amazon\\':\\n                    data = parse_item_page_amz(asin, verbose)\\n                if env == \\'webshop\\':\\n                    data = parse_item_page_ws(asin, search_terms, page_num, options, verbose)\\n                if env == \\'ebay\\':\\n                    data = parse_item_page_ebay(asin, verbose)\\n                end = time.time()\\n                if verbose:\\n                    print(\"Parsing item page took\", end-begin, \"seconds\")\\n                product_map[asin] = data\\n        elif page_type == Page.SEARCH:\\n            if verbose:\\n                print(\"Executing search\")\\n            obs = \"Amazon Shopping Game\\\\nInstruction:\" + goal + \"\\\\n[button] search [button]\"\\n            info = {\\'valid\\': [\\'search[stuff]\\'], \\'image_feat\\': torch.zeros(512)}\\n            continue\\n        else:\\n            raise Exception(\"Page of type `\", page_type, \"` not found\")\\n\\n        # Dict of Info -> Fake HTML -> Text Observation\\n        begin = time.time()\\n        html_str = dict_to_fake_html(data, page_type, asin, sub_page_type, options, product_map, goal)\\n        obs = convert_html_to_text(html_str, simple=False, clicked_options=clicked_options, visited_asins=visited_asins)\\n        end = time.time()\\n        if verbose:\\n            print(\"[Page Info -> WebShop HTML -> Observation] took\", end-begin, \"seconds\")\\n\\n        # Dict of Info -> Valid Action State (Info)\\n        begin = time.time()\\n        prod_arg = product_map if page_type == Page.ITEM_PAGE else data\\n        info = convert_dict_to_actions(page_type, prod_arg, asin, page_num)\\n        end = time.time()\\n        if verbose:\\n            print(\"Extracting available actions took\", end-begin, \"seconds\")\\n        \\n        if i == 50:\\n            return get_return_value(env, asin, options, search_terms, page_num, product_map[asin])\\n',\n",
       "  'function_name': 'run_episode',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/app.py'},\n",
       " {'code': 'def parse_results_ebay(query, page_num=None, verbose=True):\\n    query_string = \\'+\\'.join(query.split())\\n    page_num = 1 if page_num is None else page_num\\n    url = f\\'https://www.ebay.com/sch/i.html?_nkw={query_string}&_pgn={page_num}\\'\\n    if verbose:\\n        print(f\"Search Results URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.text, \\'html.parser\\')\\n    products = soup.select(\\'.s-item__wrapper.clearfix\\')\\n\\n    results = []\\n    for item in products[:NUM_PROD_LIMIT]:\\n        title = item.select_one(\\'.s-item__title\\').text.strip()\\n        if \"shop on ebay\" in title.lower():\\n            # Skip \"Shop on ebay\" product title\\n            continue\\n        link = item.select_one(\\'.s-item__link\\')[\\'href\\']\\n        asin = link.split(\"?\")[0][len(\"https://www.ebay.com/itm/\"):]\\n\\n        try:\\n            price = item.select_one(\\'.s-item__price\\').text\\n            if \"to\" in price:\\n                prices = price.split(\" to \")\\n                price = [p.strip(\"$\") for p in prices]\\n        except:\\n            price = None\\n        \\n        results.append({\\n            \"asin\": asin,\\n            \"Title\": title,\\n            \"Price\": price\\n        })\\n    if verbose:\\n        print(f\"Scraped {len(results)} products\")\\n    return results\\n\\n',\n",
       "  'function_name': 'parse_results_ebay',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def parse_item_page_ebay(asin, verbose=True):\\n    product_dict = {}\\n    product_dict[\"asin\"] = asin\\n    \\n    url = f\"https://www.ebay.com/itm/{asin}\"\\n    if verbose:\\n        print(f\"Item Page URL: {url}\")\\n    begin = time.time()\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    end = time.time()\\n    if verbose:\\n        print(f\"Item page scraping took {end-begin} seconds\")\\n    soup = BeautifulSoup(webpage.content, \"html.parser\")\\n\\n    # Title\\n    try:\\n        product_dict[\"Title\"] = soup.find(\\'h1\\', {\\'class\\': \\'x-item-title__mainTitle\\'}).text.strip()\\n    except:\\n        product_dict[\"Title\"] = \"N/A\"\\n\\n    # Price: Get price string, extract decimal numbers from string\\n    try:\\n        price_str = soup.find(\\'div\\', {\\'class\\': \\'mainPrice\\'}).text\\n        prices = re.findall(\\'\\\\d*\\\\.?\\\\d+\\', price_str)\\n        product_dict[\"Price\"] = prices[0]\\n    except:\\n        product_dict[\"Price\"] = \"N/A\"\\n\\n     # Main Image\\n    try:\\n        img_div = soup.find(\\'div\\', {\\'id\\': \\'mainImgHldr\\'})\\n        img_link = img_div.find(\\'img\\', {\\'id\\': \\'icImg\\'})[\"src\"]\\n        product_dict[\"MainImage\"] = img_link\\n    except:\\n        product_dict[\"MainImage\"] = \"\"\\n    \\n    # Rating\\n    try:\\n        rating = soup.find(\\'span\\', {\\'class\\': \\'reviews-star-rating\\'})[\"title\"].split()[0]\\n    except:\\n        rating = None\\n    product_dict[\"Rating\"] = rating\\n\\n    # Options\\n    options, options_to_images = {}, {} # TODO: options_to_images possible?\\n    try:\\n        option_blocks = soup.findAll(\\'select\\', {\\'class\\': \\'msku-sel\\'})\\n        for block in option_blocks:\\n            name = block[\"name\"].strip().strip(\":\")\\n            option_tags = block.findAll(\"option\")\\n            opt_list = []\\n            for option_tag in option_tags:\\n                if \"select\" not in option_tag.text.lower():\\n                    # Do not include \"- select -\" (aka `not selected`) choice\\n                    opt_list.append(option_tag.text)\\n            options[name] = opt_list\\n    except:\\n        options = {}\\n    product_dict[\"options\"], product_dict[\"option_to_image\"] = options, options_to_images\\n\\n    # Description\\n    desc = None\\n    try:\\n        # Ebay descriptions are shown in `iframe`s\\n        desc_link = soup.find(\\'iframe\\', {\\'id\\': \\'desc_ifr\\'})[\"src\"]\\n        desc_webpage = requests.get(desc_link, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n        desc_soup = BeautifulSoup(desc_webpage.content, \"html.parser\")\\n        desc = \\' \\'.join(desc_soup.text.split())\\n    except:\\n        desc = \"N/A\"\\n    product_dict[\"Description\"] = desc\\n\\n    # Features\\n    features = None\\n    try:\\n        features = soup.find(\\'div\\', {\\'class\\': \\'x-about-this-item\\'}).text\\n    except:\\n        features = \"N/A\"\\n    product_dict[\"BulletPoints\"] = features\\n\\n    return product_dict\\n    \\n',\n",
       "  'function_name': 'parse_item_page_ebay',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def parse_results_ws(query, page_num=None, verbose=True):\\n    query_string = \\'+\\'.join(query.split())\\n    page_num = 1 if page_num is None else page_num\\n    url = (\\n        f\\'{WEBSHOP_URL}/search_results/{WEBSHOP_SESSION}/\\'\\n        f\\'{query_string}/{page_num}\\'\\n    )\\n    if verbose:\\n        print(f\"Search Results URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.content, \\'html.parser\\')\\n    products = soup.findAll(\\'div\\', {\\'class\\': \\'list-group-item\\'})\\n\\n    results = []\\n    for product in products:\\n        asin = product.find(\\'a\\', {\\'class\\': \\'product-link\\'})\\n        title = product.find(\\'h4\\', {\\'class\\': \\'product-title\\'})\\n        price = product.find(\\'h5\\', {\\'class\\': \\'product-price\\'})\\n\\n        if \"\\\\n\" in title:\\n            title = title.text.split(\"\\\\n\")[0].strip()\\n        else:\\n            title = title.text.strip().strip(\"\\\\n\")\\n\\n        if \"to\" in price.text:\\n            # Parse if price presented as range\\n            prices = price.text.split(\" to \")\\n            price = [float(p.strip().strip(\"\\\\n$\")) for p in prices]\\n        else:\\n            price = float(price.text.strip().strip(\"\\\\n$\"))\\n\\n        results.append({\\n            \"asin\": asin.text,\\n            \"Title\": title,\\n            \"Price\": price\\n        })\\n\\n    if verbose:\\n        print(f\"Scraped {len(results)} products\")\\n    return results\\n\\n',\n",
       "  'function_name': 'parse_results_ws',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def parse_item_page_ws(asin, query, page_num, options, verbose=True):\\n    product_dict = {}\\n    product_dict[\"asin\"] = asin\\n\\n    query_string = \\'+\\'.join(query.split())\\n    options_string = json.dumps(options)\\n    url = (\\n        f\\'{WEBSHOP_URL}/item_page/{WEBSHOP_SESSION}/\\'\\n        f\\'{asin}/{query_string}/{page_num}/{options_string}\\'\\n    )\\n    if verbose:\\n        print(f\"Item Page URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.content, \\'html.parser\\')\\n\\n    # Title, Price, Rating, and MainImage\\n    product_dict[\"Title\"] = soup.find(\\'h2\\').text\\n    \\n    h4_headers = soup.findAll(\"h4\")\\n    for header in h4_headers:\\n        text = header.text\\n        if \"Price\" in text:\\n            product_dict[\"Price\"] = text.split(\":\")[1].strip().strip(\"$\")\\n        elif \"Rating\" in text:\\n            product_dict[\"Rating\"] = text.split(\":\")[1].strip()\\n    \\n    product_dict[\"MainImage\"] = soup.find(\\'img\\')[\\'src\\']\\n\\n    # Options\\n    options, options_to_image = {}, {}\\n    option_blocks = soup.findAll(\"div\", {\\'class\\': \\'radio-toolbar\\'})\\n    for block in option_blocks:\\n        name = block.find(\"input\")[\"name\"]\\n        labels = block.findAll(\"label\")\\n        inputs = block.findAll(\"input\")\\n        opt_list = []\\n        for label, input in zip(labels, inputs):\\n            opt = label.text\\n            opt_img_path = input[\"onclick\"].split(\"href=\")[1].strip(\\'\\\\\\';\\')\\n            opt_img_url = f\\'{WEBSHOP_URL}{opt_img_path}\\'\\n\\n            opt_list.append(opt)\\n            options_to_image[opt] = opt_img_url\\n        options[name] = opt_list\\n    product_dict[\"options\"] = options\\n    product_dict[\"option_to_image\"] = options_to_image\\n\\n    # Description\\n    url = (\\n        f\\'{WEBSHOP_URL}/item_sub_page/{WEBSHOP_SESSION}/\\'\\n        f\\'{asin}/{query_string}/{page_num}/Description/{options_string}\\'\\n    )\\n    if verbose:\\n        print(f\"Item Description URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.content, \\'html.parser\\')\\n    product_dict[\"Description\"] = soup.find(name=\"p\", attrs={\\'class\\': \\'product-info\\'}).text.strip()\\n\\n    # Features\\n    url = (\\n        f\\'{WEBSHOP_URL}/item_sub_page/{WEBSHOP_SESSION}/\\'\\n        f\\'{asin}/{query_string}/{page_num}/Features/{options_string}\\'\\n    )\\n    if verbose:\\n        print(f\"Item Features URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.content, \\'html.parser\\')\\n    bullets = soup.find(name=\"ul\").findAll(name=\"li\")\\n    product_dict[\"BulletPoints\"] = \\'\\\\n\\'.join([b.text.strip() for b in bullets])\\n\\n    return product_dict\\n\\n',\n",
       "  'function_name': 'parse_item_page_ws',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def parse_results_amz(query, page_num=None, verbose=True):\\n    url = \\'https://www.amazon.com/s?k=\\' + query.replace(\" \", \"+\")\\n    if page_num is not None:\\n        url += \"&page=\" + str(page_num)\\n    if verbose:\\n        print(f\"Search Results URL: {url}\")\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    soup = BeautifulSoup(webpage.content, \\'html.parser\\')\\n    products = soup.findAll(\\'div\\', {\\'data-component-type\\': \\'s-search-result\\'})\\n    if products is None:\\n        temp = open(DEBUG_HTML, \"w\")\\n        temp.write(str(soup))\\n        temp.close()\\n        raise Exception(\"Couldn\\'t find search results page, outputted html for inspection\")\\n    results = []\\n\\n    for product in products[:NUM_PROD_LIMIT]:\\n        asin = product[\\'data-asin\\']\\n        title = product.find(\"h2\", {\\'class\\': \"a-size-mini\"})\\n        price_div = product.find(\"div\", {\\'class\\': \\'s-price-instructions-style\\'})\\n        price = price_div.find(\"span\", {\\'class\\': \\'a-offscreen\\'})\\n\\n        result = {\\n            \\'asin\\': asin,\\n            \\'Title\\': title.text.strip(),\\n            \\'Price\\': price.text.strip().strip(\"$\")\\n        }\\n        results.append(result)\\n    if verbose:\\n        print(\"Scraped\", len(results), \"products\")\\n    return results\\n\\n',\n",
       "  'function_name': 'parse_results_amz',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def parse_item_page_amz(asin, verbose=True):\\n    product_dict = {}\\n    product_dict[\"asin\"] = asin\\n\\n    url = f\"https://www.amazon.com/dp/{asin}\"\\n    if verbose:\\n        print(\"Item Page URL:\", url)\\n    begin = time.time()\\n    webpage = requests.get(url, headers={\\'User-Agent\\': HEADER_, \\'Accept-Language\\': \\'en-US, en;q=0.5\\'})\\n    end = time.time()\\n    if verbose:\\n        print(f\"Item page scraping took {end-begin} seconds\")\\n    soup = BeautifulSoup(webpage.content, \"html.parser\")\\n\\n    # Title\\n    try:\\n        title = soup.find(\"span\", attrs={\"id\": \\'productTitle\\'})\\n        title = title.string.strip().replace(\\',\\', \\'\\')\\n    except AttributeError:\\n        title = \"N/A\"\\n    product_dict[\"Title\"] = title\\n \\n    # Price\\n    try:\\n        parent_price_span = soup.find(name=\"span\", class_=\"apexPriceToPay\")\\n        price_span = parent_price_span.find(name=\"span\", class_=\"a-offscreen\")\\n        price = float(price_span.getText().replace(\"$\", \"\"))\\n    except AttributeError:\\n        price = \"N/A\"\\n    product_dict[\"Price\"] = price\\n\\n    # Rating\\n    try:\\n        rating = soup.find(name=\"span\", attrs={\"id\": \"acrPopover\"})\\n        if rating is None:\\n            rating = \"N/A\"\\n        else:\\n            rating = rating.text\\n    except AttributeError:\\n        rating = \"N/A\"\\n    product_dict[\"Rating\"] = rating.strip(\"\\\\n\").strip()\\n \\n    # Features\\n    try:\\n        features = soup.find(name=\"div\", attrs={\"id\": \"feature-bullets\"}).text\\n    except AttributeError:\\n        features = \"N/A\"\\n    product_dict[\"BulletPoints\"] = features\\n    \\n    # Description\\n    try:\\n        desc_body = soup.find(name=\"div\", attrs={\"id\": \"productDescription_feature_div\"})\\n        desc_div = desc_body.find(name=\"div\", attrs={\"id\": \"productDescription\"})\\n        desc_ps = desc_div.findAll(name=\"p\")\\n        desc = \" \".join([p.text for p in desc_ps])\\n    except AttributeError:\\n        desc = \"N/A\"\\n    product_dict[\"Description\"] = desc.strip()\\n\\n    # Main Image\\n    try:\\n        imgtag = soup.find(\"img\", {\"id\":\"landingImage\"})\\n        imageurl = dict(imgtag.attrs)[\"src\"]\\n    except AttributeError:\\n        imageurl = \"\"\\n    product_dict[\"MainImage\"] = imageurl\\n\\n    # Options\\n    options, options_to_image = {}, {}\\n    try:\\n        option_body = soup.find(name=\\'div\\', attrs={\"id\": \"softlinesTwister_feature_div\"})\\n        if option_body is None:\\n            option_body = soup.find(name=\\'div\\', attrs={\"id\": \"twister_feature_div\"})\\n        option_blocks = option_body.findAll(name=\\'ul\\')\\n        for block in option_blocks:\\n            name = json.loads(block[\"data-a-button-group\"])[\"name\"]\\n            # Options\\n            opt_list = []\\n            for li in block.findAll(\"li\"):\\n                img = li.find(name=\"img\")\\n                if img is not None:\\n                    opt = img[\"alt\"].strip()\\n                    opt_img = img[\"src\"]\\n                    if len(opt) > 0:\\n                        options_to_image[opt] = opt_img\\n                else:\\n                    opt = li.text.strip()\\n                if len(opt) > 0:\\n                    opt_list.append(opt)\\n            options[name.replace(\"_name\", \"\").replace(\"twister_\", \"\")] = opt_list\\n    except AttributeError:\\n        options = {}\\n    product_dict[\"options\"], product_dict[\"option_to_image\"] = options, options_to_image\\n    return product_dict\\n\\n',\n",
       "  'function_name': 'parse_item_page_amz',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def convert_html_to_text(html, simple=False, clicked_options=None, visited_asins=None):\\n    def tag_visible(element):\\n        ignore = {\\'style\\', \\'script\\', \\'head\\', \\'title\\', \\'meta\\', \\'[document]\\'}\\n        return (\\n            element.parent.name not in ignore and not isinstance(element, Comment)\\n        )\\n    html_obj = BeautifulSoup(html, \\'html.parser\\')\\n    texts = html_obj.findAll(text=True)\\n    visible_texts = filter(tag_visible, texts)\\n    if simple:\\n        return \\' [SEP] \\'.join(t.strip() for t in visible_texts if t != \\'\\\\n\\')\\n    else:\\n        observation = \\'\\'\\n        for t in visible_texts:\\n            if t == \\'\\\\n\\': continue\\n            if t.parent.name == \\'button\\':  # button\\n                processed_t = f\\'[button] {t} [button]\\'\\n            elif t.parent.name == \\'label\\':  # options\\n                if f\\'{t}\\' in clicked_options:\\n                    processed_t = f\\'  [clicked button] {t} [clicked button]\\'\\n                    observation = f\\'You have clicked {t}.\\\\n\\' + observation\\n                else:\\n                    processed_t = f\\'  [button] {t} [button]\\'\\n            elif t.parent.get(\\'class\\') == [\"product-link\"]: # asins\\n                if f\\'{t}\\' in visited_asins:\\n                    processed_t = f\\'\\\\n[clicked button] {t} [clicked button]\\'\\n                else:\\n                    processed_t = f\\'\\\\n[button] {t} [button]\\'\\n            else: # regular, unclickable text\\n                processed_t =  str(t)\\n            observation += processed_t + \\'\\\\n\\'\\n        return observation\\n\\n',\n",
       "  'function_name': 'convert_html_to_text',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def convert_dict_to_actions(page_type, products=None, asin=None, page_num=None) -> dict:\\n    info = {\"valid\": []}\\n    if page_type == Page.RESULTS:\\n        info[\"valid\"] = [\\'click[back to search]\\']\\n        if products is None or page_num is None:\\n            print(page_num)\\n            print(products)\\n            raise Exception(\\'Provide `products`, `page_num` to get `results` valid actions\\')\\n        # Decide whether to add `next >` as clickable based on # of search results\\n        if len(products) > 10:\\n            info[\"valid\"].append(\\'click[next >]\\')\\n        # Add `< prev` as clickable if not first page of search results\\n        if page_num > 1:\\n            info[\"valid\"].append(\\'click[< prev]\\')\\n        for product in products:\\n            info[\"valid\"].append(\"click[item - \" + product[\"Title\"] + \"]\")\\n    if page_type == Page.ITEM_PAGE:\\n        if products is None or asin is None:\\n            raise Exception(\\'Provide `products` and `asin` to get `item_page` valid actions\\')\\n        info[\"valid\"] = [\\'click[back to search]\\', \\'click[< prev]\\', \\'click[description]\\',\\\\\\n            \\'click[features]\\', \\'click[buy now]\\'] # To do: reviews\\n        if \"options\" in products[asin]:\\n            for key, values in products[asin][\"options\"].items():\\n                for value in values:\\n                    info[\"valid\"].append(\"click[\" + value + \"]\")\\n    if page_type == Page.SUB_PAGE:\\n        info[\"valid\"] = [\\'click[back to search]\\', \\'click[< prev]\\']\\n    info[\\'image_feat\\'] = torch.zeros(512)\\n    return info',\n",
       "  'function_name': 'convert_dict_to_actions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/predict_help.py'},\n",
       " {'code': 'def read_html_template(path):\\n    with open(path) as f:\\n        template = f.read()\\n    return template\\n',\n",
       "  'function_name': 'read_html_template',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': 'def index(session_id, **kwargs):\\n    print(\"Hello world\")\\n',\n",
       "  'function_name': 'index',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': \"def search_results(data):\\n    path = os.path.join(TEMPLATE_DIR, 'results_page.html')\\n    html = render_template_string(\\n        read_html_template(path=path),\\n        session_id=SESSION_ID,\\n        products=data,\\n        keywords=KEYWORDS,\\n        page=1,\\n        total=len(data),\\n        instruction_text=QUERY,\\n    )\\n    return html\\n\",\n",
       "  'function_name': 'search_results',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': \"def item_page(session_id, asin, keywords, page, options):\\n    path = os.path.join(TEMPLATE_DIR, 'item_page.html')\\n    html = render_template_string(\\n        read_html_template(path=path),\\n        session_id=session_id,\\n        product_info=product_map[asin],\\n        keywords=keywords,\\n        page=page,\\n        asin=asin,\\n        options=options,\\n        instruction_text=QUERY\\n    )\\n    return html\\n\",\n",
       "  'function_name': 'item_page',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': 'def item_sub_page(session_id, asin, keywords, page, sub_page, options):\\n    path = os.path.join(TEMPLATE_DIR, sub_page.value.lower() + \"_page.html\")\\n    html = render_template_string(\\n        read_html_template(path),\\n        session_id=session_id, \\n        product_info=product_map[asin],\\n        keywords=keywords,\\n        page=page,\\n        asin=asin,\\n        options=options,\\n        instruction_text=QUERY\\n    )\\n    return html\\n',\n",
       "  'function_name': 'item_sub_page',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': 'def done(asin, options, session_id, **kwargs):\\n    path = os.path.join(TEMPLATE_DIR, \\'done_page.html\\')\\n    html = render_template_string(\\n        read_html_template(path),\\n        session_id=session_id,\\n        reward=1,\\n        asin=asin,\\n        options=product_map[asin][\"options\"],\\n        reward_info=kwargs.get(\\'reward_info\\'),\\n        goal_attrs=kwargs.get(\\'goal_attrs\\'),\\n        purchased_attrs=kwargs.get(\\'purchased_attrs\\'),\\n        goal=kwargs.get(\\'goal\\'),\\n        mturk_code=kwargs.get(\\'mturk_code\\'),\\n        query=kwargs.get(\\'query\\'),\\n        category=kwargs.get(\\'category\\'),\\n        product_category=kwargs.get(\\'product_category\\'),\\n    )\\n    return html\\n    ',\n",
       "  'function_name': 'done',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': 'def dict_to_fake_html(data, page_type, asin=None, sub_page_type=None, options=None, prod_map={}, query=\"\"):\\n    global QUERY, product_map\\n    QUERY = query\\n    product_map = prod_map\\n    with app.app_context(), app.test_request_context():\\n        if page_type == Page.RESULTS:\\n            return search_results(data)\\n        if page_type == Page.ITEM_PAGE:\\n            return item_page(SESSION_ID, asin, KEYWORDS, 1, options)\\n        if page_type == Page.SUB_PAGE:\\n            if sub_page_type is not None:\\n                return item_sub_page(SESSION_ID, asin, KEYWORDS, 1, sub_page_type, options)\\n            else:\\n                raise Exception(\"Sub page of type\", sub_page_type, \"unrecognized\")',\n",
       "  'function_name': 'dict_to_fake_html',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/webshop/transfer/webshop_lite.py'},\n",
       " {'code': 'def run_cmd(cmd_string, timeout=600):\\n    #print(\"命令为：\" + cmd_string)\\n    p = subprocess.Popen(cmd_string, stderr=subprocess.DEVNULL, stdout=subprocess.PIPE, shell=True, close_fds=True,\\n                         start_new_session=True)\\n    format = \\'utf-8\\'\\n    if platform.system() == \"Windows\":\\n        format = \\'gbk\\'\\n    \\n    #time.sleep(2)\\n    \\n    #p.kill()\\n    \\n    #stdout = p.stdout.read()\\n    #stderr = p.stderr.read()\\n    \\n    #input(\">>> \")\\n    #print(stdout)\\n    #input(\">>> \")\\n    #print(stderr)\\n\\n    # exit(1)\\n    \\n    try:\\n        (msg, errs) = p.communicate(timeout=timeout)\\n        ret_code = p.poll()\\n        if ret_code:\\n            code = 1\\n            msg = \"[Error]Called Error ： \" + str(msg.decode(format))\\n        else:\\n            code = 0\\n            msg = str(msg.decode(format))\\n    except subprocess.TimeoutExpired:\\n        # 注意：不能只使用p.kill和p.terminate，无法杀干净所有的子进程，需要使用os.killpg\\n        p.kill()\\n        p.terminate()\\n        os.killpg(p.pid, signal.SIGTERM)\\n \\n        # 注意：如果开启下面这两行的话，会等到执行完成才报超时错误，但是可以输出执行结果\\n        # (outs, errs) = p.communicate()\\n        # print(outs.decode(\\'utf-8\\'))\\n \\n        code = 1\\n        msg = \"[ERROR]Timeout Error : Command \\'\" + cmd_string + \"\\' timed out after \" + str(timeout) + \" seconds\"\\n    except Exception as e:\\n        code = 1\\n        msg = \"[ERROR]Unknown Error : \" + str(e)\\n \\n    return code, msg',\n",
       "  'function_name': 'run_cmd',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/utils.py'},\n",
       " {'code': 'def process_file(path):\\n    meta_json = json.load(open(os.path.join(path, \\'meta.json\\')))\\n    replay = json.load(open(os.path.join(path, \\'replay.json\\')))\\n    win = [1, 0] if meta_json[\"winner\"] == \\'0\\' else [0, 1]\\n    damage = [0, 0]\\n    takedown = [0, 0]\\n    try_times = [0, 0]\\n    full_play = [1, 1]\\n    round_num = len(replay) - 1\\n    \\n    last_round = replay[-2]\\n    \\n    if \\'errors\\' in last_round:\\n        error = last_round[\\'errors\\'][0]\\n        error_player = error[\\'player\\']\\n        full_play[error_player] = 0\\n    \\n    if last_round[\\'players\\'][0][\\'id\\'] == 0:\\n        for fish_0 in last_round[\\'players\\'][0][\\'fight_fish\\']:\\n            damage[1] += 400 - max(fish_0[\\'hp\\'], 0)\\n            takedown[1] += 1 if fish_0[\\'hp\\'] <= 0 else 0\\n        for fish_1 in last_round[\\'players\\'][1][\\'fight_fish\\']:\\n            damage[0] += 400 - max(fish_1[\\'hp\\'], 0)\\n            takedown[0] += 1 if fish_1[\\'hp\\'] <= 0 else 0\\n    else:\\n        for fish_0 in last_round[\\'players\\'][0][\\'fight_fish\\']:\\n            damage[0] += 400 - max(fish_0[\\'hp\\'], 0)\\n            takedown[0] += 1 if fish_0[\\'hp\\'] <= 0 else 0\\n        for fish_1 in last_round[\\'players\\'][1][\\'fight_fish\\']:\\n            damage[1] += 400 - max(fish_1[\\'hp\\'], 0)\\n            takedown[1] += 1 if fish_1[\\'hp\\'] <= 0 else 0\\n    \\n    if os.path.exists(os.path.join(path, \\'thinking_process_0.jsonl\\')):\\n        for data in open(os.path.join(path, \\'thinking_process_0.jsonl\\')).readlines():\\n            data = json.loads(data)\\n            try_times[0] += data[\\'try_times\\']\\n    if os.path.exists(os.path.join(path, \\'guess_process_0.jsonl\\')):\\n        for data in open(os.path.join(path, \\'guess_process_0.jsonl\\')).readlines():\\n            data = json.loads(data)\\n            try_times[0] += data[\\'try_times\\']\\n    \\n    if os.path.exists(os.path.join(path, \\'thinking_process_1.jsonl\\')):\\n        for data in open(os.path.join(path, \\'thinking_process_1.jsonl\\')).readlines():\\n            data = json.loads(data)\\n            try_times[1] += data[\\'try_times\\']\\n    if os.path.exists(os.path.join(path, \\'guess_process_1.jsonl\\')):\\n        for data in open(os.path.join(path, \\'guess_process_1.jsonl\\')).readlines():\\n            data = json.loads(data)\\n            try_times[1] += data[\\'try_times\\']\\n    \\n    return full_play, try_times, takedown, damage, win, round_num\\n',\n",
       "  'function_name': 'process_file',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/cal_metric.py'},\n",
       " {'code': \"def calculate(result_dir, agent):\\n    total_full_play = [0, 0]\\n    total_try_times = [0, 0]\\n    total_takedown = [0, 0]\\n    total_damage = [0, 0]\\n    total_win = [0, 0]\\n    total_round_num = 0\\n    test_times = 0\\n    \\n    for filename in os.listdir(result_dir):\\n        try:\\n            full_play, try_times, takedown, damage, win, round_num = process_file(os.path.join(result_dir, filename))\\n        except:\\n            continue\\n        \\n        total_full_play[0] += full_play[0]\\n        total_full_play[1] += full_play[1]\\n        \\n        total_try_times[0] += try_times[0]\\n        total_try_times[1] += try_times[1]\\n        \\n        total_takedown[0] += takedown[0]\\n        total_takedown[1] += takedown[1]\\n        \\n        total_damage[0] += damage[0]\\n        total_damage[1] += damage[1]\\n        \\n        total_win[0] += win[0]\\n        total_win[1] += win[1]\\n        \\n        total_round_num += round_num\\n        \\n        test_times += 1\\n    return {\\n        'full_play': total_full_play[agent],\\n        'try_times': total_try_times[agent],\\n        'takedown': total_takedown[agent],\\n        'damage': total_damage[agent],\\n        'win_round': total_win[agent],\\n        'round_num': total_round_num,\\n        'test_times': test_times\\n    }\\n            \\n\",\n",
       "  'function_name': 'calculate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/cal_metric.py'},\n",
       " {'code': 'def run_cmd(cmd_string, timeout=600):\\n    print(\"命令为：\" + cmd_string)\\n    p = subprocess.Popen(cmd_string, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, shell=True, close_fds=True,\\n                         start_new_session=True)\\n \\n    format = \\'utf-8\\'\\n    if platform.system() == \"Windows\":\\n        format = \\'gbk\\'\\n \\n    try:\\n        (msg, errs) = p.communicate(timeout=timeout)\\n        ret_code = p.poll()\\n        if ret_code:\\n            code = 1\\n            msg = \"[Error]Called Error ： \" + str(msg.decode(format))\\n        else:\\n            code = 0\\n            msg = str(msg.decode(format))\\n    except subprocess.TimeoutExpired:\\n        # 注意：不能只使用p.kill和p.terminate，无法杀干净所有的子进程，需要使用os.killpg\\n        p.kill()\\n        p.terminate()\\n        os.killpg(p.pid, signal.SIGTERM)\\n \\n        # 注意：如果开启下面这两行的话，会等到执行完成才报超时错误，但是可以输出执行结果\\n        # (outs, errs) = p.communicate()\\n        # print(outs.decode(\\'utf-8\\'))\\n \\n        code = 1\\n        msg = \"[ERROR]Timeout Error : Command \\'\" + cmd_string + \"\\' timed out after \" + str(timeout) + \" seconds\"\\n    except Exception as e:\\n        code = 1\\n        msg = \"[ERROR]Unknown Error : \" + str(e)\\n \\n    return code, msg\\n',\n",
       "  'function_name': 'run_cmd',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/run_all.py'},\n",
       " {'code': 'def batch_test(ai, base, stage, test_times):\\n    \\n    for i in range(test_times):\\n        stamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime(int(time.time())))\\n        save_dir = f\\'{result_dir}/{stage}_{ai.name}_{base}/{stamp}\\'\\n        os.makedirs(save_dir)\\n\\n        cmd = f\\'python judger.py {root_dir}/logic/bin/main3 %s %s config {save_dir}/replay.json\\'\\n        msg = run_cmd(cmd % (location[\"ai\"] % (ai, stage, 0, save_dir), location[base] % (stage, 1, save_dir)))[1]\\n        time.sleep(1)\\n        print(msg)\\n        \\n        meta = {\\'ai1\\': ai.name, \\'ai2\\': base}\\n        \\n        if \"\\\\\"0\\\\\" : 0\" in msg:\\n            meta[\\'winner\\'] = \\'1\\'\\n        else:\\n            meta[\\'winner\\'] = \\'0\\'\\n                \\n        with open(save_dir + \\'/meta.json\\', \\'w\\') as f:\\n            f.write(json.dumps(meta))\\n',\n",
       "  'function_name': 'batch_test',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/run_all.py'},\n",
       " {'code': 'def get_llm(ai, test_time=50):\\n    output_path = \"result.csv\"\\n    ret = []\\n    for stage in [2, 1]:\\n        # run and eval model\\n        for base in base_model:\\n            print(stage, ai, base)\\n            batch_test(ai, base, stage, test_time)\\n            dict1 = calculate(\"../result/%d_%s_%s\" % (stage, ai.name, base), 0)\\n            ret.append({\\n                \\'stage\\': stage,\\n                \\'ai\\': ai.name,\\n                \\'base_model\\': base,  \\n                \\'first\\': True,\\n                \\'result\\': dict1,\\n            })\\n            \\n            dict2 = calculate(\"../result/%d_%s_%s\" % (stage, base, ai.name), 1)\\n            ret.append({\\n                \\'stage\\': stage,\\n                \\'ai\\': ai.name,\\n                \\'base_model\\': base,  \\n                \\'first\\': False,\\n                \\'result\\': dict2,\\n            })\\n    return ret',\n",
       "  'function_name': 'get_llm',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/run_all.py'},\n",
       " {'code': 'def system_convert():\\n    \\'\\'\\'\\n    获取命令行参数\\n    \\'\\'\\'\\n    argv_len = len(sys.argv)\\n    logic_command = sys.argv[1].replace(\"+\", \" \")\\n    path_list = [command_str.replace(\"+\", \" \") for command_str in sys.argv[2:argv_len-2]]\\n    replay_path = sys.argv[argv_len-1]\\n    return logic_command, path_list, replay_path\\n',\n",
       "  'function_name': 'system_convert',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/judger.py'},\n",
       " {'code': 'def convert_byte(data_str):\\n    \\'\\'\\'\\n    传输数据的时候加数据长度作为数据头\\n    \\'\\'\\'\\n    msg_len = len(data_str)\\n    msg = msg_len.to_bytes(4, byteorder=\\'big\\', signed=True)\\n    msg += bytes(data_str, encoding=\"utf8\")\\n    return msg\\n',\n",
       "  'function_name': 'convert_byte',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/judger.py'},\n",
       " {'code': \"def main():\\n    '''\\n    主函数\\n    '''\\n    std_buffer = std_thread()\\n    if len(sys.argv) == 1: #pragma: no cover\\n        std_buffer.run_buffer()\\n    elif sys.argv[1] == 'test_mode':#pragma: no cover\\n        std_buffer.run_test()\\n    else:\\n        logic, path_list, replay_path = system_convert()\\n        std_buffer.run_game(logic, path_list, replay_path)\\n\",\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/judger.py'},\n",
       " {'code': 'def rserver_convert_byte(data_str):\\n    \\'\\'\\'\\n    传输数据的时候加数据长度作为数据头\\n    \\'\\'\\'\\n    message_len = len(data_str)\\n    message = message_len.to_bytes(4, byteorder=\\'big\\', signed=True)\\n    message += bytes(data_str, encoding=\"utf8\")\\n    return message\\n\\n',\n",
       "  'function_name': 'rserver_convert_byte',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/judger/rserver.py'},\n",
       " {'code': 'def fish_map(fish_id):\\n    return fish_info[fish_id - 1]\\n\\n',\n",
       "  'function_name': 'fish_map',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/card_game/Tools/player.py'},\n",
       " {'code': 'def build_sql(entry, conn):\\n    name = entry[\"table\"][\"table_name\"]\\n    columns = \",\".join(\\n        [f\"`{escape(column[\\'name\\'], conn)}` TEXT\" for column in entry[\"table\"][\"table_info\"][\"columns\"]])\\n    column_names = \",\".join(\\n        [f\"`{escape(column[\\'name\\'], conn)}`\" for column in entry[\"table\"][\"table_info\"][\"columns\"]])\\n    items = []\\n    for row in entry[\"table\"][\"table_info\"][\"rows\"]:\\n        item = \"(\"\\n        for col in row:\\n            item += f\"\\'{escape(col, conn)}\\',\"\\n        item = item[:-1] + \")\"\\n        items.append(item)\\n    items = \",\".join(items)\\n    sql = f\"\"\"CREATE DATABASE IF NOT EXISTS `{name}`;',\n",
       "  'function_name': 'build_sql',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/dbbench/__init__.py'},\n",
       " {'code': 'def escape(string: str, conn):\\n    if type(string) is not str:\\n        string = str(string)\\n    return conn._cmysql.escape_string(string).decode(\"utf-8\")\\n\\n',\n",
       "  'function_name': 'escape',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/dbbench/__init__.py'},\n",
       " {'code': 'def process(receiver, max_round):\\n    container = Container()\\n    while True:\\n        data_item, session, sender = receiver.recv()\\n\\n        if data_item is None and session is None and sender is None:\\n            break\\n\\n        entry = data_item\\n        # container = self.container\\n        init = build_sql(entry, container.conn)\\n        container.execute(init)\\n        db = entry[\\'table\\'][\\'table_name\\']\\n        session.inject({\"role\": \"user\", \"content\": big_prompt})\\n        session.inject({\"role\": \"agent\", \"content\": \"Ok.\"})\\n        prompt = entry[\"description\"] + \"\\\\n\" + entry[\"add_description\"]\\n        session.inject({\"role\": \"user\", \"content\": prompt})\\n        res = session.action()\\n        try:\\n            action = re.search(r\"Action: (.*?)\\\\n\", res)\\n            rounds = 0\\n            while action and action.group(1) == \"Operation\" and rounds < max_round:\\n                res = re.search(r\"```sql\\\\n([\\\\s\\\\S]*?)\\\\n```\", res)\\n                if not res:\\n                    answer = \"\"\\n                    break\\n                sql = res.group(1).strip()\\n                sql = sql.replace(\"\\\\n\", \" \")\\n                response = container.execute(sql, db)\\n                if response:\\n                    session.inject({\"role\": \"user\", \"content\": response})\\n                else:\\n                    session.inject({\"role\": \"user\", \"content\": \"\"})\\n                res = session.action()\\n                action = re.search(r\"Action: (.*?)\\\\n\", res)\\n                rounds += 1\\n            else:\\n                answer = re.search(r\"\\\\nFinal Answer:(.*)\", res)\\n                if answer:\\n                    answer = answer.group(1)\\n                else:\\n                    answer = \"\"\\n        except Exception as e:\\n            error = str(e)\\n            answer = \"\"\\n        else:\\n            error = \"\"\\n        if data_item[\"type\"][0] in (\"INSERT\", \"DELETE\", \"UPDATE\"):\\n            columns = \",\".join([f\"`{escape(column[\\'name\\'], container.conn)}`\"\\n                                for column in entry[\"table\"][\"table_info\"][\"columns\"]])\\n            md5_query = f\"select md5(group_concat(rowhash order by rowhash)) as hash \" \\\\\\n                        f\"from( SELECT substring(MD5(CONCAT_WS(\\',\\', {columns})), 1, 5) AS rowhash FROM `{db}`) as sub;\"\\n            answer = container.execute(md5_query, db)\\n        container.execute(f\"drop database `{db}`\")\\n        sender.send({\\n            \"answer\": str(answer),\\n            \"type\": entry[\"type\"][0],\\n            \"history\": session.history,\\n            \"error\": error,\\n        })\\n    container.delete()\\n\\n',\n",
       "  'function_name': 'process',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/dbbench/__init__.py'},\n",
       " {'code': 'def fetch_data(session: Session, prompt_template, max_attempts=20):\\n    for attempt in range(max_attempts):\\n        try:\\n            output = session.action(prompt_template)\\n            assert output is not None\\n            return output\\n        except AssertionError:\\n            print(f\"Output is None! Retrying...({attempt + 1}/{max_attempts})\")\\n            time.sleep(3)\\n    raise RuntimeError(\"Failed to fetch data after several attempts\")\\n',\n",
       "  'function_name': 'fetch_data',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/task.py'},\n",
       " {'code': 'def format_input_generation(\\n    sample, candidate_ids, gt=-1, previous_k=5, keep_html_brackets=False\\n):\\n    dom_tree = lxml.etree.fromstring(sample[\"cleaned_html\"])\\n    dom_tree = prune_tree(dom_tree, candidate_ids)\\n    tree_repr, id_mapping = get_tree_repr(\\n        dom_tree, id_mapping={}, keep_html_brackets=keep_html_brackets\\n    )\\n    candidate_nodes = dom_tree.xpath(\"//*[@backend_node_id]\")\\n    choices = []\\n    for idx, node in enumerate(candidate_nodes):\\n        choices.append(\\n            [\\n                node.attrib[\"backend_node_id\"],\\n                \" \".join(\\n                    get_tree_repr(\\n                        node,\\n                        id_mapping=id_mapping,\\n                        keep_html_brackets=keep_html_brackets,\\n                    )[0].split()[:10]\\n                ),\\n            ]\\n        )\\n    gt = id_mapping.get(gt, -1)\\n    seq_input = (\\n        \"Based on the HTML webpage above, try to complete the following task:\\\\n\"\\n        f\"Task: {sample[\\'confirmed_task\\']}\\\\n\"\\n        f\"Previous actions:\\\\n\"\\n    )\\n    if len(sample[\"previous_actions\"]) > 0:\\n        for action in sample[\"previous_actions\"][-previous_k:]:\\n            seq_input += f\"{action}\\\\n\"\\n    else:\\n        seq_input += \"None\\\\n\"\\n    seq_input += (\\n        \"What should be the next action?\"\\n        \"Please select the element to interact with, and the action to perform along with the value to type in or select. \"\\n        \"If the task cannot be completed, output None.\"\\n    )\\n\\n    if gt == -1:\\n        seq_target = \"None\"\\n    else:\\n        current_action_op = sample[\"operation\"][\"op\"]\\n        current_action_value = sample[\"operation\"][\"value\"]\\n        seq_target = f\"Element: {choices[gt][1]}\\\\n\"\\n        seq_target += f\"Action: {current_action_op}\\\\n\"\\n        if current_action_op != \"CLICK\":\\n            seq_target += f\"Value: {current_action_value}\"\\n    return tree_repr, seq_input, seq_target, choices\\n\\n',\n",
       "  'function_name': 'format_input_generation',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/dataloader.py'},\n",
       " {'code': 'def format_input_multichoice(\\n    sample, candidate_ids, gt=-1, previous_k=5, keep_html_brackets=False\\n):\\n    dom_tree = lxml.etree.fromstring(sample[\"cleaned_html\"])\\n    dom_tree = prune_tree(dom_tree, candidate_ids)\\n    tree_repr, id_mapping = get_tree_repr(\\n        dom_tree, id_mapping={}, keep_html_brackets=keep_html_brackets\\n    )\\n    candidate_nodes = dom_tree.xpath(\"//*[@backend_node_id]\")\\n    choices = []\\n    for idx, node in enumerate(candidate_nodes):\\n        choices.append(\\n            [\\n                node.attrib[\"backend_node_id\"],\\n                \" \".join(\\n                    get_tree_repr(\\n                        node,\\n                        id_mapping=id_mapping,\\n                        keep_html_brackets=keep_html_brackets,\\n                    )[0].split()[:10]\\n                ),\\n            ]\\n        )\\n    gt = id_mapping.get(gt, -1)\\n    seq_input = (\\n        \"Based on the HTML webpage above, try to complete the following task:\\\\n\"\\n        f\"Task: {sample[\\'confirmed_task\\']}\\\\n\"\\n        f\"Previous actions:\\\\n\"\\n    )\\n    if len(sample[\"previous_actions\"]) > 0:\\n        for action in sample[\"previous_actions\"][-previous_k:]:\\n            seq_input += f\"{action}\\\\n\"\\n    else:\\n        seq_input += \"None\\\\n\"\\n    seq_input += (\\n        \"What should be the next action? Please select from the following choices \"\\n        \"(If the correct action is not in the page above, please select A. \\'None of the above\\'):\\\\n\\\\n\"\\n        \"A. None of the above\\\\n\"\\n    )\\n    for idx, choice in enumerate(choices):\\n        # convert to ascii A, B, C, D, ...\\n        seq_input += f\"{chr(66 + idx)}. {choice[1]}\\\\n\"\\n    if gt == -1:\\n        seq_target = \"A.\"\\n    else:\\n        gt += 1\\n        current_action_op = sample[\"operation\"][\"op\"]\\n        current_action_value = sample[\"operation\"][\"value\"]\\n        seq_target = f\"{chr(65 + gt)}.\\\\n\" f\"Action: {current_action_op}\\\\n\"\\n        if current_action_op != \"CLICK\":\\n            seq_target += f\"Value: {current_action_value}\"\\n    return tree_repr, seq_input, seq_target, choices\\n\\n',\n",
       "  'function_name': 'format_input_multichoice',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/dataloader.py'},\n",
       " {'code': 'def get_data_split(data_dir, split_file, candidate_results=None, cache_dir=None, is_train=False, is_debug=False):\\n    def flatten_actions(samples):\\n        outputs = {\\n            \"website\": [],\\n            \"confirmed_task\": [],\\n            \"annotation_id\": [],\\n            \"previous_actions\": [],\\n            \"action_uid\": [],\\n            \"operation\": [],\\n            \"pos_candidates\": [],\\n            \"neg_candidates\": [],\\n            \"cleaned_html\": [],\\n        }\\n        num_actions = [len(actions) for actions in samples[\"actions\"]]\\n        for key in [\"website\", \"confirmed_task\", \"annotation_id\"]:\\n            for idx, value in enumerate(samples[key]):\\n                outputs[key] += [value] * num_actions[idx]\\n        for actions, action_reprs in zip(samples[\"actions\"], samples[\"action_reprs\"]):\\n            for a_idx, action in enumerate(actions):\\n                outputs[\"previous_actions\"].append(action_reprs[:a_idx])\\n                for key in [\\n                    \"action_uid\",\\n                    \"operation\",\\n                    \"pos_candidates\",\\n                    \"neg_candidates\",\\n                    \"cleaned_html\",\\n                ]:\\n                    outputs[key].append(action[key])\\n        return outputs\\n    dataset = load_dataset(data_dir, data_files=split_file, split=\"all\", cache_dir=cache_dir)\\n    if is_debug:\\n        dataset = dataset.select(range(3))\\n    flatten_dataset = dataset.map(\\n        flatten_actions,\\n        batched=True,\\n        remove_columns=dataset.column_names,\\n        batch_size=10,\\n        num_proc=4,\\n    )\\n    if candidate_results is not None:\\n        candidate_scores = candidate_results[\"scores\"]\\n        candidate_ranks = candidate_results[\"ranks\"]\\n\\n        def get_score(sample):\\n            sample_id = f\"{sample[\\'annotation_id\\']}_{sample[\\'action_uid\\']}\"\\n            for candidates in [sample[\"pos_candidates\"], sample[\"neg_candidates\"]]:\\n                for candidate in candidates:\\n                    candidate_id = candidate[\"backend_node_id\"]\\n                    candidate[\"score\"] = candidate_scores[sample_id][candidate_id]\\n                    candidate[\"rank\"] = candidate_ranks[sample_id][candidate_id]\\n            return {\\n                \"pos_candidates\": sample[\"pos_candidates\"],\\n                \"neg_candidates\": sample[\"neg_candidates\"],\\n            }\\n\\n        flatten_dataset = flatten_dataset.map(get_score)\\n    if is_train:\\n        flatten_dataset = flatten_dataset.filter(lambda x: len(x[\"pos_candidates\"]) > 0)\\n\\n    return flatten_dataset\\n',\n",
       "  'function_name': 'get_data_split',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/dataloader.py'},\n",
       " {'code': 'def clean_text(text):\\n    if text is None:\\n        return \"\"\\n    text = re.sub(r\"\\\\s+\", \" \", text)\\n    return text.strip()\\n\\n',\n",
       "  'function_name': 'clean_text',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def get_descendants(node, max_depth, current_depth=0):\\n    if current_depth > max_depth:\\n        return []\\n\\n    descendants = []\\n    for child in node:\\n        descendants.append(child)\\n        descendants.extend(get_descendants(child, max_depth, current_depth + 1))\\n\\n    return descendants\\n\\n',\n",
       "  'function_name': 'get_descendants',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def clean_tree(dom_tree, all_candidate_ids):\\n    new_tree = copy.deepcopy(dom_tree)\\n    for node in new_tree.xpath(\"//*\")[::-1]:\\n        # check if node have salient attributes\\n        for attr in node.attrib:\\n            if attr == \"class\" and node.attrib[attr] and node.tag == \"svg\":\\n                icon_texts = re.findall(r\"\\\\S*icon\\\\S*\", node.attrib[attr], re.IGNORECASE)\\n                icon_texts = [clean_text(text) for text in icon_texts]\\n                icon_texts = [text for text in icon_texts if text]\\n                if icon_texts:\\n                    node.attrib[attr] = \" \".join(icon_texts)\\n                else:\\n                    node.attrib.pop(attr)\\n            elif attr in salient_attributes:\\n                if not (\\n                    (\\n                        attr == \"role\"\\n                        and node.attrib.get(attr, \"\")\\n                        in {\"presentation\", \"none\", \"link\"}\\n                    )\\n                    or (attr == \"type\" and node.attrib.get(attr, \"\") == \"hidden\")\\n                ):\\n                    value = clean_text(node.attrib[attr])\\n                    if value != \"\":\\n                        node.attrib[attr] = value\\n                    else:\\n                        node.attrib.pop(attr)\\n                else:\\n                    node.attrib.pop(attr)\\n            elif attr != \"backend_node_id\":\\n                node.attrib.pop(attr)\\n        if node.tag == \"text\":\\n            value = clean_text(node.text)\\n            if len(value) > 0:\\n                node.text = value\\n            else:\\n                node.getparent().remove(node)\\n        elif (\\n            node.attrib.get(\"backend_node_id\", \"\") not in all_candidate_ids\\n            and len(node.attrib) == 1\\n            and not any([x.tag == \"text\" for x in node.getchildren()])\\n            and node.getparent() is not None\\n            and len(node.getchildren()) <= 1\\n        ):\\n            # insert all children into parent\\n            for child in node.getchildren():\\n                node.addprevious(child)\\n            node.getparent().remove(node)\\n    return new_tree\\n\\n',\n",
       "  'function_name': 'clean_tree',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def prune_tree(\\n    dom_tree,\\n    candidate_set,\\n    max_depth=5,\\n    max_children=50,\\n    max_sibling=3,\\n):\\n    nodes_to_keep = set()\\n    for candidate_id in candidate_set:\\n        candidate_node = dom_tree.xpath(f\\'//*[@backend_node_id=\"{candidate_id}\"]\\')[0]\\n        nodes_to_keep.add(candidate_node.attrib[\"backend_node_id\"])\\n        # get all ancestors\\n        nodes_to_keep.update(\\n            [\\n                x.attrib.get(\"backend_node_id\", \"\")\\n                for x in candidate_node.xpath(\"ancestor::*\")\\n            ]\\n        )\\n        # get descendants with max depth\\n        nodes_to_keep.update(\\n            [\\n                x.attrib.get(\"backend_node_id\", \"\")\\n                for x in get_descendants(candidate_node, max_depth)\\n            ][:max_children]\\n        )\\n        # get siblings within range\\n        parent = candidate_node.getparent()\\n        if parent is not None:\\n            siblings = [x for x in parent.getchildren() if x.tag != \"text\"]\\n            idx_in_sibling = siblings.index(candidate_node)\\n            nodes_to_keep.update(\\n                [\\n                    x.attrib.get(\"backend_node_id\", \"\")\\n                    for x in siblings[\\n                        max(0, idx_in_sibling - max_sibling) : idx_in_sibling\\n                        + max_sibling\\n                        + 1\\n                    ]\\n                ]\\n            )\\n    # clone the tree\\n    new_tree = copy.deepcopy(dom_tree)\\n    # remove nodes not in nodes_to_keep\\n    for node in new_tree.xpath(\"//*\")[::-1]:\\n        if node.tag != \"text\":\\n            is_keep = node.attrib.get(\"backend_node_id\", \"\") in nodes_to_keep\\n            is_candidate = node.attrib.get(\"backend_node_id\", \"\") in candidate_set\\n        else:\\n            is_keep = (\\n                node.getparent().attrib.get(\"backend_node_id\", \"\") in nodes_to_keep\\n            )\\n            is_candidate = (\\n                node.getparent().attrib.get(\"backend_node_id\", \"\") in candidate_set\\n            )\\n        if not is_keep and node.getparent() is not None:\\n            node.getparent().remove(node)\\n        else:\\n            if not is_candidate or node.tag == \"text\":\\n                node.attrib.pop(\"backend_node_id\", None)\\n            if (\\n                len(node.attrib) == 0\\n                and not any([x.tag == \"text\" for x in node.getchildren()])\\n                and node.getparent() is not None\\n                and node.tag != \"text\"\\n                and len(node.getchildren()) <= 1\\n            ):\\n                # insert all children into parent\\n                for child in node.getchildren():\\n                    node.addprevious(child)\\n                node.getparent().remove(node)\\n    return new_tree\\n\\n',\n",
       "  'function_name': 'prune_tree',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def get_attribute_repr(node, max_value_length=5, max_length=20):\\n    # get attribute values in order\\n    attr_values_set = set()\\n    attr_values = \"\"\\n    for attr in [\\n        \"role\",\\n        \"aria_role\",\\n        \"type\",\\n        \"alt\",\\n        \"aria_description\",\\n        \"aria_label\",\\n        \"label\",\\n        \"title\",\\n        \"name\",\\n        \"text_value\",\\n        \"value\",\\n        \"placeholder\",\\n        \"input_checked\",\\n        \"input_value\",\\n        \"option_selected\",\\n        \"class\",\\n    ]:\\n        if attr in node.attrib and node.attrib[attr] is not None:\\n            value = node.attrib[attr].lower()\\n            # less menaingful values\\n            if value in [\\n                \"hidden\",\\n                \"none\",\\n                \"presentation\",\\n                \"null\",\\n                \"undefined\",\\n            ] or value.startswith(\"http\"):\\n                continue\\n            value = value.split()\\n            value = \" \".join([v for v in value if len(v) < 15][:max_value_length])\\n            if value and value not in attr_values_set:\\n                attr_values_set.add(value)\\n                attr_values += value + \" \"\\n    uid = node.attrib.get(\"backend_node_id\", \"\")\\n    # clear all attributes\\n    node.attrib.clear()\\n    if uid:\\n        node.attrib[\"id\"] = uid\\n    # add meta attribute\\n    if attr_values:\\n        node.attrib[\"meta\"] = \" \".join(attr_values.split()[:max_length])\\n\\n',\n",
       "  'function_name': 'get_attribute_repr',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def get_tree_repr(\\n    tree, max_value_length=5, max_length=20, id_mapping={}, keep_html_brackets=False\\n):\\n    if isinstance(tree, str):\\n        tree = etree.fromstring(tree)\\n    else:\\n        tree = copy.deepcopy(tree)\\n    for node in tree.xpath(\"//*\"):\\n        if node.tag != \"text\":\\n            if \"backend_node_id\" in node.attrib:\\n                if node.attrib[\"backend_node_id\"] not in id_mapping:\\n                    id_mapping[node.attrib[\"backend_node_id\"]] = len(id_mapping)\\n                node.attrib[\"backend_node_id\"] = str(\\n                    id_mapping[node.attrib[\"backend_node_id\"]]\\n                )\\n            get_attribute_repr(node, max_value_length, max_length)\\n        else:\\n            node.text = \" \".join(node.text.split()[:max_length])\\n    tree_repr = etree.tostring(tree, encoding=\"unicode\")\\n\\n    tree_repr = tree_repr.replace(\\'\"\\', \" \")\\n    tree_repr = (\\n        tree_repr.replace(\"meta= \", \"\").replace(\"id= \", \"id=\").replace(\" >\", \">\")\\n    )\\n    tree_repr = re.sub(r\"<text>(.*?)</text>\", r\"\\\\1\", tree_repr)\\n    if not keep_html_brackets:\\n        tree_repr = tree_repr.replace(\"/>\", \"$/$>\")\\n        tree_repr = re.sub(r\"</(.+?)>\", r\")\", tree_repr)\\n        tree_repr = re.sub(r\"<(.+?)>\", r\"(\\\\1\", tree_repr)\\n        tree_repr = tree_repr.replace(\"$/$\", \")\")\\n\\n    html_escape_table = [\\n        (\"&quot;\", \\'\"\\'),\\n        (\"&amp;\", \"&\"),\\n        (\"&lt;\", \"<\"),\\n        (\"&gt;\", \">\"),\\n        (\"&nbsp;\", \" \"),\\n        (\"&ndash;\", \"-\"),\\n        (\"&rsquo;\", \"\\'\"),\\n        (\"&lsquo;\", \"\\'\"),\\n        (\"&ldquo;\", \\'\"\\'),\\n        (\"&rdquo;\", \\'\"\\'),\\n        (\"&#39;\", \"\\'\"),\\n        (\"&#40;\", \"(\"),\\n        (\"&#41;\", \")\"),\\n    ]\\n    for k, v in html_escape_table:\\n        tree_repr = tree_repr.replace(k, v)\\n    tree_repr = re.sub(r\"\\\\s+\", \" \", tree_repr).strip()\\n\\n    return tree_repr, id_mapping\\n',\n",
       "  'function_name': 'get_tree_repr',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/mind2web/data_utils/dom_utils.py'},\n",
       " {'code': 'def get_file_hash(file_path):\\n    \"\"\"Function to get hash of a file\"\"\"\\n    hasher = hashlib.md5()\\n    with open(file_path, \\'rb\\') as afile:\\n        buf = afile.read()\\n        hasher.update(buf)\\n    return hasher.hexdigest()\\n\\n',\n",
       "  'function_name': 'get_file_hash',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/os_interaction/images.py'},\n",
       " {'code': 'def build_images(force=False):\\n    \"\"\"Function to build docker images\"\"\"\\n    dockerfile_directory = os.path.join(args.root, CONFIG[\"docker_config\"][\"directory\"])\\n    for filename in os.listdir(dockerfile_directory):\\n        if filename not in CONFIG[\"data_config\"][\"ignore\"]:\\n            image_name = f\\'{CONFIG[\"docker_config\"][\"localhost\"]}/{filename}\\'\\n            dockerfile_path = os.path.join(dockerfile_directory, filename)\\n            try:\\n                image = client.images.get(image_name)\\n                if not force:\\n                    # Check if the dockerfile has changed\\n                    if image.labels.get(\\'file_hash\\') != get_file_hash(dockerfile_path):\\n                        # If dockerfile has changed, rebuild image\\n                        print(f\\'Rebuilding image: {image_name}\\')\\n                        client.images.build(path=dockerfile_directory, dockerfile=filename, tag=image_name, labels={\\'file_hash\\': get_file_hash(dockerfile_path)})\\n                    else:\\n                        print(f\\'Image: {image_name} up to date.\\')\\n                else:\\n                    print(f\\'Rebuilding image: {image_name}\\')\\n                    client.images.build(path=dockerfile_directory, dockerfile=filename, tag=image_name, labels={\\'file_hash\\': get_file_hash(dockerfile_path)})\\n            except docker.errors.ImageNotFound:\\n                # If image does not exist, build it\\n                print(f\\'Building image: {image_name}\\')\\n                client.images.build(path=dockerfile_directory, dockerfile=filename, tag=image_name, labels={\\'file_hash\\': get_file_hash(dockerfile_path)})\\n\\n',\n",
       "  'function_name': 'build_images',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/os_interaction/images.py'},\n",
       " {'code': 'def clean_images():\\n    \"\"\"Function to clean docker images\"\"\"\\n    dockerfile_directory = os.path.join(args.root, CONFIG[\"docker_config\"][\"directory\"])\\n    for filename in os.listdir(dockerfile_directory):\\n        if filename not in CONFIG[\"data_config\"][\"ignore\"]:\\n            image_name = f\\'{CONFIG[\"docker_config\"][\"localhost\"]}/{filename}\\'\\n            try:\\n                image = client.images.get(image_name)\\n                client.images.remove(image.id)\\n                print(f\\'Removed image: {image_name}\\')\\n            except docker.errors.ImageNotFound:\\n                print(f\\'Image not found: {image_name}\\')\\n\\n',\n",
       "  'function_name': 'clean_images',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/os_interaction/images.py'},\n",
       " {'code': 'def final_execute(variable: Variable, sparql_executor):\\n    program = variable.program\\n    processed_code = postprocess_raw_code(program)\\n    sparql_query = lisp_to_sparql(processed_code)\\n\\n    results = sparql_executor.execute_query(sparql_query)\\n\\n    return results\\n',\n",
       "  'function_name': 'final_execute',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def get_relations(variable: Union[Variable, str], sparql_executor):\\n    \"\"\"\\n    Get all relations of a variable\\n    :param variable: here a variable is represented as its program derivation\\n    :return: a list of relations\\n    \"\"\"\\n    if not isinstance(variable, Variable):\\n        if not re.match(r\\'^(m|f)\\\\.[\\\\w_]+$\\', variable):\\n            raise ValueError(\"get_relations: variable must be a variable or an entity\")\\n\\n    if isinstance(variable, Variable):\\n        program = variable.program\\n        \\n        processed_code = postprocess_raw_code(program)\\n        sparql_query = lisp_to_sparql(processed_code)\\n        clauses = sparql_query.split(\"\\\\n\")\\n        \\n        new_clauses = [clauses[0], \"SELECT DISTINCT ?rel\\\\nWHERE {\\\\n?x ?rel ?obj .\\\\n{\"]\\n        new_clauses.extend(clauses[1:])\\n        new_clauses.append(\"}\\\\n}\")\\n        new_query = \\'\\\\n\\'.join(new_clauses)\\n        out_relations = sparql_executor.execute_query(new_query)\\n    else: # variable is an entity\\n        out_relations = sparql_executor.get_out_relations(variable)\\n\\n    out_relations = list(set(out_relations).intersection(set(relations)))\\n\\n    # new_clauses = [clauses[0], \"SELECT DISTINCT ?rel\\\\nWHERE {\\\\n?sub ?rel ?x .\\\\n{\"]\\n    # new_clauses.extend(clauses[1:])\\n    # new_clauses.append(\"}\\\\n}\")\\n    # new_query = \\'\\\\n\\'.join(new_clauses)\\n    # in_relations = execute_query(new_query)\\n\\n    rtn_str = f\"Observation: [{\\', \\'.join(out_relations)}]\"\\n    variable_relations_cache[variable] = out_relations\\n\\n    return None, rtn_str\\n      \\n',\n",
       "  'function_name': 'get_relations',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def get_neighbors(variable: Union[Variable, str], relation: str, sparql_executor):  # will create a new variable\\n    \"\"\"\\n    Get all neighbors of a variable\\n    :param variable: a variable, here a variable is represented as its program derivation\\n    :param relation: a relation\\n    :return: a list of neighbors\\n    \"\"\"\\n    if not isinstance(variable, Variable):\\n        if not re.match(r\\'^(m|f)\\\\.[\\\\w_]+$\\', variable):\\n            raise ValueError(\"get_neighbors: variable must be a variable or an entity\")\\n    if not relation in variable_relations_cache[variable]:\\n        raise ValueError(\"get_neighbors: relation must be a relation of the variable\")\\n        \\n\\n    rtn_str = f\"Observation: variable ##, which are instances of {range_info[relation]}\"\\n\\n    new_variable = Variable(range_info[relation], \\n                            f\"(JOIN {relation + \\'_inv\\'} {variable.program if isinstance(variable, Variable) else variable})\")\\n\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'get_neighbors',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def intersection(variable1: Variable, variable2: Variable, sparql_executor):  # will create a new variable\\n    \"\"\"\\n    Get the intersection of two variables\\n    :param variable1: a variable\\n    :param variable2: a variable\\n    :return: a list of intersection\\n    \"\"\"\\n    if variable1.type != variable2.type:\\n        raise ValueError(\"intersection: two variables must have the same type\")\\n\\n    if not isinstance(variable1, Variable) or not isinstance(variable2, Variable):\\n        raise ValueError(\"intersection: variable must be a variable\")\\n\\n    rtn_str = f\"Observation: variable ##, which are instances of {variable1.type}\"\\n    new_variable = Variable(variable1.type, f\"(AND {variable1.program} {variable2.program})\")\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'intersection',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def union(variable1: set, variable2: set, sparql_executor): # will create a new variable\\n    \"\"\"\\n    Get the union of two variables\\n    :param variable1: a variable\\n    :param variable2: a variable\\n    :return: a list of union\\n    \"\"\"\\n    if variable1.type != variable2.type:\\n        raise ValueError(\"union: two variables must have the same type\")\\n\\n    if not isinstance(variable1, Variable) or not isinstance(variable2, Variable):\\n        raise ValueError(\"union: variable must be a variable\")\\n\\n    rtn_str = f\"Observation: variable ##, which are instances of {variable1.type}\"\\n    new_variable = Variable(variable1.type, f\"(OR {variable1.program} {variable2.program})\")\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'union',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def count(variable: Variable, sparql_executor):\\n    \"\"\"\\n    Count the number of a variable\\n    :param variable: a variable\\n    :return: the number of a variable\\n    \"\"\"\\n    rtn_str = f\"Observation: variable ##, which is a number\"\\n    new_variable = Variable(\"type.int\", f\"(COUNT {variable.program})\")\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'count',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def get_attributes(variable: Variable, sparql_executor):\\n    program = variable.program\\n        \\n    processed_code = postprocess_raw_code(program)\\n    sparql_query = lisp_to_sparql(processed_code)\\n    clauses = sparql_query.split(\"\\\\n\")\\n    \\n    new_clauses = [clauses[0], \"SELECT DISTINCT ?rel\\\\nWHERE {\\\\n?x ?rel ?obj .\\\\n{\"]\\n    new_clauses.extend(clauses[1:])\\n    new_clauses.append(\"}\\\\n}\")\\n    new_query = \\'\\\\n\\'.join(new_clauses)\\n    out_relations = sparql_executor.execute_query(new_query)\\n\\n    out_relations = list(set(out_relations).intersection(set(attributes)))\\n    variable_attributes_cache[variable] = out_relations\\n\\n    rtn_str = f\"Observation: [{\\', \\'.join(out_relations)}]\"\\n\\n    return None, rtn_str\\n\\n\\n',\n",
       "  'function_name': 'get_attributes',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def argmax(variable: str, attribute: str, sparql_executor):\\n    \"\"\"\\n    Get the argmax of a variable\\n    :param variable: a variable\\n    :param relation: a relation\\n    :return: the argmax of a variable\\n    \"\"\"\\n    # program = f\"(ARGMAX {variable} {attribute})\"\\n    # processed_code = postprocess_raw_code(program)\\n    # sparql_query = lisp_to_sparql(processed_code)\\n    # answers = execute_query(sparql_query)\\n    if attribute not in variable_attributes_cache[variable]:\\n        raise ValueError(\"argmax: attribute must be an attribute of the variable\")\\n    \\n    rtn_str = f\"Observation: variable ##, which are instances of {variable.type}\"\\n    new_variable = Variable(variable.type, f\"(ARGMAX {variable.program} {attribute})\")\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'argmax',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def argmin(variable: str, attribute: str, sparql_executor):\\n    \"\"\"\\n    Get the argmin of a variable\\n    :param variable: a variable\\n    :param relation: a relation\\n    :return: the argmin of a variable\\n    \"\"\"\\n    if attribute not in variable_attributes_cache[variable]:\\n        raise ValueError(\"argmin: attribute must be an attribute of the variable\")\\n\\n    rtn_str = f\"Observation: variable ##, which are instances of {variable.type}\"\\n    new_variable = Variable(variable.type, f\"(ARGMIN {variable.program} {attribute})\")\\n    return new_variable, rtn_str\\n\\n',\n",
       "  'function_name': 'argmin',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/api.py'},\n",
       " {'code': 'def get_answer_type(query: str):\\n    try:\\n        expression = lisp_to_nested_expression(query)\\n        G = logical_form_to_graph(expression)\\n        for node in G.nodes.items():\\n            if \"question_node\" in node[1] and node[1][\"question_node\"] == 1:\\n                return node[1][\"id\"]\\n    except Exception:\\n        # print(query)\\n        return None\\n\\n',\n",
       "  'function_name': 'get_answer_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def get_symbol_type(symbol: str) -> int:\\n    if symbol.__contains__('^^'):\\n        return 2\\n    elif symbol in types:\\n        return 3\\n    elif symbol in relations:\\n        return 4\\n    elif symbol:\\n        return 1\\n\\n\",\n",
       "  'function_name': 'get_symbol_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def same_logical_form(form1: str, form2: str) -> bool:\\n    if form1.__contains__(\"@@UNKNOWN@@\") or form2.__contains__(\"@@UNKNOWN@@\"):\\n        return False\\n    try:\\n        G1 = logical_form_to_graph(lisp_to_nested_expression(form1))\\n    except Exception:\\n        return False\\n    try:\\n        G2 = logical_form_to_graph(lisp_to_nested_expression(form2))\\n    except Exception:\\n        return False\\n\\n    def node_match(n1, n2):\\n        if n1[\\'id\\'] == n2[\\'id\\'] and n1[\\'type\\'] == n2[\\'type\\']:\\n            func1 = n1.pop(\\'function\\', \\'none\\')\\n            func2 = n2.pop(\\'function\\', \\'none\\')\\n            tc1 = n1.pop(\\'tc\\', \\'none\\')\\n            tc2 = n2.pop(\\'tc\\', \\'none\\')\\n\\n            if func1 == func2 and tc1 == tc2:\\n                return True\\n            else:\\n                return False\\n            # if \\'function\\' in n1 and \\'function\\' in n2 and n1[\\'function\\'] == n2[\\'function\\']:\\n            #     return True\\n            # elif \\'function\\' not in n1 and \\'function\\' not in n2:\\n            #     return True\\n            # else:\\n            #     return False\\n        else:\\n            return False\\n\\n    def multi_edge_match(e1, e2):\\n        if len(e1) != len(e2):\\n            return False\\n        values1 = []\\n        values2 = []\\n        for v in e1.values():\\n            values1.append(v[\\'relation\\'])\\n        for v in e2.values():\\n            values2.append(v[\\'relation\\'])\\n        return sorted(values1) == sorted(values2)\\n\\n    return nx.is_isomorphic(G1, G2, node_match=node_match, edge_match=multi_edge_match)\\n\\n',\n",
       "  'function_name': 'same_logical_form',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def logical_form_to_graph(expression: List) -> nx.MultiGraph:\\n    # TODO: merge two entity node with same id. But there is no such need for\\n    # the second version of graphquestions\\n    G = _get_graph(expression)\\n    G.nodes[len(G.nodes())]['question_node'] = 1\\n    return G\\n\\n\",\n",
       "  'function_name': 'logical_form_to_graph',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def _get_graph(\\n        expression: List) -> nx.MultiGraph:  # The id of question node is always the same as the size of the graph\\n    if isinstance(expression, str):\\n        G = nx.MultiDiGraph()\\n        if get_symbol_type(expression) == 1:\\n            G.add_node(1, id=expression, type=\\'entity\\')\\n        elif get_symbol_type(expression) == 2:\\n            G.add_node(1, id=expression, type=\\'literal\\')\\n        elif get_symbol_type(expression) == 3:\\n            G.add_node(1, id=expression, type=\\'class\\')\\n            # G.add_node(1, id=\"common.topic\", type=\\'class\\')\\n        elif get_symbol_type(expression) == 4:  # relation or attribute\\n            domain, rang = relation_dr[expression]\\n            G.add_node(1, id=rang, type=\\'class\\')  # if it\\'s an attribute, the type will be changed to literal in arg\\n            G.add_node(2, id=domain, type=\\'class\\')\\n            G.add_edge(2, 1, relation=expression)\\n\\n            if REVERSE:\\n                if expression in reverse_properties:\\n                    G.add_edge(1, 2, relation=reverse_properties[expression])\\n\\n        return G\\n\\n    if expression[0] == \\'R\\':\\n        if get_symbol_type(expression[1]) != 4:\\n            pass  # return nx.MultiDiGraph()\\n        G = _get_graph(expression[1])\\n        size = len(G.nodes())\\n        mapping = {}\\n        for n in G.nodes():\\n            mapping[n] = size - n + 1\\n        G = nx.relabel_nodes(G, mapping)\\n        return G\\n\\n    elif expression[0] in [\\'JOIN\\', \\'le\\', \\'ge\\', \\'lt\\', \\'gt\\']:\\n        if (isinstance(expression[1], str) and get_symbol_type(expression[1]) != 4) or (\\n                not isinstance(expression[2], list) and get_symbol_type(expression[2]) not in [1, 2]) or (\\n                isinstance(expression[1], list) and expression[1][0] != \\'R\\'):\\n            pass  # return nx.MultiDiGraph()\\n        G1 = _get_graph(expression=expression[1])\\n        G2 = _get_graph(expression=expression[2])\\n\\n        size = len(G2.nodes())\\n        qn_id = size\\n        if G1.nodes[1][\\'type\\'] == G2.nodes[qn_id][\\'type\\'] == \\'class\\':\\n            if G2.nodes[qn_id][\\'id\\'] in upper_types[G1.nodes[1][\\'id\\']]:\\n                G2.nodes[qn_id][\\'id\\'] = G1.nodes[1][\\'id\\']\\n            # G2.nodes[qn_id][\\'id\\'] = G1.nodes[1][\\'id\\']\\n        if G1.nodes[1][\\'type\\'] == \\'entity\\':\\n            mapping = {}\\n            for n in G1.nodes():\\n                mapping[n] = n + size\\n            G1 = nx.relabel_nodes(G1, mapping)\\n        else:\\n            mapping = {}\\n            for n in G1.nodes():\\n                mapping[n] = n + size - 1\\n            G1 = nx.relabel_nodes(G1, mapping)\\n        G = nx.compose(G1, G2)\\n\\n        if expression[0] != \\'JOIN\\':\\n            G.nodes[1][\\'function\\'] = function_map[expression[0]]\\n\\n        return G\\n\\n    elif expression[0] == \\'AND\\':\\n        if (not isinstance(expression[1], list) and get_symbol_type(expression[1]) != 3) or not isinstance(\\n                expression[2], list):\\n            pass  # return nx.MultiDiGraph()\\n\\n        G1 = _get_graph(expression[1])\\n        G2 = _get_graph(expression[2])\\n\\n        size1 = len(G1.nodes())\\n        size2 = len(G2.nodes())\\n        if G1.nodes[size1][\\'type\\'] == G2.nodes[size2][\\'type\\'] == \\'class\\':\\n            # if G2.nodes[size2][\\'id\\'] in upper_types[G1.nodes[size1][\\'id\\']]:\\n            G2.nodes[size2][\\'id\\'] = G1.nodes[size1][\\'id\\']\\n            # IIRC, in nx.compose, for the same node, its information can be overwritten by its info in the second graph\\n            # So here for the AND function we force it to choose the type explicitly provided in the logical form\\n\\n        if G1.nodes[1][\\'type\\'] == \\'entity\\':\\n            mapping = {}\\n            for n in G1.nodes():\\n                mapping[n] = n + size2\\n            G1 = nx.relabel_nodes(G1, mapping)\\n        else:\\n            mapping = {}\\n            for n in G1.nodes():\\n                mapping[n] = n + size2 - 1\\n            G1 = nx.relabel_nodes(G1, mapping)\\n\\n        G2 = nx.relabel_nodes(G2, {size2: size1 + size2 - 1})\\n        G = nx.compose(G1, G2)\\n\\n        return G\\n\\n    elif expression[0] == \\'COUNT\\':\\n        if len(expression) != 2 or not isinstance(expression[1], list):\\n            pass  # return nx.MultiDiGraph()\\n        G = _get_graph(expression[1])\\n        size = len(G.nodes())\\n        G.nodes[size][\\'function\\'] = \\'count\\'\\n\\n        return G\\n\\n    elif expression[0].__contains__(\\'ARG\\'):\\n        if (not isinstance(expression[1], list) and get_symbol_type(expression[1]) != 3) or (not isinstance(\\n                expression[2], list) and get_symbol_type(expression[2]) != 4):\\n            pass  # return nx.MultiDiGraph()\\n        G1 = _get_graph(expression[1])\\n        size1 = len(G1.nodes())\\n        G2 = _get_graph(expression[2])\\n        size2 = len(G2.nodes())\\n        # G2.nodes[1][\\'class\\'] = G2.nodes[1][\\'id\\']   # not sure whether this is needed for sparql\\n        G2.nodes[1][\\'id\\'] = 0\\n        G2.nodes[1][\\'type\\'] = \\'literal\\'\\n        G2.nodes[1][\\'function\\'] = expression[0].lower()\\n        if G1.nodes[size1][\\'type\\'] == G2.nodes[size2][\\'type\\'] == \\'class\\':\\n            # if G2.nodes[size2][\\'id\\'] in upper_types[G1.nodes[size1][\\'id\\']]:\\n            G2.nodes[size2][\\'id\\'] = G1.nodes[size1][\\'id\\']\\n\\n        mapping = {}\\n        for n in G1.nodes():\\n            mapping[n] = n + size2 - 1\\n        G1 = nx.relabel_nodes(G1, mapping)\\n        G2 = nx.relabel_nodes(G2, {size2: size1 + size2 - 1})\\n        G = nx.compose(G1, G2)\\n\\n        return G\\n\\n    elif expression[0] == \\'TC\\':\\n        G = _get_graph(expression[1])\\n        size = len(G.nodes())\\n        G.nodes[size][\\'tc\\'] = (expression[2], expression[3])\\n\\n        return G\\n\\n',\n",
       "  'function_name': '_get_graph',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def graph_to_logical_form(G, start, count: bool = False):\\n    if count:\\n        return '(COUNT ' + none_function(G, start) + ')'\\n    else:\\n        return none_function(G, start)\\n\\n\",\n",
       "  'function_name': 'graph_to_logical_form',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def get_end_num(G, s):\\n    end_num = defaultdict(lambda: 0)\\n    for edge in list(G.edges(s)):  # for directed graph G.edges is the same as G.out_edges, not including G.in_edges\\n        end_num[list(edge)[1]] += 1\\n    return end_num\\n\\n',\n",
       "  'function_name': 'get_end_num',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def set_visited(G, s, e, relation):\\n    end_num = get_end_num(G, s)\\n    for i in range(0, end_num[e]):\\n        if G.edges[s, e, i]['relation'] == relation:\\n            G.edges[s, e, i]['visited'] = True\\n\\n\",\n",
       "  'function_name': 'set_visited',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def binary_nesting(function: str, elements: List[str], types_along_path=None) -> str:\\n    if len(elements) < 2:\\n        print(\"error: binary function should have 2 parameters!\")\\n    if not types_along_path:\\n        if len(elements) == 2:\\n            return \\'(\\' + function + \\' \\' + elements[0] + \\' \\' + elements[1] + \\')\\'\\n        else:\\n            return \\'(\\' + function + \\' \\' + elements[0] + \\' \\' + binary_nesting(function, elements[1:]) + \\')\\'\\n    else:\\n        if len(elements) == 2:\\n            return \\'(\\' + function + \\' \\' + types_along_path[0] + \\' \\' + elements[0] + \\' \\' + elements[1] + \\')\\'\\n        else:\\n            return \\'(\\' + function + \\' \\' + types_along_path[0] + \\' \\' + elements[0] + \\' \\' \\\\\\n                   + binary_nesting(function, elements[1:], types_along_path[1:]) + \\')\\'\\n\\n',\n",
       "  'function_name': 'binary_nesting',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def count_function(G, start):\\n    return '(COUNT ' + none_function(G, start) + ')'\\n\\n\",\n",
       "  'function_name': 'count_function',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def none_function(G, start, arg_node=None, type_constraint=True):  # type_constraint is false for WebQSP\\n    if arg_node is not None:\\n        arg = G.nodes[arg_node]['function']\\n        path = list(nx.all_simple_paths(G, start, arg_node))\\n        assert len(path) == 1\\n        arg_clause = []\\n        for i in range(0, len(path[0]) - 1):\\n            edge = G.edges[path[0][i], path[0][i + 1], 0]\\n            if edge['reverse']:\\n                relation = '(R ' + edge['relation'] + ')'\\n            else:\\n                relation = edge['relation']\\n            arg_clause.append(relation)\\n\\n        # Deleting edges until the first node with out degree > 2 is meet\\n        # (conceptually it should be 1, but remember that add edges is both directions)\\n        while i >= 0:\\n            flag = False\\n            if G.out_degree[path[0][i]] > 2:\\n                flag = True\\n            G.remove_edge(path[0][i], path[0][i + 1], 0)\\n            i -= 1\\n            if flag:\\n                break\\n\\n        if len(arg_clause) > 1:\\n            arg_clause = binary_nesting(function='JOIN', elements=arg_clause)\\n            # arg_clause = ' '.join(arg_clause)\\n        else:\\n            arg_clause = arg_clause[0]\\n\\n        return '(' + arg.upper() + ' ' + none_function(G, start) + ' ' + arg_clause + ')'\\n\\n    # arg = -1\\n    # for nei in G[start]:\\n    #     if G.nodes[nei]['function'].__contains__('arg'):\\n    #         arg = nei\\n    #         arg_function = G.nodes[nei]['function']\\n    # if arg != -1:\\n    #     edge = G.edges[start, arg, 0]\\n    #     if edge['reverse']:\\n    #         relation = '(R ' + edge['relation'] + ')'\\n    #     else:\\n    #         relation = edge['relation']\\n    #     G.remove_edge(start, arg, 0)\\n    #     return '(' + arg_function.upper() + ' ' + none_function(G, start) + ' ' + relation + ')'\\n\\n    if G.nodes[start]['type'] != 'class':\\n        return G.nodes[start]['id']\\n\\n    end_num = get_end_num(G, start)\\n    clauses = []\\n\\n    if G.nodes[start]['question'] and type_constraint:\\n        clauses.append(G.nodes[start]['id'])\\n    for key in end_num.keys():\\n        for i in range(0, end_num[key]):\\n            if not G.edges[start, key, i]['visited']:\\n                relation = G.edges[start, key, i]['relation']\\n                G.edges[start, key, i]['visited'] = True\\n                set_visited(G, key, start, relation)\\n                if G.edges[start, key, i]['reverse']:\\n                    relation = '(R ' + relation + ')'\\n                if G.nodes[key]['function'].__contains__('<') or G.nodes[key]['function'].__contains__('>'):\\n                    if G.nodes[key]['function'] == '>':\\n                        clauses.append('(gt ' + relation + ' ' + none_function(G, key) + ')')\\n                    if G.nodes[key]['function'] == '>=':\\n                        clauses.append('(ge ' + relation + ' ' + none_function(G, key) + ')')\\n                    if G.nodes[key]['function'] == '<':\\n                        clauses.append('(lt ' + relation + ' ' + none_function(G, key) + ')')\\n                    if G.nodes[key]['function'] == '<=':\\n                        clauses.append('(le ' + relation + ' ' + none_function(G, key) + ')')\\n                else:\\n                    clauses.append('(JOIN ' + relation + ' ' + none_function(G, key) + ')')\\n\\n    if len(clauses) == 0:\\n        return G.nodes[start]['id']\\n\\n    if len(clauses) == 1:\\n        return clauses[0]\\n    else:\\n        return binary_nesting(function='AND', elements=clauses)\\n\\n\",\n",
       "  'function_name': 'none_function',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def get_lisp_from_graph_query(graph_query):\\n    G = nx.MultiDiGraph()\\n    aggregation = 'none'\\n    arg_node = None\\n    for node in graph_query['nodes']:\\n        #         G.add_node(node['nid'], id=node['id'].replace('.', '/'), type=node['node_type'], question=node['question_node'], function=node['function'])\\n        G.add_node(node['nid'], id=node['id'], type=node['node_type'], question=node['question_node'],\\n                   function=node['function'], cla=node['class'])\\n        if node['question_node'] == 1:\\n            qid = node['nid']\\n        if node['function'] != 'none':\\n            aggregation = node['function']\\n            if node['function'].__contains__('arg'):\\n                arg_node = node['nid']\\n    for edge in graph_query['edges']:\\n        G.add_edge(edge['start'], edge['end'], relation=edge['relation'], reverse=False, visited=False)\\n        G.add_edge(edge['end'], edge['start'], relation=edge['relation'], reverse=True, visited=False)\\n    if 'count' == aggregation:\\n        # print(count_function(G, qid))\\n        return count_function(G, qid)\\n    else:\\n        # print(none_function(G, qid))\\n        return none_function(G, qid, arg_node=arg_node)\\n\\n\",\n",
       "  'function_name': 'get_lisp_from_graph_query',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def get_derivations_from_lisp(expression: List):\\n    if expression[0] == 'AND':\\n        assert len(expression) == 3\\n        if isinstance(expression[1], str):  # class assertion\\n            return get_derivations_from_lisp(expression[2])\\n        else:\\n            rtn = get_derivations_from_lisp(expression[1])\\n            rtn.update(get_derivations_from_lisp(expression[2]))\\n            return rtn\\n    elif expression[0] in ['ARGMIN', 'ARGMAX']:\\n        return None  # do not need to handle for now\\n    elif expression[0] == 'COUNT':\\n        return get_derivations_from_lisp(expression[1])\\n    elif expression[0] == 'JOIN':\\n        assert isinstance(expression[1], str)\\n        if isinstance(expression[2], str):\\n            rtn = {expression[2]: [':' + expression[1][:-4] if expression[1][-4:] == '_inv' else '^:' + expression[1]]}\\n            return rtn\\n        else:\\n            previous = get_derivations_from_lisp(expression[2])\\n            for k in previous:\\n                relation = expression[1]\\n                if isinstance(previous[k], list):\\n                    previous[k].extend(\\n                        [':' + relation[:-4] if relation[-4:] == '_inv' else '^:' + relation])\\n                elif isinstance(previous[k], tuple):\\n                    previous[k][0].extend([':' + relation[:-4] if relation[-4:] == '_inv' else '^:' + relation])\\n\\n            return previous\\n    elif expression[0] in ['le', 'ge', 'lt', 'gt']:\\n        assert len(expression) == 3 and isinstance(expression[1], str) and isinstance(expression[2], str)\\n        rtn = {expression[2]: (['^:' + expression[1]], expression[0])}\\n        return rtn\\n    elif expression[0] == 'TC':\\n        assert len(expression) == 4\\n        return get_derivations_from_lisp(expression[1])\\n\\n\",\n",
       "  'function_name': 'get_derivations_from_lisp',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def lisp_to_sparql(lisp_program: str):\\n    clauses = []\\n    order_clauses = []\\n    entities = set()  # collect entites for filtering\\n    # identical_variables = {}   # key should be smaller than value, we will use small variable to replace large variable\\n    identical_variables_r = {}  # key should be larger than value\\n    expression = lisp_to_nested_expression(lisp_program)\\n    superlative = False\\n    if expression[0] in [\\'ARGMAX\\', \\'ARGMIN\\']:\\n        superlative = True\\n        # remove all joins in relation chain of an arg function. In another word, we will not use arg function as\\n        # binary function here, instead, the arity depends on the number of relations in the second argument in the\\n        # original function\\n        if isinstance(expression[2], list):\\n            def retrieve_relations(exp: list):\\n                rtn = []\\n                for element in exp:\\n                    if element == \\'JOIN\\':\\n                        continue\\n                    elif isinstance(element, str):\\n                        rtn.append(element)\\n                    elif isinstance(element, list) and element[0] == \\'R\\':\\n                        rtn.append(element)\\n                    elif isinstance(element, list) and element[0] == \\'JOIN\\':\\n                        rtn.extend(retrieve_relations(element))\\n                return rtn\\n\\n            relations = retrieve_relations(expression[2])\\n            expression = expression[:2]\\n            expression.extend(relations)\\n\\n    sub_programs = _linearize_lisp_expression(expression, [0])\\n    question_var = len(sub_programs) - 1\\n    count = False\\n\\n    def get_root(var: int):\\n        while var in identical_variables_r:\\n            var = identical_variables_r[var]\\n\\n        return var\\n\\n    for i, subp in enumerate(sub_programs):\\n        i = str(i)\\n        if subp[0] == \\'JOIN\\':\\n            if isinstance(subp[1], list):  # R relation\\n                if subp[2][:2] in [\"m.\", \"g.\"]:  # entity\\n                    clauses.append(\"ns:\" + subp[2] + \" ns:\" + subp[1][1] + \" ?x\" + i + \" .\")\\n                    entities.add(subp[2])\\n                elif subp[2][0] == \\'#\\':  # variable\\n                    clauses.append(\"?x\" + subp[2][1:] + \" ns:\" + subp[1][1] + \" ?x\" + i + \" .\")\\n                else:  # literal   (actually I think literal can only be object)\\n                    if subp[2].__contains__(\\'^^\\'):\\n                        data_type = subp[2].split(\"^^\")[1].split(\"#\")[1]\\n                        if data_type not in [\\'integer\\', \\'float\\', \\'dateTime\\', \\'double\\']:\\n                            subp[2] = f\\'\"{subp[2].split(\"^^\")[0] + \"-08:00\"}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n                            # subp[2] = subp[2].split(\"^^\")[0] + \\'-08:00^^\\' + subp[2].split(\"^^\")[1]\\n                        else:\\n                            subp[2] = f\\'\"{subp[2].split(\"^^\")[0]}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n                    clauses.append(subp[2] + \" ns:\" + subp[1][1] + \" ?x\" + i + \" .\")\\n            else:\\n                if subp[2][:2] in [\"m.\", \"g.\"]:  # entity\\n                    clauses.append(\"?x\" + i + \" ns:\" + subp[1] + \" ns:\" + subp[2] + \" .\")\\n                    entities.add(subp[2])\\n                elif subp[2][0] == \\'#\\':  # variable\\n                    clauses.append(\"?x\" + i + \" ns:\" + subp[1] + \" ?x\" + subp[2][1:] + \" .\")\\n                else:  # literal\\n                    if subp[2].__contains__(\\'^^\\'):\\n                        data_type = subp[2].split(\"^^\")[1].split(\"#\")[1]\\n                        if data_type not in [\\'integer\\', \\'float\\', \\'dateTime\\', \\'double\\']:\\n                            subp[2] = f\\'\"{subp[2].split(\"^^\")[0] + \"-08:00\"}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n                        else:\\n                            subp[2] = f\\'\"{subp[2].split(\"^^\")[0]}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n                        clauses.append(\"?x\" + i + \" ns:\" + subp[1] + \" \" + subp[2] + \" .\")\\n                    else:  # handles cons in webqsp\\n                        clauses.append(f\"?x ns:{subp[1]} ?obj .\")\\n                        clauses.append(f\"FILTER (str(?obj) = \\\\\"{subp[2]}\\\\\") .\")\\n        elif subp[0] == \\'AND\\':\\n            var1 = int(subp[2][1:])\\n            rooti = get_root(int(i))\\n            root1 = get_root(var1)\\n            if rooti > root1:\\n                identical_variables_r[rooti] = root1\\n            else:\\n                identical_variables_r[root1] = rooti\\n                root1 = rooti\\n            # identical_variables[var1] = int(i)\\n            if subp[1][0] == \"#\":\\n                var2 = int(subp[1][1:])\\n                root2 = get_root(var2)\\n                # identical_variables[var2] = int(i)\\n                if root1 > root2:\\n                    # identical_variables[var2] = var1\\n                    identical_variables_r[root1] = root2\\n                else:\\n                    # identical_variables[var1] = var2\\n                    identical_variables_r[root2] = root1\\n            else:  # 2nd argument is a class\\n                clauses.append(\"?x\" + i + \" ns:type.object.type ns:\" + subp[1] + \" .\")\\n        elif subp[0] in [\\'le\\', \\'lt\\', \\'ge\\', \\'gt\\']:  # the 2nd can only be numerical value\\n            clauses.append(\"?x\" + i + \" ns:\" + subp[1] + \" ?y\" + i + \" .\")\\n            if subp[0] == \\'le\\':\\n                op = \"<=\"\\n            elif subp[0] == \\'lt\\':\\n                op = \"<\"\\n            elif subp[0] == \\'ge\\':\\n                op = \">=\"\\n            else:\\n                op = \">\"\\n            if subp[2].__contains__(\\'^^\\'):\\n                data_type = subp[2].split(\"^^\")[1].split(\"#\")[1]\\n                if data_type not in [\\'integer\\', \\'float\\', \\'dateTime\\', \\'double\\']:\\n                    subp[2] = f\\'\"{subp[2].split(\"^^\")[0] + \"-08:00\"}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n                else:\\n                    subp[2] = f\\'\"{subp[2].split(\"^^\")[0]}\"^^<{subp[2].split(\"^^\")[1]}>\\'\\n            clauses.append(f\"FILTER (?y{i} {op} {subp[2]})\")\\n        elif subp[0] == \\'TC\\':\\n            var = int(subp[1][1:])\\n            # identical_variables[var] = int(i)\\n            rooti = get_root(int(i))\\n            root_var = get_root(var)\\n            if rooti > root_var:\\n                identical_variables_r[rooti] = root_var\\n            else:\\n                identical_variables_r[root_var] = rooti\\n\\n            year = subp[3]\\n            if year == \\'NOW\\':\\n                from_para = \\'\"2015-08-10\"^^xsd:dateTime\\'\\n                to_para = \\'\"2015-08-10\"^^xsd:dateTime\\'\\n            else:\\n                from_para = f\\'\"{year}-12-31\"^^xsd:dateTime\\'\\n                to_para = f\\'\"{year}-01-01\"^^xsd:dateTime\\'\\n\\n            clauses.append(f\\'FILTER(NOT EXISTS {{?x{i} ns:{subp[2]} ?sk0}} || \\')\\n            clauses.append(f\\'EXISTS {{?x{i} ns:{subp[2]} ?sk1 . \\')\\n            clauses.append(f\\'FILTER(xsd:datetime(?sk1) <= {from_para}) }})\\')\\n            if subp[2][-4:] == \"from\":\\n                clauses.append(f\\'FILTER(NOT EXISTS {{?x{i} ns:{subp[2][:-4] + \"to\"} ?sk2}} || \\')\\n                clauses.append(f\\'EXISTS {{?x{i} ns:{subp[2][:-4] + \"to\"} ?sk3 . \\')\\n            else:  # from_date -> to_date\\n                clauses.append(f\\'FILTER(NOT EXISTS {{?x{i} ns:{subp[2][:-9] + \"to_date\"} ?sk2}} || \\')\\n                clauses.append(f\\'EXISTS {{?x{i} ns:{subp[2][:-9] + \"to_date\"} ?sk3 . \\')\\n            clauses.append(f\\'FILTER(xsd:datetime(?sk3) >= {to_para}) }})\\')\\n\\n        elif subp[0] in [\"ARGMIN\", \"ARGMAX\"]:\\n            superlative = True\\n            if subp[1][0] == \\'#\\':\\n                var = int(subp[1][1:])\\n                rooti = get_root(int(i))\\n                root_var = get_root(var)\\n                # identical_variables[var] = int(i)\\n                if rooti > root_var:\\n                    identical_variables_r[rooti] = root_var\\n                else:\\n                    identical_variables_r[root_var] = rooti\\n            else:  # arg1 is class\\n                clauses.append(f\\'?x{i} ns:type.object.type ns:{subp[1]} .\\')\\n\\n            if len(subp) == 3:\\n                clauses.append(f\\'?x{i} ns:{subp[2]} ?sk0 .\\')\\n            elif len(subp) > 3:\\n                for j, relation in enumerate(subp[2:-1]):\\n                    if j == 0:\\n                        var0 = f\\'x{i}\\'\\n                    else:\\n                        var0 = f\\'c{j - 1}\\'\\n                    var1 = f\\'c{j}\\'\\n                    if isinstance(relation, list) and relation[0] == \\'R\\':\\n                        clauses.append(f\\'?{var1} ns:{relation[1]} ?{var0} .\\')\\n                    else:\\n                        clauses.append(f\\'?{var0} ns:{relation} ?{var1} .\\')\\n\\n                clauses.append(f\\'?c{j} ns:{subp[-1]} ?sk0 .\\')\\n\\n            if subp[0] == \\'ARGMIN\\':\\n                order_clauses.append(\"ORDER BY ?sk0\")\\n            elif subp[0] == \\'ARGMAX\\':\\n                order_clauses.append(\"ORDER BY DESC(?sk0)\")\\n            order_clauses.append(\"LIMIT 1\")\\n\\n\\n        elif subp[0] == \\'COUNT\\':  # this is easy, since it can only be applied to the quesiton node\\n            var = int(subp[1][1:])\\n            root_var = get_root(var)\\n            identical_variables_r[int(i)] = root_var  # COUNT can only be the outtermost\\n            count = True\\n    #  Merge identical variables\\n    for i in range(len(clauses)):\\n        for k in identical_variables_r:\\n            clauses[i] = clauses[i].replace(f\\'?x{k} \\', f\\'?x{get_root(k)} \\')\\n\\n    question_var = get_root(question_var)\\n\\n    for i in range(len(clauses)):\\n        clauses[i] = clauses[i].replace(f\\'?x{question_var} \\', f\\'?x \\')\\n\\n    if superlative:\\n        arg_clauses = clauses[:]\\n\\n    for entity in entities:\\n        clauses.append(f\\'FILTER (?x != ns:{entity})\\')\\n    clauses.insert(0,\\n                   f\"FILTER (!isLiteral(?x) OR lang(?x) = \\'\\' OR langMatches(lang(?x), \\'en\\'))\")\\n    clauses.insert(0, \"WHERE {\")\\n    if count:\\n        clauses.insert(0, f\"SELECT COUNT DISTINCT ?x\")\\n    elif superlative:\\n        clauses.insert(0, \"{SELECT ?sk0\")\\n        clauses = arg_clauses + clauses\\n        clauses.insert(0, \"WHERE {\")\\n        clauses.insert(0, f\"SELECT DISTINCT ?x\")\\n    else:\\n        clauses.insert(0, f\"SELECT DISTINCT ?x\")\\n    clauses.insert(0, \"PREFIX ns: <http://rdf.freebase.com/ns/>\")\\n\\n    clauses.append(\\'}\\')\\n    clauses.extend(order_clauses)\\n    if superlative:\\n        clauses.append(\\'}\\')\\n        clauses.append(\\'}\\')\\n\\n    # for clause in clauses:\\n    #     print(clause)\\n\\n    return \\'\\\\n\\'.join(clauses)\\n\\n',\n",
       "  'function_name': 'lisp_to_sparql',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def _linearize_lisp_expression(expression: list, sub_formula_id):\\n    sub_formulas = []\\n    for i, e in enumerate(expression):\\n        if isinstance(e, list) and e[0] != 'R':\\n            sub_formulas.extend(_linearize_lisp_expression(e, sub_formula_id))\\n            expression[i] = '#' + str(sub_formula_id[0] - 1)\\n\\n    sub_formulas.append(expression)\\n    sub_formula_id[0] += 1\\n    return sub_formulas\\n\\n\",\n",
       "  'function_name': '_linearize_lisp_expression',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def get_canonical_lisp(logical_form: str):  # used only for string match, not semantic match\\n    expression = lisp_to_nested_expression(logical_form)\\n    new_expression = _anonymize_entities(expression)\\n    new_logical_form = expression_to_lisp(new_expression)\\n\\n    return new_logical_form\\n\\n',\n",
       "  'function_name': 'get_canonical_lisp',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def _anonymize_entities(expression: list):\\n    if isinstance(expression, list):\\n        for i in range(len(expression)):\\n            if isinstance(expression[i], str):\\n                if expression[i].__contains__(\"^^\") or expression[i][:2] in [\"m.\", \"g.\"]:\\n                    expression[i] = \"[ENT]\"\\n            else:\\n                _anonymize_entities(expression[i])\\n\\n    return expression\\n\\n',\n",
       "  'function_name': '_anonymize_entities',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def postprocess_raw_code(raw_lisp):\\n    expression = lisp_to_nested_expression(raw_lisp)\\n    if expression[0] in [\"ARGMAX\", \"ARGMIN\"] and len(expression) > 3:\\n        expression[2] = binary_nesting(\"JOIN\", expression[2:])\\n        expression = expression[:3]\\n        raw_lisp = expression_to_lisp(expression)\\n\\n    splits = raw_lisp.split(\\' \\')\\n    for i, s in enumerate(splits):\\n        if len(s) > 4 and s[-4:] == \\'_inv\\':\\n            splits[i] = f\\'(R {s[:-4]})\\'\\n        if len(s) > 5 and s[-5:] == \\'_inv)\\':\\n            splits[i] = f\\'(R {s[:-5]}))\\'\\n    processed_lisp = \\' \\'.join(splits)\\n\\n    return processed_lisp\\n\\n',\n",
       "  'function_name': 'postprocess_raw_code',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def lisp_to_lambda(expressions: Union[List[str], str]):  # from lisp-grammar formula to lambda DCS\\n    # expressions = lisp_to_nested_expression(source_formula)\\n    if not isinstance(expressions, list):\\n        return expressions\\n    if expressions[0] == 'AND':\\n        return lisp_to_lambda(expressions[1]) + ' AND ' + lisp_to_lambda(expressions[2])\\n    elif expressions[0] == 'JOIN':\\n        return lisp_to_lambda(expressions[1]) + '*' + lisp_to_lambda(expressions[2])\\n\\n\",\n",
       "  'function_name': 'lisp_to_lambda',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def lisp_to_sparql_naive(expressions: Union[List[str], str]):\\n    if expressions[0] == \\'AND\\':\\n        clauses = lisp_to_sparql_and(expressions[1:])\\n    elif expressions[1] == \\'JOIN\\':\\n        clauses = lisp_to_sparql_join(expressions[1:])\\n\\n    sparql = \"PREFIX : <http://rdf.freebase.com/ns/> \\\\n SELECT distinct ?x1 WHERE{\\\\n\"\\n    for clause in clauses:\\n        if not clause.__contains__(\"2015-08-10\"):\\n            sparql += (clause + \\'\\\\n\\')\\n    sparql += \\'}\\'\\n\\n    return sparql\\n\\n',\n",
       "  'function_name': 'lisp_to_sparql_naive',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def lisp_to_sparql_and(expressions: Union[List[str], str], variable=1):\\n    assert len(expressions) == 2\\n    clauses = []\\n    if not isinstance(expressions[0], list):\\n        # this constraint makes no sense in WebQSP. it's only used for formatting purpose\\n        # clauses.append('?x' + str(variable) + ' :type.object.type :' + expressions[0] + ' .')\\n        pass\\n    else:\\n        if expressions[0][0] == 'JOIN':\\n            clauses.extend(lisp_to_sparql_join(expressions[0][1:], variable))\\n        elif expressions[0][0] == 'AND':\\n            clauses.extend(lisp_to_sparql_and(expressions[0][1:], variable))\\n\\n    if not isinstance(expressions[1], list):\\n        clauses.append('?x' + str(variable) + ' :type.object.type ' + expressions[0] + ' .')\\n    else:\\n        if expressions[1][0] == 'JOIN':\\n            clauses.extend(lisp_to_sparql_join(expressions[1][1:], variable))\\n        elif expressions[1][0] == 'AND':\\n            clauses.extend(lisp_to_sparql_and(expressions[1][1:], variable))\\n\\n    return clauses\\n\\n\",\n",
       "  'function_name': 'lisp_to_sparql_and',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def lisp_to_sparql_join(expressions: Union[List[str], str], variable=1):\\n    assert len(expressions) == 2\\n    clauses = []\\n    if not isinstance(expressions[1], list):\\n        if not isinstance(expressions[0], list):\\n            clauses.append('?x' + str(variable) + ' :' + expressions[0] + ' :' + expressions[1] + ' .')\\n        else:  # R\\n            clauses.append(':' + expressions[1] + ' :' + expressions[0][1] + ' ' + '?x' + str(variable) + ' .')\\n    else:\\n        if not isinstance(expressions[0], list):\\n            if expressions[1][0] == 'JOIN':\\n                clauses.append('?x' + str(variable) + ' :' + expressions[0] + ' ' + '?x' + str(variable + 1) + ' .')\\n                clauses.extend(lisp_to_sparql_join(expressions[1][1:], variable + 1))\\n            elif expressions[1][0] == 'AND':\\n                clauses.append('?x' + str(variable) + ' :' + expressions[0] + ' ' + '?x' + str(variable + 1) + ' .')\\n                clauses.extend(lisp_to_sparql_and(expressions[1][1:], variable + 1))\\n\\n        else:\\n            if expressions[1][0] == 'JOIN':\\n                clauses.append('?x' + str(variable + 1) + ' :' + expressions[0][1] + ' ' + '?x' + str(variable) + ' .')\\n                clauses.extend(lisp_to_sparql_join(expressions[1][1:], variable + 1))\\n            elif expressions[1][0] == 'AND':\\n                clauses.append('?x' + str(variable + 1) + ' :' + expressions[0][1] + ' ' + '?x' + str(variable) + ' .')\\n                clauses.extend(lisp_to_sparql_and(expressions[1][1:], variable + 1))\\n\\n    return clauses\\n\\n\",\n",
       "  'function_name': 'lisp_to_sparql_join',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def process_inv_function(expression: List):\\n    # to replace (R XXX) to XXX_inv\\n    for i, item in enumerate(expression):\\n        if isinstance(item, list):\\n            if item[0] == 'R':\\n                expression[i] = item[1] + '_inv'\\n            else:\\n                process_inv_function(item)\\n\\n\",\n",
       "  'function_name': 'process_inv_function',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def preprocess_relation_path_for_superlatives(expression):\\n    relations = []\\n    for element in expression:\\n        if element == 'JOIN':\\n            continue\\n        if isinstance(element, list) and element[0] != 'R':\\n            assert element[0] == 'JOIN'\\n            relations.extend(preprocess_relation_path_for_superlatives(element))\\n            continue\\n        relations.append(element)\\n\\n    return relations\\n\\n\",\n",
       "  'function_name': 'preprocess_relation_path_for_superlatives',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def linearize_lisp_expression_for_bottom_up(expression: list, sub_formula_id):\\n    sub_formulas = []\\n    level = {}\\n    max_sub_level = -1\\n    for i, e in enumerate(expression):\\n        # if isinstance(e, list) and e[0] != 'R':\\n        if isinstance(e, list):\\n            sf, lvl = linearize_lisp_expression_for_bottom_up(e, sub_formula_id)\\n            sub_formulas.extend(sf)\\n            level.update(lvl)\\n            expression[i] = '#' + str(sub_formula_id[0] - 1)\\n            if lvl[sub_formula_id[0] - 1] > max_sub_level:\\n                max_sub_level = lvl[sub_formula_id[0] - 1]\\n    current_level = max_sub_level + 1\\n\\n    sub_formulas.append(expression)\\n\\n    level[sub_formula_id[0]] = current_level\\n    sub_formula_id[0] += 1\\n\\n    return sub_formulas, level\\n\\n\",\n",
       "  'function_name': 'linearize_lisp_expression_for_bottom_up',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': \"def get_sub_programs(formula: str):\\n    expression = lisp_to_nested_expression(formula)\\n    process_inv_function(expression)\\n\\n    if expression[0] in ['ARGMIN', 'ARGMAX']:\\n        if isinstance(expression[2], list) and expression[2][0] == 'JOIN':\\n            arg_path = preprocess_relation_path_for_superlatives(expression[2])\\n\\n            expression = expression[:2]\\n            expression.extend(arg_path)\\n    # level_mapping: sub_formula_id -> level\\n    sub_formulas, level_mapping = linearize_lisp_expression_for_bottom_up(expression, [0])\\n    # special processing for superlatives\\n    if sub_formulas[-1][0] in ['ARGMAX', 'ARGMIN'] and len(sub_formulas[-1]) > 3:\\n        last_id = len(level_mapping) - 1\\n        last_level = level_mapping[last_id]\\n        new_sub_formulas = sub_formulas[:-1]\\n        for i in range(len(sub_formulas[-1]) - 2):\\n            new_sub_formulas.append(sub_formulas[-1][:3 + i])\\n            level_mapping[last_id] = last_level\\n            last_id += 1\\n            last_level += 1\\n        sub_formulas = new_sub_formulas\\n\\n    new_level_mapping = defaultdict(lambda: [])\\n    for k, v in level_mapping.items():\\n        new_level_mapping[v].append(k)\\n\\n    return sub_formulas, new_level_mapping\\n\\n\",\n",
       "  'function_name': 'get_sub_programs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def fill_sub_programs(sub_programs, entity_name, use_mid=False):\\n    sub_programs_filled = []\\n    for i, p in enumerate(sub_programs):\\n        p = [*p]\\n        for j, expression in enumerate(p):\\n            if expression[0] == \\'#\\':\\n                sub_id = int(expression[1:])\\n                p[j] = sub_programs_filled[sub_id]\\n            if not use_mid:\\n                if expression.__contains__(\\'^^\\'):\\n                    p[j] = p[j].split(\\'^^\\')[0]\\n                if expression in entity_name:\\n                    p[j] = entity_name[expression]\\n\\n        sub_programs_filled.append(f\"({\\' \\'.join(p)})\")\\n\\n    return sub_programs_filled\\n\\n',\n",
       "  'function_name': 'fill_sub_programs',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def max_count_relations(program: str):   # used for penalizing long predictions by CodeX\\n    expression = lisp_to_nested_expression(program)\\n    relations_count = count_relations_expression(expression)\\n    max = 0\\n    for r in relations_count:\\n        if relations_count[r] > max:\\n            max = relations_count[r]\\n    return max\\n',\n",
       "  'function_name': 'max_count_relations',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def count_relations_expression(expression: List):\\n    rtn = defaultdict(lambda: 0)\\n    for item in expression:\\n        if isinstance(item, str):\\n            if get_symbol_type(item) == 4:\\n                rtn[item] += 1\\n                if item in reverse_properties:\\n                    rtn[reverse_properties[item]] += 1\\n        else:\\n            item_rtn = count_relations_expression(item)\\n            for r in item_rtn:\\n                if r in rtn:\\n                    rtn[r] = (rtn[r] + item_rtn[r])\\n                else:\\n                    rtn[r] = item_rtn[r]\\n    return rtn\\n',\n",
       "  'function_name': 'count_relations_expression',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/logic_form_util.py'},\n",
       " {'code': 'def lisp_to_nested_expression(lisp_string: str) -> List:\\n    \"\"\"\\n    Takes a logical form as a lisp string and returns a nested list representation of the lisp.\\n    For example, \"(count (division first))\" would get mapped to [\\'count\\', [\\'division\\', \\'first\\']].\\n    \"\"\"\\n    stack: List = []\\n    current_expression: List = []\\n    tokens = lisp_string.split()\\n    for token in tokens:\\n        while token[0] == \\'(\\':\\n            nested_expression: List = []\\n            current_expression.append(nested_expression)\\n            stack.append(current_expression)\\n            current_expression = nested_expression\\n            token = token[1:]\\n        current_expression.append(token.replace(\\')\\', \\'\\'))\\n        while token[-1] == \\')\\':\\n            current_expression = stack.pop()\\n            token = token[:-1]\\n    return current_expression[0]\\n',\n",
       "  'function_name': 'lisp_to_nested_expression',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/semparse_util.py'},\n",
       " {'code': \"def expression_to_lisp(expression) -> str:\\n    rtn = '('\\n    for i, e in enumerate(expression):\\n        if isinstance(e, list):\\n            rtn += expression_to_lisp(e)\\n        else:\\n            rtn += e\\n        if i != len(expression) - 1:\\n            rtn += ' '\\n\\n    rtn += ')'\\n    return rtn\\n\\n\",\n",
       "  'function_name': 'expression_to_lisp',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/semparse_util.py'},\n",
       " {'code': 'def get_nesting_level(expression) -> int:\\n    max_sub = 0\\n    for item in expression:\\n        if isinstance(item, list):\\n            level = get_nesting_level(item)\\n            if level > max_sub:\\n                max_sub = level\\n\\n    return 1 + max_sub\\n\\n\\n',\n",
       "  'function_name': 'get_nesting_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/knowledgegraph/utils/semparse_util.py'},\n",
       " {'code': 'def bleu_score(reference, candidate):\\n    reference_tokens = reference.split()\\n    candidate_tokens = candidate.split()\\n\\n    smoothie = SmoothingFunction().method4\\n    score = sentence_bleu([reference_tokens], candidate_tokens, smoothing_function=smoothie)\\n    return score\\n',\n",
       "  'function_name': 'bleu_score',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/utils.py'},\n",
       " {'code': \"def process_ob(ob):\\n    if ob.startswith('You arrive at loc '):\\n        ob = ob[ob.find('. ')+2:]    \\n    return ob\\n\",\n",
       "  'function_name': 'process_ob',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/utils.py'},\n",
       " {'code': 'def process_action(action, choices, limit=0.01, to_print=False):\\n    if to_print:\\n        print(\"preprocess action: \", action)\\n    match = re.search(\"ACTION:(.*)\\\\n\", action)\\n    if match:\\n        action = match.group(1)\\n    else:\\n        match = re.search(\"ACTION:(.*)\", action)\\n        if match:\\n            action = match.group(1)\\n\\n    action = action.strip().lower().split(\"\\\\n\")[0]\\n    if not choices:\\n        return action\\n    if action in choices:\\n        return action\\n    try:\\n        bleus = [bleu_score(choice, action) for choice in choices]\\n        max_index = np.argmax(np.array(bleus))\\n        max_score = bleus[max_index]\\n        if max_score > limit:\\n            if to_print:\\n                print(\"processed action: \", choices[max_index], \" score: \", max_score)\\n            return choices[max_index]\\n    except Exception as e:\\n        print(\"encounter exception: \", e)\\n        print(\"choices: \", choices)\\n        print(\"action: \", action)\\n    return action\\n',\n",
       "  'function_name': 'process_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/utils.py'},\n",
       " {'code': \"def load_prompts(prompts_file):\\n    with open(prompts_file, 'r') as f:\\n        d = json.load(f)\\n        f.close()\\n    return d\\n\",\n",
       "  'function_name': 'load_prompts',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/utils.py'},\n",
       " {'code': 'def load_config(config_file):\\n    with open(config_file) as reader:\\n        config = yaml.safe_load(reader)\\n    return config',\n",
       "  'function_name': 'load_config',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/utils.py'},\n",
       " {'code': 'def get_all_game_files(config, split=\"eval_out_of_distribution\"):\\n    env = AlfredTWEnv(config, train_eval=split)\\n    game_files = env.game_files\\n    del env\\n    return game_files\\n',\n",
       "  'function_name': 'get_all_game_files',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/AgentBench.old/src/tasks/alfworld/environment.py'},\n",
       " {'code': 'def process_agent_run_step(agent):\\n    agent.run()\\n',\n",
       "  'function_name': 'process_agent_run_step',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/eval_hotpot.py'},\n",
       " {'code': 'def run_one_complex_level(args, level=\"easy\"):\\n    print(llm_name)\\n    hotpot = joblib.load(\\n        f\\'src/data/{level}.joblib\\').reset_index(drop=True)\\n    agent_save_file = f\"execution_data/{args.min}-{args.max}/{level}_{agent_name}_{llm_name}.jsonl\"\\n\\n    task_instructions = [(row[\\'question\\'], row[\\'answer\\'])\\n                         for _, row in hotpot.iterrows()]\\n    if os.path.exists(agent_save_file):\\n        sessions = utils.get_all_agent_sessions(agent_save_file)\\n        completed_tasks = utils.get_non_error_tasks(sessions)\\n        print(f\"{level}:{len(completed_tasks)}\")\\n        task_instructions = [\\n            task for task in task_instructions if task not in completed_tasks]\\n        utils.delete_error(agent_save_file)\\n    llm = get_llm_backend(llm_name, args.ip, args.min, args.max).run\\n    agent_cls = get_agent(agent_name)\\n    agents = [agent_cls(ques, ans, llm, max_context_len)\\n              for ques, ans in task_instructions]\\n    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\\n        executor.map(process_agent_run_step, agents)\\n    # for agent in agents:\\n    #     process_agent_run_step(agent)\\n    for agent in agents:\\n        utils.log_agent(agent, agent_save_file)\\n    print(f\\'Finished Trial. Total: {len(agents)}\\')\\n\\n',\n",
       "  'function_name': 'run_one_complex_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/eval_hotpot.py'},\n",
       " {'code': 'def main():\\n    if not os.path.exists(\\'execution_data\\'):\\n        os.mkdir(\\'execution_data\\')\\n\\n    folder_path = f\\'execution_data/{args.min}-{args.max}\\'\\n    # embed()\\n    if not os.path.exists(folder_path):\\n        os.mkdir(folder_path)\\n    \\n    levels = [\\'easy\\', \\'medium\\', \\'hard\\']\\n    for level in levels:\\n        run_one_complex_level(args, level)\\n\\n    def average_reward(name):\\n        with open(name) as f:\\n            data = [i for i in jsonlines.Reader(f)]\\n        rewards = [i[\\'reward\\'] for i in data]\\n        return sum(rewards) / len(rewards)\\n\\n    result_dict = {}\\n\\n    for root, dirs, files in os.walk(folder_path):\\n        for file_name in files:\\n            if file_name.endswith(\\'.jsonl\\'):\\n                file_path = os.path.join(root, file_name)\\n                avg_reward = average_reward(file_path)\\n                print(f\"{file_name}: {avg_reward}\")\\n                result_dict[file_name] = avg_reward\\n\\n    average_score = sum(result_dict.values()) / len(result_dict)\\n    result_dict[\"average\"] = average_score\\n    print(f\"Average: {average_score}\")\\n    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\n    with open(f\"result_{timestamp}.json\", \"w\") as f:\\n        f.write(json.dumps(result_dict))\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/eval_hotpot.py'},\n",
       " {'code': 'def summarize_trial(agents):\\n    correct = [a for a in agents if a.is_correct()]\\n    incorrect = [a for a in agents if a.is_finished() and not a.is_correct()]\\n    not_finish = [a for a in agents if not a.is_finished()]\\n    return correct, incorrect, not_finish\\n',\n",
       "  'function_name': 'summarize_trial',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': \"def remove_fewshot(prompt: str) -> str:\\n    prefix = prompt.split('Here are some examples:')[0]\\n    suffix = prompt.split('(END OF EXAMPLES)')[1]\\n    return prefix.strip('\\\\n').strip() + '\\\\n' +  suffix.strip('\\\\n').strip()\\n\",\n",
       "  'function_name': 'remove_fewshot',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def log_trial(agents, trial_n):\\n    correct, incorrect, not_finish = summarize_trial(agents)\\n\\n    log = f\"\"\"',\n",
       "  'function_name': 'log_trial',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def summarize_trial_detailed(agents):\\n    correct = [a.is_correct() for a in agents]\\n    reward = [a.reward()[0] for a in agents]\\n    halted = [a for a in agents if a.is_halted()]\\n    incorrect = [a for a in agents if a.is_finished() and not a.is_correct()]\\n    error = [a.run_error for a in agents]\\n    return correct, reward, error, halted, incorrect\\n',\n",
       "  'function_name': 'summarize_trial_detailed',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def log_agent(agent, file_path):\\n    question = agent.question\\n    g_truth = agent.key\\n    correct = agent.is_correct()\\n    reward = agent.reward()[0]\\n    halted = agent.is_halted()\\n    error = agent.run_error\\n    prompt = agent._build_agent_prompt()\\n    save_dict = {\"question\":question, \"answer\":g_truth, \"correct\":correct, \"reward\":reward, \\n                 \"halted\":halted, \"error\":error,\"prompt\":prompt}\\n    with open(file_path, \\'w\\') as f:\\n        json.dump(save_dict, f)\\n        f.write(\"\\\\n\")\\n\\n',\n",
       "  'function_name': 'log_agent',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def get_all_agent_sessions(file_name):\\n    sessions = []\\n    with open(file_name) as f:\\n        for line in f:\\n            session = json.loads(line)\\n            sessions.append(session)\\n    return sessions\\n',\n",
       "  'function_name': 'get_all_agent_sessions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def get_error_tasks(sessions):\\n    error_tasks = []\\n    for sess in sessions:\\n        if sess[\"error\"]:\\n            task = (sess[\"question\"], sess[\"answer\"])\\n            error_tasks.append(task)\\n    error_tasks = list(set(error_tasks))\\n    return error_tasks\\n',\n",
       "  'function_name': 'get_error_tasks',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def get_non_error_tasks(sessions):\\n    tasks = []\\n    for sess in sessions:   \\n        if not sess[\"error\"]:    \\n            task = (sess[\"question\"], sess[\"answer\"])\\n            tasks.append(task)\\n    tasks = list(set(tasks))\\n    return tasks\\n',\n",
       "  'function_name': 'get_non_error_tasks',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def delete_error(file_name):\\n    sessions = get_all_agent_sessions(file_name)\\n    non_error_sessions = [sess for sess in sessions if not sess[\"error\"]]\\n    with open(file_name+\\'.back\\', \\'a\\') as b_f:\\n        for sess in sessions:\\n            json.dump(sess, b_f)\\n            b_f.write(\\'\\\\n\\')\\n    with open(file_name, \\'w\\') as f:\\n        for sess in non_error_sessions:\\n            json.dump(sess, f)\\n            f.write(\\'\\\\n\\')\\n            ',\n",
       "  'function_name': 'delete_error',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def summarize_react_trial(agents):\\n    correct = [a for a in agents if a.is_correct()]\\n    halted = [a for a in agents if a.is_halted()]\\n    incorrect = [a for a in agents if a.is_finished() and not a.is_correct()]\\n    return correct, incorrect, halted\\n',\n",
       "  'function_name': 'summarize_react_trial',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def summarize_react_trial_detailed(agents):\\n    correct = [a.is_correct() for a in agents]\\n    reward = [a.reward()[0] for a in agents]\\n    return correct, reward\\n',\n",
       "  'function_name': 'summarize_react_trial_detailed',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def log_react_trial(agents, trial_n):\\n    correct, incorrect, halted = summarize_react_trial(agents)\\n\\n    log = f\"\"\"',\n",
       "  'function_name': 'log_react_trial',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': \"def save_agents(agents, dir: str):\\n    os.makedirs(dir, exist_ok=True)\\n    for i, agent in enumerate(agents):\\n        agent.enc = None\\n        joblib.dump(agent, os.path.join(dir, f'{i}.joblib'))\\n\",\n",
       "  'function_name': 'save_agents',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def load_agents(dir:str):\\n    import tiktoken\\n    agents = []\\n    for f in os.listdir(dir):\\n        agent = joblib.load(os.path.join(dir, f))\\n        agent.enc = tiktoken.encoding_for_model(\"text-davinci-003\")\\n        agents.append(agent)\\n    return agents',\n",
       "  'function_name': 'load_agents',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/utils.py'},\n",
       " {'code': 'def get_llm_backend(llm_name, ip, port_min, port_max):\\n    if llm_name in OPENAI_CHAT_MODELS:\\n        return langchain_openai_chatllm(llm_name)\\n    elif llm_name in OPENAI_LLM_MODELS:\\n        return langchain_openai_llm(llm_name)\\n    else:\\n        return langchain_tgi_llm(llm_name, ip, port_min, port_max)\\n',\n",
       "  'function_name': 'get_llm_backend',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/llms.py'},\n",
       " {'code': \"def parse_action(string):\\n    pattern = r'^(\\\\w+)\\\\[(.+)\\\\]$'\\n    match = re.match(pattern, string)\\n    \\n    if match:\\n        action_type = match.group(1)\\n        argument = match.group(2)\\n        return action_type, argument\\n    else:\\n        action_type, argument = fuzzy_parse_action(string)\\n        return action_type, argument\\n        \",\n",
       "  'function_name': 'parse_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': \"def fuzzy_parse_action(text):\\n    text = text.strip(' ').strip('.')\\n    pattern = r'^(\\\\w+)\\\\[(.+)\\\\]'\\n    match = re.match(pattern, text)\\n    if match:\\n        action_type = match.group(1)\\n        argument = match.group(2)\\n        return action_type, argument\\n    else:\\n        return text, ''\\n\",\n",
       "  'function_name': 'fuzzy_parse_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': \"def format_step(step: str) -> str:\\n    return step.strip('\\\\n').strip().replace('\\\\n', '')\\n\",\n",
       "  'function_name': 'format_step',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': \"def truncate_scratchpad(scratchpad: str, n_tokens: int = 1600, tokenizer = token_enc) -> str:\\n    lines = scratchpad.split('\\\\n')\\n    observations = filter(lambda x: x.startswith('Observation'), lines)\\n    observations_by_tokens = sorted(observations, key=lambda x: len(tokenizer.encode(x)))\\n    while len(token_enc.encode('\\\\n'.join(lines))) > n_tokens:\\n        largest_observation = observations_by_tokens.pop(-1)\\n        ind = lines.index(largest_observation)\\n        lines[ind] = largest_observation.split(':')[0] + ': [truncated wikipedia excerpt]'\\n    return '\\\\n'.join(lines)\\n\",\n",
       "  'function_name': 'truncate_scratchpad',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': 'def normalize_answer(s):\\n    def remove_articles(text):\\n        return re.sub(r\"\\\\b(a|an|the)\\\\b\", \" \", text)\\n    \\n    def white_space_fix(text):\\n        return \" \".join(text.split())\\n    \\n    def remove_punc(text):\\n        exclude = set(string.punctuation)\\n        return \"\".join(ch for ch in text if ch not in exclude)\\n    \\n    def lower(text):\\n        return text.lower()\\n\\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\\n',\n",
       "  'function_name': 'normalize_answer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': \"def f1_score(prediction, ground_truth):\\n    normalized_prediction = normalize_answer(prediction)\\n    normalized_ground_truth = normalize_answer(ground_truth)\\n\\n    ZERO_METRIC = (0, 0, 0)\\n\\n    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n        return ZERO_METRIC\\n    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n        return ZERO_METRIC\\n  \\n    prediction_tokens = normalized_prediction.split()\\n    ground_truth_tokens = normalized_ground_truth.split()\\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\\n    num_same = sum(common.values())\\n    if num_same == 0:\\n        return ZERO_METRIC\\n    precision = 1.0 * num_same / len(prediction_tokens)\\n    recall = 1.0 * num_same / len(ground_truth_tokens)\\n    f1 = (2 * precision * recall) / (precision + recall)\\n    return f1, precision, recall\\n\",\n",
       "  'function_name': 'f1_score',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': 'def EM(answer, key) -> bool:\\n    return normalize_answer(answer) == normalize_answer(key)\\n\\n',\n",
       "  'function_name': 'EM',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': 'def get_agent(agent_name):\\n    if agent_name in [\"Zeroshot_HotPotQA_run_Agent\"]:\\n        return ZeroshotAgent\\n    if agent_name in [\"ZeroshotThink_HotPotQA_run_Agent\"]:\\n        return ZeroshotThinkAgent\\n    if agent_name in [\"React_HotPotQA_run_Agent\"]:\\n        return ReactAgent\\n    if agent_name in [\"Planner_HotPotQA_run_Agent\"]:\\n        return PlannerAgent\\n    if agent_name in [\"PlannerReact_HotPotQA_run_Agent\"]:\\n        return PlannerReactAgent',\n",
       "  'function_name': 'get_agent',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/agent_arch.py'},\n",
       " {'code': 'def clean_str(p):\\n  return p.encode().decode(\"unicode-escape\").encode(\"latin1\").decode(\"utf-8\")\\n\\n',\n",
       "  'function_name': 'clean_str',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/wikienv.py'},\n",
       " {'code': 'def normalize_answer(s):\\n  def remove_articles(text):\\n    return re.sub(r\"\\\\b(a|an|the)\\\\b\", \" \", text)\\n  \\n  def white_space_fix(text):\\n      return \" \".join(text.split())\\n\\n  def remove_punc(text):\\n      exclude = set(string.punctuation)\\n      return \"\".join(ch for ch in text if ch not in exclude)\\n\\n  def lower(text):\\n      return text.lower()\\n\\n  return white_space_fix(remove_articles(remove_punc(lower(s))))\\n',\n",
       "  'function_name': 'normalize_answer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/wrappers.py'},\n",
       " {'code': \"def f1_score(prediction, ground_truth):\\n  normalized_prediction = normalize_answer(prediction)\\n  normalized_ground_truth = normalize_answer(ground_truth)\\n\\n  ZERO_METRIC = (0, 0, 0)\\n\\n  if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n    return ZERO_METRIC\\n  if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n    return ZERO_METRIC\\n  \\n  prediction_tokens = normalized_prediction.split()\\n  ground_truth_tokens = normalized_ground_truth.split()\\n  common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\\n  num_same = sum(common.values())\\n  if num_same == 0:\\n    return ZERO_METRIC\\n  precision = 1.0 * num_same / len(prediction_tokens)\\n  recall = 1.0 * num_same / len(ground_truth_tokens)\\n  f1 = (2 * precision * recall) / (precision + recall)\\n  return f1, precision, recall\\n  \",\n",
       "  'function_name': 'f1_score',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/wrappers.py'},\n",
       " {'code': 'def step(env, action):\\n    attempts = 0\\n    while attempts < 10:\\n        try:\\n            return env.step(action)\\n        except requests.exceptions.Timeout:\\n            attempts += 1\\n',\n",
       "  'function_name': 'step',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/hotpotqa_env.py'},\n",
       " {'code': \"def eval_success(result_file) -> list:\\n    df = pd.read_csv(result_file)\\n    return df['success'].tolist()\\n\",\n",
       "  'function_name': 'eval_success',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': \"def eval_reward(result_file) -> list:\\n    df = pd.read_csv(result_file)\\n    return df['reward'].tolist()\\n\",\n",
       "  'function_name': 'eval_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': 'def eval_llm_agent(llm_name, agent_name):\\n    levels = [\\'easy\\',\\'medium\\',\\'hard\\']\\n    all_reward = []\\n    all_success = []\\n    for l in levels:\\n        file_name = f\"execution_data/hotpotqa/{l}_{agent_name}_{llm_name}.csv\"\\n        all_reward += eval_reward(file_name)\\n        all_success += eval_success(file_name)\\n    avg_reward = sum(all_reward)/len(all_reward)\\n    avg_success = sum(all_success)/len(all_success)\\n    return avg_reward, avg_success\\n',\n",
       "  'function_name': 'eval_llm_agent',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': 'def eval_llm_agent_level(llm_name, agent_name, level):\\n    file_name = f\"execution_data/hotpotqa/{level}_{agent_name}_{llm_name}.csv\"\\n    all_reward = eval_reward(file_name)\\n    all_success = eval_success(file_name)\\n    avg_reward = sum(all_reward)/len(all_reward)\\n    avg_success = sum(all_success)/len(all_success)\\n    return avg_reward, avg_success\\n',\n",
       "  'function_name': 'eval_llm_agent_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': \"def eval_sessions(llm_name, agent_name):\\n    levels = ['easy','medium','hard']\\n    all_reward = []\\n    all_success = []\\n    for l in levels:\\n        reward, success = eval_sessions_level((llm_name, agent_name,l))\\n        all_reward += reward\\n        all_success += success\\n    avg_reward = sum(all_reward)/len(all_reward)\\n    avg_success = sum(all_success)/len(all_success)\\n    return avg_reward, avg_success\\n\",\n",
       "  'function_name': 'eval_sessions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': 'def eval_sessions_level(llm_name, agent_name,level):\\n    file_name = f\"execution_data/hotpotqa/{level}_{agent_name}_{llm_name}.jsonl\"\\n    sessions = utils.get_all_agent_sessions(file_name)\\n    all_reward = [sess[\"reward\"] for sess in sessions]\\n    all_success = [sess[\"correct\"] for sess in sessions]\\n    avg_reward = sum(all_reward)/len(all_reward)\\n    avg_success = sum(all_success)/len(all_success)\\n    return avg_reward, avg_success\\n',\n",
       "  'function_name': 'eval_sessions_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': \"def get_reward_w_level(llm_name, agent_name):\\n    levels = ['easy','medium','hard']\\n    ret = []\\n    for l in levels:\\n        reward, _ = eval_sessions_level(llm_name, agent_name, l)\\n        ret.append(reward)\\n    return ret\\n        \\n\",\n",
       "  'function_name': 'get_reward_w_level',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/hotpotQA/src/evaluate.py'},\n",
       " {'code': 'def save_data(dataset, data, save_path):\\n    dataset[\"preds\"] = data[\"preds\"]\\n    dataset[\"em\"] = data[\"em\"]\\n    dataset[\"f1\"] = data[\"f1\"]\\n    dataset[\"acc\"] = data[\"acc\"]\\n    dataset[\"wall_time\"] = data[\"wall_time\"]\\n    dataset[\"total_tokens\"] = data[\"total_tokens\"]\\n    dataset[\"steps\"] = data[\"steps\"]\\n    dataset[\"tool_cost\"] = data[\"tool_cost\"]\\n    dataset[\"token_cost\"] = data[\"token_cost\"]\\n    dataset[\"total_cost\"] = data[\"total_cost\"]\\n    dataset.to_csv(save_path, index=False)\\n    return dataset\\n\\n',\n",
       "  'function_name': 'save_data',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/run_eval.py'},\n",
       " {'code': \"def main(args):\\n    dataset = DataLoader(args.dataset, seed=args.seed).load(sample_size=args.sample_size)\\n    if args.method == 'direct':\\n        method = IO(model_name=args.base_lm)\\n        eval = Evaluator(args.dataset, dataset, method)\\n    elif args.method == 'cot':\\n        method = CoT(model_name=args.base_lm, fewshot=DEFAULT_EXEMPLARS_COT[args.dataset])\\n        eval = Evaluator(args.dataset, dataset, method)\\n    elif args.method == 'react':\\n        if args.dataset in ['hotpot_qa', 'trivia_qa']:\\n            method = ReactBase(model_name=args.base_lm, fewshot=DEFAULT_EXEMPLARS_REACT[args.dataset], verbose=False)\\n        else:\\n            method = ReactExtraTool(model_name=args.base_lm, available_tools=args.toolset,\\n                                    fewshot=DEFAULT_EXEMPLARS_REACT[args.dataset], verbose=False)\\n        eval = Evaluator(args.dataset, dataset, method)\\n    elif args.method == 'rewoo':\\n        if args.planner_lm is None:\\n            args.planner_lm = args.base_lm\\n        if args.solver_lm is None:\\n            args.solver_lm = args.base_lm\\n        method = PWS_Base(planner_model=args.planner_lm, solver_model=args.solver_lm,\\n                          fewshot=DEFAUL_EXEMPLARS_PWS[args.dataset], available_tools=args.toolset)\\n        eval = Evaluator(args.dataset, dataset, method)\\n    else:\\n        raise NotImplementedError\\n\\n    responses, data = eval.run()\\n    if args.save_result:\\n        save_data(dataset, data, f'./results/eval_{args.dataset}_{args.method}_{args.base_lm}.csv')\\n    print(responses)\\n\\n\",\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/run_eval.py'},\n",
       " {'code': \"def get_time() -> str:\\n    return datetime.now(timezone('Asia/Shanghai')).strftime('%m%d%H%M%S')\\n\",\n",
       "  'function_name': 'get_time',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/nodes/LLMNode.py'},\n",
       " {'code': 'def token_count(text):\\n    return len(tokenizer.encode(text))\\n',\n",
       "  'function_name': 'token_count',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/nodes/LLMNode.py'},\n",
       " {'code': 'def get_prompt(conv: Conversation) -> str:\\n    if conv.name == \\'openchat\\':\\n        ret = \\'\\'\\n        for role, message in conv.messages:\\n            if message:\\n                ret += role + \": \" + message.strip() + conv.sep\\n            else:\\n                ret += role + \":\"\\n        return ret\\n    else:\\n        return conv.get_prompt()\\n',\n",
       "  'function_name': 'get_prompt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/nodes/LLMNode.py'},\n",
       " {'code': 'def llm_llama(prompt: str) -> str:\\n    CONTROLLER_ADDR = os.environ[\\'CONTROLLER_ADDR\\'].split(\\',\\')\\n    data = {\\n        \"inputs\": prompt,\\n        \"parameters\": {\\n            \"max_new_tokens\": 256,\\n            \"do_sample\": True,\\n            \\'temperature\\': 0.5,\\n            \\'frequency_penalty\\': 0,\\n            \\'presence_penalty\\': 0,\\n            \\'truncate\\': 4000,\\n        }\\n    }\\n    if True or os.getenv(\\'GREEDY\\'):\\n        data[\\'parameters\\'][\\'do_sample\\'] = False\\n        data[\\'parameters\\'].pop(\\'temperature\\')\\n        print(\\'greedy mode enabled\\')\\n    for _ in range(5):\\n        try:\\n            response = requests.post(\\n                random.choice(CONTROLLER_ADDR) + \"/generate\",\\n                json=data,\\n                timeout=120,\\n                proxies={\\'http\\': \\'\\', \\'https\\': \\'\\'},\\n            )\\n            print(response.content)\\n            text = response.json()[\"generated_text\"]\\n            print(text)\\n            return text.split(\\'[INST]\\')[0].split(\\'<|end_of_turn|>\\')[0].strip()\\n        # if timeout or connection error, retry\\n        except Timeout: \\n            print(\"Timeout, retrying...\")\\n        except ConnectionError:\\n            print(\"Connection error, retrying...\")\\n        except Exception:\\n            traceback.print_exc()\\n            try:\\n                print(response)\\n                print(response.text)\\n            except:\\n                pass\\n        time.sleep(5)\\n    else:\\n        raise Exception(\"Timeout after 5 retries.\")\\n',\n",
       "  'function_name': 'llm_llama',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/nodes/LLMNode.py'},\n",
       " {'code': \"def refresh(label: str):\\n    global NOW, ID, LOG, traj\\n    LOG.rename(LOG.with_name(f'{NOW}_{label}.json'))\\n    NOW = get_time()\\n    ID = f'{TASK}_{NOW}'\\n    LOG = Path('logs') / f'{MODEL}-{METHOD}' / TASK / f'{NOW}.json'\\n    traj = []\\n\",\n",
       "  'function_name': 'refresh',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/nodes/LLMNode.py'},\n",
       " {'code': 'def normalize_answer(s):\\n    def remove_articles(text):\\n        return re.sub(r\"\\\\b(a|an|the)\\\\b\", \" \", text)\\n\\n    def white_space_fix(text):\\n        return \" \".join(text.split())\\n\\n    def remove_punc(text):\\n        exclude = set(string.punctuation)\\n        return \"\".join(ch for ch in text if ch not in exclude)\\n\\n    def lower(text):\\n        return text.lower()\\n\\n    return white_space_fix(remove_articles(remove_punc(lower(s))))\\n\\n',\n",
       "  'function_name': 'normalize_answer',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/utils/Evaluator.py'},\n",
       " {'code': \"def f1_score(prediction, ground_truth):\\n    normalized_prediction = normalize_answer(prediction)\\n    normalized_ground_truth = normalize_answer(ground_truth)\\n\\n    if normalized_prediction in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n        return 0\\n    if normalized_ground_truth in ['yes', 'no', 'noanswer'] and normalized_prediction != normalized_ground_truth:\\n        return 0\\n\\n    prediction_tokens = normalized_prediction.split()\\n    ground_truth_tokens = normalized_ground_truth.split()\\n    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\\n    num_same = sum(common.values())\\n    if num_same == 0:\\n        return 0\\n    precision = 1.0 * num_same / len(prediction_tokens)\\n    recall = 1.0 * num_same / len(ground_truth_tokens)\\n    f1 = (2 * precision * recall) / (precision + recall)\\n    return f1\\n\\n\",\n",
       "  'function_name': 'f1_score',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/utils/Evaluator.py'},\n",
       " {'code': \"def llm_accuracy_score(query, prediction, ground_truth):\\n    data = [{\\n        'query': query,\\n        'answer': ground_truth,\\n    }]\\n    pred = [{\\n        'query': query,\\n        'answer': ground_truth,\\n        'result': prediction,\\n    }]\\n    eval_chain = QAEvalChain.from_llm(OpenAI(\\n        temperature=0,\\n    ))\\n    graded_outputs = eval_chain.evaluate(data, pred)\\n    return 1 if graded_outputs[0]['text'].strip() == 'CORRECT' else 0\\n\\n\",\n",
       "  'function_name': 'llm_accuracy_score',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/utils/Evaluator.py'},\n",
       " {'code': 'def get_token_unit_price(model: str):\\n    if model in OPENAI_COMPLETION_MODELS:\\n        return 0.00002\\n    elif model in OPENAI_CHAT_MODELS:\\n        if model == \"gpt-3.5-turbo\":\\n            return 0.000002\\n        elif model == \"gpt-4\":\\n            return 0.00003\\n    elif model in LLAMA_WEIGHTS:\\n        return 0.0\\n    else:\\n        return 0.0\\n    # else:\\n    #     raise ValueError(\"Model not found\")\\n',\n",
       "  'function_name': 'get_token_unit_price',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/rewoo/utils/util.py'},\n",
       " {'code': 'def config() -> argparse.Namespace:\\n    parser = argparse.ArgumentParser(\\n        description=\"Run end-to-end evaluation on the benchmark\"\\n    )\\n    parser.add_argument(\\n        \"--render\", action=\"store_true\", help=\"Render the browser\"\\n    )\\n    parser.add_argument(\\n        \"--slow_mo\",\\n        type=int,\\n        default=0,\\n        help=\"Slow down the browser by the specified amount\",\\n    )\\n    parser.add_argument(\\n        \"--action_set_tag\", default=\"id_accessibility_tree\", help=\"Action type\"\\n    )\\n    parser.add_argument(\\n        \"--observation_type\",\\n        choices=[\"accessibility_tree\", \"html\", \"image\"],\\n        default=\"accessibility_tree\",\\n        help=\"Observation type\",\\n    )\\n    parser.add_argument(\\n        \"--current_viewport_only\",\\n        action=\"store_true\",\\n        help=\"Only use the current viewport for the observation\",\\n    )\\n    parser.add_argument(\"--viewport_width\", type=int, default=1280)\\n    parser.add_argument(\"--viewport_height\", type=int, default=720)\\n    parser.add_argument(\"--save_trace_enabled\", action=\"store_true\")\\n    parser.add_argument(\"--sleep_after_execution\", type=float, default=0.0)\\n\\n    parser.add_argument(\"--max_steps\", type=int, default=30)\\n\\n    # agent config\\n    parser.add_argument(\"--agent_type\", type=str, default=\"prompt\")\\n    parser.add_argument(\\n        \"--instruction_path\",\\n        type=str,\\n        default=\"agents/prompts/state_action_agent.json\",\\n    )\\n    parser.add_argument(\\n        \"--parsing_failure_th\",\\n        help=\"When concesecutive parsing failure exceeds this threshold, the agent will stop\",\\n        type=int,\\n        default=3,\\n    )\\n    parser.add_argument(\\n        \"--repeating_action_failure_th\",\\n        help=\"When concesecutive repeating action exceeds this threshold, the agent will stop\",\\n        type=int,\\n        default=3,\\n    )\\n\\n    # lm config\\n    parser.add_argument(\"--provider\", type=str, default=\"openai\")\\n    parser.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo-0613\")\\n    parser.add_argument(\"--mode\", type=str, default=\"chat\")\\n    parser.add_argument(\"--temperature\", type=float, default=1.0)\\n    parser.add_argument(\"--top_p\", type=float, default=0.9)\\n    parser.add_argument(\"--context_length\", type=int, default=0)\\n    parser.add_argument(\"--max_tokens\", type=int, default=384)\\n    parser.add_argument(\"--stop_token\", type=str, default=None)\\n    parser.add_argument(\\n        \"--max_obs_length\",\\n        type=int,\\n        help=\"when not zero, will truncate the observation to this length before feeding to the model\",\\n        default=1920,\\n    )\\n\\n    # example config\\n    parser.add_argument(\"--test_start_idx\", type=int, default=0)\\n    parser.add_argument(\"--test_end_idx\", type=int, default=1000)\\n\\n    parser.add_argument(\\'--site\\', type=str, default=\\'\\')\\n\\n    # logging related\\n    parser.add_argument(\"--result_dir\", type=str, default=\"\")\\n    args = parser.parse_args()\\n\\n    # check the whether the action space is compatible with the observation space\\n    if (\\n        args.action_set_tag == \"id_accessibility_tree\"\\n        and args.observation_type != \"accessibility_tree\"\\n    ):\\n        raise ValueError(\\n            f\"Action type {args.action_set_tag} is incompatible with the observation type {args.observation_type}\"\\n        )\\n\\n    return args\\n\\n',\n",
       "  'function_name': 'config',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def early_stop(\\n    trajectory: Trajectory, max_steps: int, thresholds: dict[str, int]\\n) -> tuple[bool, str]:\\n    \"\"\"Check whether need to early stop\"\"\"\\n\\n    # reach the max step\\n    num_steps = (len(trajectory) - 1) / 2\\n    if num_steps >= max_steps:\\n        return True, f\"Reach max steps {max_steps}\"\\n\\n    last_k_actions: list[Action]\\n    action_seq: list[Action]\\n\\n    # Case: parsing failure for k times\\n    k = thresholds[\"parsing_failure\"]\\n    last_k_actions = trajectory[1::2][-k:]  # type: ignore[assignment]\\n    if len(last_k_actions) >= k:\\n        if all(\\n            [\\n                action[\"action_type\"] == ActionTypes.NONE\\n                for action in last_k_actions\\n            ]\\n        ):\\n            return True, f\"Failed to parse actions for {k} times\"\\n\\n    # Case: same action for k times\\n    k = thresholds[\"repeating_action\"]\\n    last_k_actions = trajectory[1::2][-k:]  # type: ignore[assignment]\\n    action_seq = trajectory[1::2]  # type: ignore[assignment]\\n\\n    if len(action_seq) == 0:\\n        return False, \"\"\\n\\n    last_action: Action = action_seq[-1]\\n\\n    if last_action[\"action_type\"] != ActionTypes.TYPE:\\n        if len(last_k_actions) >= k:\\n            if all(\\n                [\\n                    is_equivalent(action, last_action)\\n                    for action in last_k_actions\\n                ]\\n            ):\\n                return True, f\"Same action for {k} times\"\\n\\n    else:\\n        # check the action sequence\\n        if (\\n            sum([is_equivalent(action, last_action) for action in action_seq])\\n            >= k\\n        ):\\n            return True, f\"Same typing action for {k} times\"\\n\\n    return False, \"\"\\n\\n',\n",
       "  'function_name': 'early_stop',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def test(\\n    args: argparse.Namespace,\\n    agent: Agent | PromptAgent | TeacherForcingAgent,\\n    config_file_list: list[str],\\n) -> None:\\n    scores = []\\n    max_steps = args.max_steps\\n\\n    early_stop_thresholds = {\\n        \"parsing_failure\": args.parsing_failure_th,\\n        \"repeating_action\": args.repeating_action_failure_th,\\n    }\\n\\n    env = ScriptBrowserEnv(\\n        headless=not args.render,\\n        slow_mo=args.slow_mo,\\n        observation_type=args.observation_type,\\n        current_viewport_only=args.current_viewport_only,\\n        viewport_size={\\n            \"width\": args.viewport_width,\\n            \"height\": args.viewport_height,\\n        },\\n        save_trace_enabled=args.save_trace_enabled,\\n        sleep_after_execution=args.sleep_after_execution,\\n    )\\n\\n    for config_file in config_file_list:\\n        idx = Path(config_file).with_suffix(\\'\\').name\\n        interactions = []\\n        try:\\n            render_helper = RenderHelper(\\n                config_file, args.result_dir, args.action_set_tag\\n            )\\n\\n            # get intent\\n            with open(config_file) as f:\\n                _c = json.load(f)\\n                intent = _c[\"intent\"]\\n                task_id = _c[\"task_id\"]\\n\\n            logger.info(f\"[Config file]: {config_file}\")\\n            logger.info(f\"[Intent]: {intent}\")\\n\\n            agent.reset(config_file)\\n            trajectory: Trajectory = []\\n            obs, info = env.reset(options={\"config_file\": config_file})\\n            state_info: StateInfo = {\"observation\": obs, \"info\": info}\\n            trajectory.append(state_info)\\n\\n            meta_data = {\"action_history\": [\"None\"]}\\n            while True:\\n                early_stop_flag, stop_info = early_stop(\\n                    trajectory, max_steps, early_stop_thresholds\\n                )\\n\\n                if early_stop_flag:\\n                    action = create_stop_action(f\"Early stop: {stop_info}\")\\n                else:\\n                    try:\\n                        action, prompt, response = agent.next_action(\\n                            trajectory, intent, meta_data=meta_data\\n                        )\\n                    except ValueError as e:\\n                        # get the error message\\n                        action = create_stop_action(f\"ERROR: {str(e)}\")\\n\\n                trajectory.append(action)\\n\\n                interactions.append({\\n                    \\'id\\': f\\'{idx}_{len(interactions)}\\',\\n                    \\'conversations\\': [\\n                        {\\n                            \\'from\\': \\'human\\',\\n                            \\'value\\': prompt,\\n                        },\\n                        {\\n                            \\'from\\': \\'gpt\\',\\n                            \\'value\\': response,\\n                        },\\n                    ]\\n                })\\n\\n                action_str = get_action_description(\\n                    action,\\n                    state_info[\"info\"][\"observation_metadata\"],\\n                    action_set_tag=args.action_set_tag,\\n                    prompt_constructor=agent.prompt_constructor\\n                    if isinstance(agent, PromptAgent)\\n                    else None,\\n                )\\n                render_helper.render(\\n                    action, state_info, meta_data, args.render_screenshot\\n                )\\n                meta_data[\"action_history\"].append(action_str)\\n\\n                if action[\"action_type\"] == ActionTypes.STOP:\\n                    break\\n\\n                obs, _, terminated, _, info = env.step(action)\\n                state_info = {\"observation\": obs, \"info\": info}\\n                trajectory.append(state_info)\\n\\n                if terminated:\\n                    # add a action place holder\\n                    trajectory.append(create_stop_action(\"\"))\\n                    break\\n\\n            evaluator = evaluator_router(config_file)\\n            score = evaluator(\\n                trajectory=trajectory,\\n                config_file=config_file,\\n                page=env.page,\\n                client=env.get_page_client(env.page),\\n            )\\n\\n            scores.append(score)\\n\\n            if score == 1:\\n                logger.info(f\"[Result] (PASS) {config_file}\")\\n            else:\\n                logger.info(f\"[Result] (FAIL) {config_file}\")\\n\\n            if args.save_trace_enabled:\\n                env.save_trace(\\n                    Path(args.result_dir) / \"traces\" / f\"{task_id}.zip\"\\n                )\\n\\n        except openai.error.OpenAIError as e:\\n            logger.info(f\"[OpenAI Error] {repr(e)}\")\\n        except Exception as e:\\n            logger.info(f\"[Unhandled Error] {repr(e)}]\")\\n            import traceback\\n\\n            # write to error file\\n            with open(Path(args.result_dir) / \"error.txt\", \"a\") as f:\\n                f.write(f\"[Config file]: {config_file}\\\\n\")\\n                f.write(f\"[Unhandled Error] {repr(e)}\\\\n\")\\n                f.write(traceback.format_exc())  # write stack trace to file\\n\\n        finally:\\n            # Save interaction history\\n            os.makedirs(Path(args.result_dir) / \\'logs\\', exist_ok=True)\\n            with (Path(args.result_dir) / \\'logs\\' / f\\'{idx}.json\\').open(\\'w\\') as f:\\n                json.dump(interactions, f)\\n\\n        render_helper.close()\\n\\n    env.close()\\n    logger.info(f\"Average score: {sum(scores) / len(scores)}\")\\n\\n',\n",
       "  'function_name': 'test',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def prepare(args: argparse.Namespace) -> None:\\n    # convert prompt python files to json\\n    from agent.prompts import to_json\\n\\n    to_json.run()\\n\\n    # prepare result dir\\n    result_dir = args.result_dir\\n    if not result_dir:\\n        result_dir = (\\n            f\"cache/results_{time.strftime(\\'%Y%m%d%H%M%S\\', time.localtime())}\"\\n        )\\n    if not Path(result_dir).exists():\\n        Path(result_dir).mkdir(parents=True, exist_ok=True)\\n        args.result_dir = result_dir\\n        logger.info(f\"Create result dir: {result_dir}\")\\n\\n    if not (Path(result_dir) / \"traces\").exists():\\n        (Path(result_dir) / \"traces\").mkdir(parents=True)\\n\\n    # log the log file\\n    with open(os.path.join(result_dir, \"log_files.txt\"), \"a+\") as f:\\n        f.write(f\"{LOG_FILE_NAME}\\\\n\")\\n\\n',\n",
       "  'function_name': 'prepare',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def get_unfinished(config_files: list[str], result_dir: str) -> list[str]:\\n    result_files = glob.glob(f\"{result_dir}/*.html\")\\n    task_ids = [\\n        os.path.basename(f).split(\".\")[0].split(\"_\")[1] for f in result_files\\n    ]\\n    unfinished_configs = []\\n    for config_file in config_files:\\n        task_id = os.path.basename(config_file).split(\".\")[0]\\n        if task_id not in task_ids:\\n            unfinished_configs.append(config_file)\\n    return unfinished_configs\\n\\n',\n",
       "  'function_name': 'get_unfinished',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def dump_config(args: argparse.Namespace) -> None:\\n    config_file = Path(args.result_dir) / \"config.json\"\\n    if not config_file.exists():\\n        with open(config_file, \"w\") as f:\\n            json.dump(vars(args), f, indent=4)\\n            logger.info(f\"Dump config to {config_file}\")\\n\\n',\n",
       "  'function_name': 'dump_config',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/run.py'},\n",
       " {'code': 'def llm_llama(prompt: str, config: lm_config.LMConfig) -> str:\\n    data = {\\n        \"inputs\": prompt,\\n        \"parameters\": {\\n            \"max_new_tokens\": config.gen_config[\\'max_tokens\\'],\\n            \"do_sample\": True,\\n            \\'temperature\\': config.gen_config[\\'temperature\\'],\\n            \\'top_p\\': config.gen_config[\\'top_p\\'],\\n            \\'truncate\\': 4000,\\n        }\\n    }\\n    for _ in range(5):\\n        try:\\n            response = requests.post(\\n                random.choice(CONTROLLER_ADDR) + \"/generate\",\\n                json=data,\\n                timeout=120,\\n                proxies={\\'http\\': \\'\\', \\'https\\': \\'\\'},\\n            )\\n            text = response.json()[\"generated_text\"]\\n            return text\\n        # if timeout or connection error, retry\\n        except Timeout: \\n            print(\"Timeout, retrying...\")\\n        except ConnectionError:\\n            print(\"Connection error, retrying...\")\\n        except Exception as e:\\n            traceback.print_exc()\\n            try:\\n                print(response)\\n                print(response.text)\\n            except:\\n                pass\\n        time.sleep(5)\\n    else:\\n        raise Exception(\"Timeout after 5 retries.\")\\n',\n",
       "  'function_name': 'llm_llama',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/agent/agent.py'},\n",
       " {'code': 'def construct_llm_config(args: argparse.Namespace) -> lm_config.LMConfig:\\n    llm_config = lm_config.LMConfig(\\n        provider=args.provider, model=args.model, mode=args.mode\\n    )\\n    if args.provider in {\\'openai\\', \\'llama\\'}:\\n        llm_config.gen_config[\"temperature\"] = args.temperature\\n        llm_config.gen_config[\"top_p\"] = args.top_p\\n        llm_config.gen_config[\"context_length\"] = args.context_length\\n        llm_config.gen_config[\"max_tokens\"] = args.max_tokens\\n        llm_config.gen_config[\"stop_token\"] = args.stop_token\\n        llm_config.gen_config[\"max_obs_length\"] = args.max_obs_length\\n    else:\\n        raise NotImplementedError(f\"provider {args.provider} not implemented\")\\n    return llm_config\\n\\n',\n",
       "  'function_name': 'construct_llm_config',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/agent/agent.py'},\n",
       " {'code': 'def construct_agent(args: argparse.Namespace) -> Agent:\\n    llm_config = construct_llm_config(args)\\n\\n    agent: Agent\\n    if args.agent_type == \"teacher_forcing\":\\n        agent = TeacherForcingAgent()\\n    elif args.agent_type == \"prompt\":\\n        with open(args.instruction_path) as f:\\n            constructor_type = json.load(f)[\"meta_data\"][\"prompt_constructor\"]\\n        if llm_config.provider in {\\'llama\\'}:\\n            tokenizer = tiktoken.encoding_for_model(\\'gpt-4\\')\\n        else: tokenizer = tiktoken.encoding_for_model(llm_config.model)\\n        prompt_constructor = eval(constructor_type)(\\n            args.instruction_path, lm_config=llm_config, tokenizer=tokenizer\\n        )\\n        agent = PromptAgent(\\n            action_set_tag=args.action_set_tag,\\n            lm_config=llm_config,\\n            prompt_constructor=prompt_constructor,\\n        )\\n    else:\\n        raise NotImplementedError(\\n            f\"agent type {args.agent_type} not implemented\"\\n        )\\n    return agent\\n',\n",
       "  'function_name': 'construct_agent',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/agent/agent.py'},\n",
       " {'code': 'def run() -> None:\\n    \"\"\"Convert all python files in agent/prompts to json files in agent/prompts/jsons\\n\\n    Python files are easiser to edit\\n    \"\"\"\\n    for p_file in glob.glob(f\"agent/prompts/raw/*.py\"):\\n        # import the file as a module\\n        base_name = os.path.basename(p_file).replace(\".py\", \"\")\\n        module = importlib.import_module(f\"agent.prompts.raw.{base_name}\")\\n        prompt = module.prompt\\n        # save the prompt as a json file\\n        os.makedirs(\"agent/prompts/jsons\", exist_ok=True)\\n        with open(f\"agent/prompts/jsons/{base_name}.json\", \"w+\") as f:\\n            json.dump(prompt, f, indent=2)\\n    print(f\"Done convert python files to json\")\\n\\n',\n",
       "  'function_name': 'run',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/agent/prompts/to_json.py'},\n",
       " {'code': 'def evaluator_router(config_file: Path | str) -> EvaluatorComb:\\n    \"\"\"Router to get the evaluator class\"\"\"\\n    with open(config_file, \"r\") as f:\\n        configs = json.load(f)\\n\\n    eval_types = configs[\"eval\"][\"eval_types\"]\\n    evaluators: list[Evaluator | EvaluatorPartial] = []\\n    for eval_type in eval_types:\\n        match eval_type:\\n            case \"string_match\":\\n                evaluators.append(StringEvaluator())\\n            case \"url_match\":\\n                evaluators.append(URLExactEvaluator())\\n            case \"program_html\":\\n                evaluators.append(HTMLContentExactEvaluator())\\n            case _:\\n                raise ValueError(f\"eval_type {eval_type} is not supported\")\\n\\n    return EvaluatorComb(evaluators)\\n',\n",
       "  'function_name': 'evaluator_router',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/evaluators.py'},\n",
       " {'code': 'def shopping_get_auth_token() -> str:\\n    response = requests.post(\\n        url=f\"{SHOPPING}/rest/default/V1/integration/admin/token\",\\n        headers={\"content-type\": \"application/json\"},\\n        data=json.dumps(\\n            {\\n                \"username\": ACCOUNTS[\"shopping_site_admin\"][\"username\"],\\n                \"password\": ACCOUNTS[\"shopping_site_admin\"][\"password\"],\\n            }\\n        ),\\n    )\\n    token: str = response.json()\\n    return token\\n\\n',\n",
       "  'function_name': 'shopping_get_auth_token',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def shopping_get_latest_order_url() -> str:\\n    \"\"\"Get the latest order url from the shopping website.\"\"\"\\n\\n    header = {\\n        \"Authorization\": f\"Bearer {shopping_get_auth_token()}\",\\n        \"Content-Type\": \"application/json\",\\n    }\\n\\n    params = {\\n        \"searchCriteria[sortOrders][0][field]\": \"created_at\",\\n        \"searchCriteria[sortOrders][0][direction]\": \"DESC\",\\n        \"searchCriteria[pageSize]\": \"1\",\\n    }\\n\\n    response = requests.get(\\n        f\"{SHOPPING}/rest/V1/orders\", params=params, headers=header\\n    )\\n    assert response.status_code == 200\\n    response_obj = response.json()[\"items\"][0]\\n    order_id = int(response_obj[\"increment_id\"])\\n    order_url = f\"{SHOPPING}/sales/order/view/order_id/{order_id}/\"\\n    return order_url\\n\\n',\n",
       "  'function_name': 'shopping_get_latest_order_url',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def shopping_get_sku_latest_review_author(sku: str) -> str:\\n    \"\"\"Get the latest review for shopping admin.\"\"\"\\n    header = {\\n        \"Authorization\": f\"Bearer {shopping_get_auth_token()}\",\\n        \"Content-Type\": \"application/json\",\\n    }\\n    response = requests.get(\\n        f\"{SHOPPING}/rest/V1/products/{sku}/reviews\", headers=header\\n    )\\n    assert response.status_code == 200\\n    response_obj = response.json()\\n    if len(response_obj) == 0:\\n        return \"\"\\n    author: str = response_obj[-1][\"nickname\"]\\n    return author\\n\\n',\n",
       "  'function_name': 'shopping_get_sku_latest_review_author',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def shopping_get_sku_latest_review_rating(sku: str) -> str:\\n    \"\"\"Get the latest review for shopping admin.\"\"\"\\n    header = {\\n        \"Authorization\": f\"Bearer {shopping_get_auth_token()}\",\\n        \"Content-Type\": \"application/json\",\\n    }\\n    response = requests.get(\\n        f\"{SHOPPING}/rest/V1/products/{sku}/reviews\", headers=header\\n    )\\n    assert response.status_code == 200\\n    response_obj = response.json()\\n    if len(response_obj) == 0:\\n        return \"\"\\n    assert response_obj[0][\"ratings\"][0][\"rating_name\"] == \"Rating\"\\n    rating: str = str(response_obj[-1][\"ratings\"][0][\"percent\"])\\n    return rating\\n\\n',\n",
       "  'function_name': 'shopping_get_sku_latest_review_rating',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def reddit_get_post_url(url: str) -> str:\\n    \"\"\"Get the post url\"\"\"\\n    # Url is http://domain/f/subreddit/post_id/...\\n    # get domain, subreddit, post_id\\n    domain = urlparse(url).netloc\\n    tok_url = urlparse(url).path.split(\"/\")\\n    # not a valid post/comment url, return the url as is\\n    if len(tok_url) < 4:\\n        return url\\n    if tok_url[1] != \"f\":\\n        return url\\n    subreddit = urlparse(url).path.split(\"/\")[2]\\n    post_id = urlparse(url).path.split(\"/\")[3]\\n    scheme = urlparse(url).scheme\\n    post_url = f\"{scheme}://{domain}/f/{subreddit}/{post_id}/\"\\n    return post_url\\n\\n',\n",
       "  'function_name': 'reddit_get_post_url',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def gitlab_get_project_memeber_role(page: Page, account_name: str) -> str:\\n    # get the account index\\n    try:\\n        account_idx = page.evaluate(\\n            f\"\"\"(() => {{\\n                const elements = document.querySelectorAll(\"td[data-label=\\'Account\\'] span.gl-avatar-labeled-sublabel\");\\n                let index = -1;  // Default value if not found\\n\\n                for(let i = 0; i < elements.length; i++) {{\\n                    if(elements[i].outerText === \\'@{account_name}\\') {{\\n                        index = i;\\n                        break;\\n                    }}\\n                }}\\n\\n                return index;\\n            }})()\"\"\"\\n        )\\n\\n        # get the role\\n        role: str = page.evaluate(\\n            f\"\"\"(() => {{\\n                return document.querySelectorAll(\"td.col-max-role span\")[{account_idx}].outerText;\\n            }})()\"\"\"\\n        )\\n    except Exception:\\n        role = \"\"\\n\\n    return role\\n\\n',\n",
       "  'function_name': 'gitlab_get_project_memeber_role',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def llm_fuzzy_match(pred: str, reference: str, question: str) -> float:\\n    \"\"\"Check whether the prediction matches the reference with GPT-3.5\"\"\"\\n    messages: list[dict[str, Any]] = []\\n    messages.append(\\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"}\\n    )\\n\\n    messages.append(\\n        {\\n            \"role\": \"user\",\\n            \"content\": f\\'Given the statement \"{pred}\", would it be correct to infer \"{reference}\"? Yes or No\\',\\n        }\\n    )\\n\\n    response = generate_from_openai_chat_completion(\\n        messages=messages,\\n        model=\"gpt-3.5-turbo\",\\n        temperature=0,\\n        top_p=1,\\n        context_length=0,\\n        max_tokens=16,\\n        stop_token=None,\\n    )\\n    if \"Yes\" in response:\\n        return 1.0\\n    else:\\n        return 0.0\\n',\n",
       "  'function_name': 'llm_fuzzy_match',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/evaluation_harness/helper_functions.py'},\n",
       " {'code': 'def index() -> str:\\n    return render_template(\"index.html\")\\n\\n',\n",
       "  'function_name': 'index',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/environment_docker/webarena-homepage/app.py'},\n",
       " {'code': 'def scratchpad() -> str:\\n    return render_template(\"scratchpad.html\")\\n\\n',\n",
       "  'function_name': 'scratchpad',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/environment_docker/webarena-homepage/app.py'},\n",
       " {'code': 'def calculator() -> str:\\n    return render_template(\"calculator.html\")\\n\\n',\n",
       "  'function_name': 'calculator',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/environment_docker/webarena-homepage/app.py'},\n",
       " {'code': 'def password() -> str:\\n    return render_template(\"password.html\")\\n\\n',\n",
       "  'function_name': 'password',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/environment_docker/webarena-homepage/app.py'},\n",
       " {'code': 'def png_bytes_to_numpy(png: bytes) -> npt.NDArray[np.uint8]:\\n    \"\"\"Convert png bytes to numpy array\\n\\n    Example:\\n\\n    >>> fig = go.Figure(go.Scatter(x=[1], y=[1]))\\n    >>> plt.imshow(png_bytes_to_numpy(fig.to_image(\\'png\\')))\\n    \"\"\"\\n    return np.array(Image.open(BytesIO(png)))\\n\\n',\n",
       "  'function_name': 'png_bytes_to_numpy',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/utils.py'},\n",
       " {'code': 'def create_empty_metadata() -> ObservationMetadata:\\n    return {\\n        \"obs_nodes_info\": {},\\n    }\\n\\n',\n",
       "  'function_name': 'create_empty_metadata',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/processors.py'},\n",
       " {'code': 'def is_expired(\\n    storage_state: Path, url: str, keyword: str, url_exact: bool = True\\n) -> bool:\\n    \"\"\"Test whether the cookie is expired\"\"\"\\n    if not storage_state.exists():\\n        return True\\n\\n    context_manager = sync_playwright()\\n    playwright = context_manager.__enter__()\\n    browser = playwright.chromium.launch(headless=HEADLESS, slow_mo=SLOW_MO)\\n    context = browser.new_context(storage_state=storage_state)\\n    page = context.new_page()\\n    page.goto(url)\\n    d_url = page.url\\n    content = page.content()\\n    context_manager.__exit__()\\n    if keyword:\\n        return keyword not in content\\n    else:\\n        print(url, d_url)\\n        if url_exact:\\n            return d_url != url\\n        else:\\n            return url not in d_url\\n\\n',\n",
       "  'function_name': 'is_expired',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/auto_login.py'},\n",
       " {'code': 'def renew_comb(comb: list[str]) -> None:\\n    context_manager = sync_playwright()\\n    playwright = context_manager.__enter__()\\n    browser = playwright.chromium.launch(headless=HEADLESS)\\n    context = browser.new_context()\\n    page = context.new_page()\\n\\n    if \"shopping\" in comb:\\n        username = ACCOUNTS[\"shopping\"][\"username\"]\\n        password = ACCOUNTS[\"shopping\"][\"password\"]\\n        page.goto(f\"{SHOPPING}/customer/account/login/\")\\n        page.get_by_label(\"Email\", exact=True).fill(username)\\n        page.get_by_label(\"Password\", exact=True).fill(password)\\n        page.get_by_role(\"button\", name=\"Sign In\").click()\\n\\n    if \"reddit\" in comb:\\n        username = ACCOUNTS[\"reddit\"][\"username\"]\\n        password = ACCOUNTS[\"reddit\"][\"password\"]\\n        page.goto(f\"{REDDIT}/login\")\\n        page.get_by_label(\"Username\").fill(username)\\n        page.get_by_label(\"Password\").fill(password)\\n        page.get_by_role(\"button\", name=\"Log in\").click()\\n\\n    if \"shopping_admin\" in comb:\\n        username = ACCOUNTS[\"shopping_admin\"][\"username\"]\\n        password = ACCOUNTS[\"shopping_admin\"][\"password\"]\\n        page.goto(f\"{SHOPPING_ADMIN}\")\\n        page.get_by_placeholder(\"user name\").fill(username)\\n        page.get_by_placeholder(\"password\").fill(password)\\n        page.get_by_role(\"button\", name=\"Sign in\").click()\\n\\n    if \"gitlab\" in comb:\\n        username = ACCOUNTS[\"gitlab\"][\"username\"]\\n        password = ACCOUNTS[\"gitlab\"][\"password\"]\\n        page.goto(f\"{GITLAB}/users/sign_in\")\\n        page.get_by_test_id(\"username-field\").click()\\n        page.get_by_test_id(\"username-field\").fill(username)\\n        page.get_by_test_id(\"username-field\").press(\"Tab\")\\n        page.get_by_test_id(\"password-field\").fill(password)\\n        page.get_by_test_id(\"sign-in-button\").click()\\n\\n    context.storage_state(path=f\"./.auth/{\\'.\\'.join(comb)}_state.json\")\\n\\n    context_manager.__exit__()\\n\\n',\n",
       "  'function_name': 'renew_comb',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/auto_login.py'},\n",
       " {'code': 'def main() -> None:\\n    sites = [\"gitlab\", \"shopping\", \"shopping_admin\", \"reddit\"]\\n    urls = [\\n        f\"{GITLAB}/-/profile\",\\n        f\"{SHOPPING}/wishlist/\",\\n        f\"{SHOPPING_ADMIN}/dashboard\",\\n        f\"{REDDIT}/user/{ACCOUNTS[\\'reddit\\'][\\'username\\']}/account\",\\n    ]\\n    exact_match = [True, True, True, True]\\n    keywords = [\"\", \"\", \"Dashboard\", \"Delete\"]\\n\\n    pairs = list(combinations(sites, 2))\\n    for pair in pairs:\\n        # TODO[shuyanzh] auth don\\'t work on these two sites\\n        if \"reddit\" in pair and (\\n            \"shopping\" in pair or \"shopping_admin\" in pair\\n        ):\\n            continue\\n        renew_comb(list(sorted(pair)))\\n\\n    for site in sites:\\n        renew_comb([site])\\n\\n    for c_file in glob.glob(\"./.auth/*.json\"):\\n        comb = c_file.split(\"/\")[-1].rsplit(\"_\", 1)[0].split(\".\")\\n        for cur_site in comb:\\n            url = urls[sites.index(cur_site)]\\n            keyword = keywords[sites.index(cur_site)]\\n            match = exact_match[sites.index(cur_site)]\\n            if is_expired(Path(c_file), url, keyword, match):\\n                print(c_file)\\n                assert False\\n            # assert not is_expired(Path(c_file), url, keyword, match)\\n\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/auto_login.py'},\n",
       " {'code': 'def get_render_action(\\n    action: Action,\\n    observation_metadata: dict[str, ObservationMetadata],\\n    action_set_tag: str,\\n) -> str:\\n    \"\"\"Parse the predicted actions for rendering purpose. More comprehensive information\"\"\"\\n    match action_set_tag:\\n        case \"id_accessibility_tree\":\\n            text_meta_data = observation_metadata[\"text\"]\\n            if action[\"element_id\"] in text_meta_data[\"obs_nodes_info\"]:\\n                node_content = text_meta_data[\"obs_nodes_info\"][\\n                    action[\"element_id\"]\\n                ][\"text\"]\\n            else:\\n                node_content = \"No match found\"\\n\\n            action_str = f\"<div class=\\'raw_parsed_prediction\\' style=\\'background-color:grey\\'><pre>{action[\\'raw_prediction\\']}</pre></div>\"\\n            action_str += f\"<div class=\\'action_object\\' style=\\'background-color:grey\\'><pre>{repr(action)}</pre></div>\"\\n            action_str += f\"<div class=\\'parsed_action\\' style=\\'background-color:yellow\\'><pre>{action2str(action, action_set_tag, node_content)}</pre></div>\"\\n\\n        case \"playwright\":\\n            action_str = action[\"pw_code\"]\\n        case _:\\n            raise ValueError(f\"Unknown action type {action[\\'action_type\\']}\")\\n    return action_str\\n\\n',\n",
       "  'function_name': 'get_render_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/helper_functions.py'},\n",
       " {'code': 'def get_action_description(\\n    action: Action,\\n    observation_metadata: dict[str, ObservationMetadata],\\n    action_set_tag: str,\\n    prompt_constructor: PromptConstructor | None,\\n) -> str:\\n    \"\"\"Generate the text version of the predicted actions to store in action history for prompt use.\\n    May contain hint information to recover from the failures\"\"\"\\n\\n    match action_set_tag:\\n        case \"id_accessibility_tree\":\\n            text_meta_data = observation_metadata[\"text\"]\\n            if action[\"action_type\"] in [\\n                ActionTypes.CLICK,\\n                ActionTypes.HOVER,\\n                ActionTypes.TYPE,\\n            ]:\\n                action_name = str(action[\"action_type\"]).split(\".\")[1].lower()\\n                if action[\"element_id\"] in text_meta_data[\"obs_nodes_info\"]:\\n                    node_content = text_meta_data[\"obs_nodes_info\"][\\n                        action[\"element_id\"]\\n                    ][\"text\"]\\n                    node_content = \" \".join(node_content.split()[1:])\\n                    action_str = action2str(\\n                        action, action_set_tag, node_content\\n                    )\\n                else:\\n                    action_str = f\"Attempt to perfom \\\\\"{action_name}\\\\\" on element \\\\\"[{action[\\'element_id\\']}]\\\\\" but no matching element found. Please check the observation more carefully.\"\\n            else:\\n                if (\\n                    action[\"action_type\"] == ActionTypes.NONE\\n                    and prompt_constructor is not None\\n                ):\\n                    action_splitter = prompt_constructor.instruction[\\n                        \"meta_data\"\\n                    ][\"action_splitter\"]\\n                    action_str = f\\'The previous prediction you issued was \"{action[\"raw_prediction\"]}\". However, the format was incorrect. Ensure that the action is wrapped inside a pair of {action_splitter} and enclose arguments within [] as follows: {action_splitter}action [arg] ...{action_splitter}.\\'\\n                else:\\n                    action_str = action2str(action, action_set_tag, \"\")\\n\\n        case \"playwright\":\\n            action_str = action[\"pw_code\"]\\n\\n        case _:\\n            raise ValueError(f\"Unknown action type {action[\\'action_type\\']}\")\\n\\n    return action_str\\n\\n',\n",
       "  'function_name': 'get_action_description',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/helper_functions.py'},\n",
       " {'code': 'def parse_action(action: str) -> PlaywrightScript:\\n    splitted = action.strip().split(\" \")\\n    assert len(splitted) >= 2\\n    match splitted[:2]:\\n        case [\"goto\", url]:\\n            assert len(splitted) == 2\\n            return PlaywrightScript(\"goto\", url)\\n        case [\"get_by_role\", destination]:\\n            assert len(splitted) >= 4\\n            match splitted[2:]:\\n                case [name, operation]:\\n                    return PlaywrightScript(\\n                        \"get_by_role\", destination, name, operation\\n                    )\\n                case [name, operation, value]:\\n                    return PlaywrightScript(\\n                        \"get_by_role\", destination, name, operation, value\\n                    )\\n                case _:\\n                    raise ValueError(\"Invalid action\")\\n        case _:\\n            raise ValueError(f\"Invalid action {action}\")\\n\\n',\n",
       "  'function_name': 'parse_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/envs.py'},\n",
       " {'code': 'def is_in_viewport(\\n    element: Locator, viewport: ViewportSize, threshold: float = 0.3\\n) -> bool:\\n    \"\"\"Given a playwright locator, check if it is in the viewport\"\"\"\\n    box = element.bounding_box()\\n    assert box is not None\\n    boxx0 = box[\"x\"]\\n    boxx1 = box[\"x\"] + box[\"width\"]\\n    boxy0 = box[\"y\"]\\n    boxy1 = box[\"y\"] + box[\"height\"]\\n    viewportx0, viewporty0 = 0, 0\\n    viewportx1, viewporty1 = viewport[\"width\"], viewport[\"height\"]\\n    inter = max(0, min(boxx1, viewportx1) - max(boxx0, viewportx0)) * max(\\n        0, min(boxy1, viewporty1) - max(boxy0, viewporty0)\\n    )\\n    ratio = inter / (box[\"width\"] * box[\"height\"])\\n    return ratio > threshold\\n\\n',\n",
       "  'function_name': 'is_in_viewport',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def async_is_in_viewport(\\n    element: ALocator, viewport: ViewportSize, threshold: float = 0.3\\n) -> bool:\\n    box = await element.bounding_box()\\n    assert box is not None\\n    boxx0 = box[\"x\"]\\n    boxx1 = box[\"x\"] + box[\"width\"]\\n    boxy0 = box[\"y\"]\\n    boxy1 = box[\"y\"] + box[\"height\"]\\n    viewportx0, viewporty0 = 0, 0\\n    viewportx1, viewporty1 = viewport[\"width\"], viewport[\"height\"]\\n    inter = max(0, min(boxx1, viewportx1) - max(boxx0, viewportx0)) * max(\\n        0, min(boxy1, viewporty1) - max(boxy0, viewporty0)\\n    )\\n    ratio = inter / (box[\"width\"] * box[\"height\"])\\n    return ratio > threshold\\n\\n',\n",
       "  'function_name': 'async_is_in_viewport',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def action2str(\\n    action: Action, action_set_tag: str, semantic_element: str = \"\"\\n) -> str:\\n    \"\"\"Return the string representation of an action\\n\\n    sementic_element: the semantic information of the element\\n    such as a line in an accessibility tree\\n    \"\"\"\\n    if action_set_tag == \"id_accessibility_tree\":\\n        element_id = action[\"element_id\"]\\n        match action[\"action_type\"]:\\n            case ActionTypes.CLICK:\\n                # [ID=X] xxxxx\\n                action_str = f\"click [{element_id}] where [{element_id}] is {semantic_element}\"\\n            case ActionTypes.TYPE:\\n                text = \"\".join([_id2key[i] for i in action[\"text\"]])\\n                action_str = f\"type [{element_id}] [{text}] where [{element_id}] is {semantic_element}\"\\n            case ActionTypes.HOVER:\\n                action_str = f\"hover [{element_id}] where [{element_id}] is {semantic_element}\"\\n            case ActionTypes.SCROLL:\\n                action_str = f\"scroll [{action[\\'direction\\']}]\"\\n            case ActionTypes.KEY_PRESS:\\n                action_str = f\"press [{action[\\'key_comb\\']}]\"\\n            case ActionTypes.GOTO_URL:\\n                action_str = f\"goto [{action[\\'url\\']}]\"\\n            case ActionTypes.NEW_TAB:\\n                action_str = \"new_tab\"\\n            case ActionTypes.PAGE_CLOSE:\\n                action_str = \"close_tab\"\\n            case ActionTypes.GO_BACK:\\n                action_str = \"go_back\"\\n            case ActionTypes.GO_FORWARD:\\n                action_str = \"go_forward\"\\n            case ActionTypes.PAGE_FOCUS:\\n                action_str = f\"page_focus [{action[\\'page_number\\']}]\"\\n            case ActionTypes.STOP:\\n                action_str = f\"stop [{action[\\'answer\\']}]\"\\n            case ActionTypes.NONE:\\n                action_str = \"none\"\\n            case _:\\n                raise ValueError(\\n                    f\"Unknown action type {action[\\'action_type\\']}\"\\n                )\\n    else:\\n        raise NotImplementedError(f\"Unknown action set tag {action_set_tag}\")\\n\\n    return action_str\\n\\n',\n",
       "  'function_name': 'action2str',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def action2create_function(action: Action) -> str:\\n    match (action[\"action_type\"]):\\n        case ActionTypes.NONE:\\n            return \"create_none_action()\"\\n        # mouse wheel and keyboard action\\n        case ActionTypes.SCROLL:\\n            direction = \"up\" if \"up\" in action[\"direction\"] else \"down\"\\n            return f\"create_scroll_action({repr(direction)})\"\\n        case ActionTypes.KEY_PRESS:\\n            return f\"create_key_press_action({repr(action[\\'key_comb\\'])})\"\\n        # inter-page actions\\n        case ActionTypes.PAGE_FOCUS:\\n            return f\"create_page_focus_action({action[\\'page_number\\']})\"\\n        case ActionTypes.NEW_TAB:\\n            return \"create_new_tab_action()\"\\n        case ActionTypes.GO_BACK:\\n            return \"create_go_back_action()\"\\n        case ActionTypes.GO_FORWARD:\\n            return \"create_go_forward_action()\"\\n        case ActionTypes.GOTO_URL:\\n            return f\"create_goto_url_action({repr(action[\\'url\\'])})\"\\n        case ActionTypes.PAGE_CLOSE:\\n            return \"create_page_close_action()\"\\n\\n        # low-level keyboard and mouse actions\\n        case ActionTypes.MOUSE_CLICK:\\n            return f\"create_mouse_click_action({action[\\'coords\\'][0]}, {action[\\'coords\\'][1]})\"\\n        case ActionTypes.MOUSE_HOVER:\\n            return f\"create_mouse_hover_action({action[\\'coords\\'][0]}, {action[\\'coords\\'][1]})\"\\n        case ActionTypes.KEYBOARD_TYPE:\\n            return f\"create_keyboard_type_action({list(map(lambda x: _id2key[x], action[\\'text\\']))})\"\\n\\n        # mid-level keyboard and mouse actions\\n        case ActionTypes.CLICK:\\n            args = []\\n            args.append(f\"element_id={repr(action[\\'element_id\\'])}\")\\n            args.append(\\n                f\"element_role={repr(_id2role[action[\\'element_role\\']])}\"\\n            )\\n            args.append(f\"element_name={repr(action[\\'element_name\\'])}\")\\n            args.append(f\"pw_code={repr(action[\\'pw_code\\'])}\")\\n            args_str = \", \".join(args)\\n            return f\"create_click_action({args_str})\"\\n        case ActionTypes.HOVER:\\n            args = []\\n            args.append(f\"element_id={repr(action[\\'element_id\\'])}\")\\n            args.append(\\n                f\"element_role={repr(_id2role[action[\\'element_role\\']])}\"\\n            )\\n            args.append(f\"element_name={repr(action[\\'element_name\\'])}\")\\n            args.append(f\"pw_code={repr(action[\\'pw_code\\'])}\")\\n            args_str = \", \".join(args)\\n            return f\"create_hover_action({args_str})\"\\n        case ActionTypes.TYPE:\\n            args = []\\n            text = \"\".join(map(lambda x: _id2key[x], action[\"text\"]))\\n            args.append(f\"text={repr(text)}\")\\n            args.append(f\"element_id={repr(action[\\'element_id\\'])}\")\\n            args.append(\\n                f\"element_role={repr(_id2role[action[\\'element_role\\']])}\"\\n            )\\n            args.append(f\"element_name={repr(action[\\'element_name\\'])}\")\\n            args.append(f\"pw_code={repr(action[\\'pw_code\\'])}\")\\n            args_str = \", \".join(args)\\n            return f\"create_type_action({args_str})\"\\n\\n        # high-level actions, only support locators from playwright\\n        case ActionTypes.CHECK:\\n            return f\"create_check_action(pw_code={repr(action[\\'pw_code\\'])})\"\\n        case ActionTypes.SELECT_OPTION:\\n            return f\"create_select_option_action(pw_code={repr(action[\\'pw_code\\'])})\"\\n        case ActionTypes.STOP:\\n            return f\\'create_stop_action({repr(action[\"answer\"])})\\'\\n\\n    raise ValueError(f\"Invalid action type: {action[\\'action_type\\']}\")\\n\\n',\n",
       "  'function_name': 'action2create_function',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def is_equivalent(a: Action, b: Action) -> bool:\\n    \"\"\"Return True if two actions are equal.\"\"\"\\n    if a[\"action_type\"] != b[\"action_type\"]:\\n        return False\\n    match (a[\"action_type\"]):\\n        case ActionTypes.NONE:\\n            return True\\n        case ActionTypes.SCROLL:\\n            da = \"up\" if \"up\" in a[\"direction\"] else \"down\"\\n            db = \"up\" if \"up\" in b[\"direction\"] else \"down\"\\n            return da == db\\n        case ActionTypes.KEY_PRESS:\\n            return a[\"key_comb\"] == b[\"key_comb\"]\\n        case ActionTypes.MOUSE_CLICK | ActionTypes.MOUSE_HOVER:\\n            return np.allclose(a[\"coords\"], b[\"coords\"])\\n        case ActionTypes.KEYBOARD_TYPE:\\n            return a[\"text\"] == b[\"text\"]\\n        case ActionTypes.CLICK | ActionTypes.HOVER | ActionTypes.TYPE:  # TODO: can be further optimized\\n            if a[\"element_id\"] and b[\"element_id\"]:\\n                return a[\"element_id\"] == b[\"element_id\"]\\n            elif a[\"element_role\"] and b[\"element_role\"]:\\n                return (\\n                    a[\"element_role\"] == b[\"element_role\"]\\n                    and a[\"element_name\"] == b[\"element_name\"]\\n                )\\n            elif a[\"pw_code\"] and b[\"pw_code\"]:\\n                return a[\"pw_code\"] == b[\"pw_code\"]\\n            else:\\n                return False\\n        case ActionTypes.PAGE_FOCUS:\\n            return a[\"page_number\"] == b[\"page_number\"]\\n        case ActionTypes.NEW_TAB:\\n            return True\\n        case ActionTypes.GO_BACK:\\n            return True\\n        case ActionTypes.GO_FORWARD:\\n            return True\\n        case ActionTypes.GOTO_URL:\\n            return a[\"url\"] == b[\"url\"]\\n        case ActionTypes.PAGE_CLOSE:\\n            return True\\n        case ActionTypes.CHECK | ActionTypes.SELECT_OPTION:\\n            return a[\"pw_code\"] == b[\"pw_code\"]\\n        case ActionTypes.STOP:\\n            return a[\"answer\"] == b[\"answer\"]\\n        case _:\\n            raise ValueError(f\"Unknown action type: {a[\\'action_type\\']}\")\\n\\n',\n",
       "  'function_name': 'is_equivalent',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def _keys2ids(keys: list[int | str] | str) -> list[int]:\\n    return list(\\n        map(\\n            lambda key: _key2id[str(key)]\\n            if is_bearable(key, str)\\n            else int(key),\\n            keys,\\n        )\\n    )\\n\\n',\n",
       "  'function_name': '_keys2ids',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def get_action_space() -> spaces.Dict:\\n    \"\"\"Return the space of serialized actions.\"\"\"\\n    space = spaces.Dict(\\n        {\\n            \"action_type\": spaces.Discrete(len(ActionTypes)),\\n            # coords (left, top) is used for COORD_CLICK\\n            \"coords\": spaces.Box(\\n                np.array([0.0, 0.0], dtype=np.float32),\\n                np.array([1.0, 1.0], dtype=np.float32),\\n            ),\\n            # element role is used for FOCUS_AND_CLICK and FOCUS_AND_TYPE\\n            \"element_role\": spaces.Discrete(\\n                len(ROLES) + len(SPECIAL_LOCATORS)\\n            ),\\n            # element name is used with element role\\n            \"element_name\": spaces.Text(TEXT_MAX_LENGTH),\\n            \"element_id\": spaces.Text(TEXT_MAX_LENGTH),\\n            # text is only used for TYPE and FOCUS_AND_TYPE\\n            \"text\": spaces.MultiDiscrete(\\n                [\\n                    len(ASCII_CHARSET)\\n                    + len(SPECIAL_KEYS)\\n                    + len(FREQ_UNICODE_CHARSET)\\n                ]\\n                * TYPING_MAX_LENGTH\\n            ),\\n            \"page_number\": spaces.Discrete(MAX_PAGE_NUMBER),\\n            \"url\": spaces.Text(URL_MAX_LENGTH),\\n            \"nth\": spaces.Discrete(MAX_ELEMENT_INDEX_IN_VIEWPORT),\\n            \"key_comb\": spaces.Text(MAX_VANILLA_STR_LENGTH),\\n            \"direction\": spaces.Text(MAX_VANILLA_STR_LENGTH),\\n            \"pw_code\": spaces.Text(MAX_VANILLA_STR_LENGTH),\\n            \"answer\": spaces.Text(MAX_ANSWER_LENGTH),\\n        }\\n    )\\n    return space\\n\\n',\n",
       "  'function_name': 'get_action_space',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_random_action() -> Action:\\n    \"\"\"Return a random action.\"\"\"\\n    return {\\n        \"action_type\": np.random.randint(len(ActionTypes)),\\n        \"coords\": np.random.rand(2).astype(np.float32),\\n        \"element_role\": np.random.randint(len(ROLES) + len(SPECIAL_LOCATORS)),\\n        \"element_name\": \"\".join(\\n            random.choices(ASCII_CHARSET, k=np.random.randint(TEXT_MAX_LENGTH))\\n        ),\\n        \"text\": list(\\n            random.choices(\\n                list(range(len(ASCII_CHARSET))),\\n                k=np.random.randint(TYPING_MAX_LENGTH),\\n            )\\n        ),\\n        \"page_number\": np.random.randint(MAX_PAGE_NUMBER),\\n        \"url\": \"\".join(\\n            random.choices(ASCII_CHARSET, k=np.random.randint(URL_MAX_LENGTH))\\n        ),\\n        \"nth\": np.random.randint(MAX_ELEMENT_INDEX_IN_VIEWPORT),\\n        \"element_id\": str(np.random.randint(MAX_ELEMENT_ID)),\\n        \"key_comb\": \"+\".join(\\n            random.choices(SPECIAL_KEYS, k=np.random.randint(3))\\n        ),\\n        \"direction\": random.choice([\"up\", \"down\"]),\\n        \"pw_code\": \"\".join(\\n            random.choices(\\n                string.ascii_uppercase + string.digits,\\n                k=np.random.randint(MAX_VANILLA_STR_LENGTH),\\n            )\\n        ),\\n        \"answer\": str(np.random.randint(MAX_ANSWER_LENGTH)),\\n        \"raw_prediction\": str(np.random.randint(MAX_ANSWER_LENGTH)),\\n    }\\n\\n',\n",
       "  'function_name': 'create_random_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_none_action() -> Action:\\n    \"\"\"Return a valid action object that does nothing.\"\"\"\\n    return {\\n        \"action_type\": ActionTypes.NONE,\\n        \"coords\": np.zeros(2, dtype=np.float32),\\n        \"element_role\": 0,\\n        \"element_name\": \"\",\\n        \"text\": [],\\n        \"page_number\": 0,\\n        \"url\": \"\",\\n        \"nth\": 0,\\n        \"pw_code\": \"\",  # str that requires further processing\\n        \"element_id\": \"\",\\n        \"key_comb\": \"\",\\n        \"direction\": \"\",\\n        \"answer\": \"\",\\n        \"raw_prediction\": \"\",\\n    }\\n\\n',\n",
       "  'function_name': 'create_none_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_stop_action(answer: str) -> Action:\\n    action = create_none_action()\\n    action.update({\"action_type\": ActionTypes.STOP, \"answer\": answer})\\n    return action\\n\\n',\n",
       "  'function_name': 'create_stop_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_scroll_action(direction: str) -> Action:\\n    \"\"\"Return the playwright action\"\"\"\\n    assert direction in [\"up\", \"down\"]\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.SCROLL,\\n            \"direction\": direction,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_scroll_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_mouse_hover_action(\\n    left: float | None = None, top: float | None = None\\n) -> Action:\\n    \"\"\"Return a valid action object with type COORD_CLICK.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.MOUSE_HOVER,\\n            \"coords\": np.array([left, top], dtype=np.float32),\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_mouse_hover_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_key_press_action(key_comb: str) -> Action:\\n    \"\"\"Return the key press action\"\"\"\\n\\n    def map_keys(key_comb: str) -> str:\\n        keys = key_comb.split(\"+\")\\n        mapped_keys = []\\n        for key in keys:\\n            mapped_key = SPECIAL_KEY_MAPPINGS.get(key.lower(), key)\\n            mapped_keys.append(mapped_key)\\n        return \"+\".join(mapped_keys)\\n\\n    action = create_none_action()\\n    mapped_key_comb = map_keys(key_comb)\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.KEY_PRESS,\\n            \"key_comb\": mapped_key_comb,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_key_press_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_page_focus_action(page_number: int) -> Action:\\n    \"\"\"Return a valid action object with type PAGE_FOCUS.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.PAGE_FOCUS,\\n            \"page_number\": page_number,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_page_focus_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_new_tab_action() -> Action:\\n    \"\"\"Return a valid action object with type NEW_TAB.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.NEW_TAB,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_new_tab_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_go_back_action() -> Action:\\n    \"\"\"Return a valid action object with type GO_BACK.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.GO_BACK,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_go_back_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_go_forward_action() -> Action:\\n    \"\"\"Return a valid action object with type GO_FORWARD.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.GO_FORWARD,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_go_forward_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_goto_url_action(url: str) -> Action:\\n    \"\"\"Return a valid action object with type GOTO_URL.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.GOTO_URL,\\n            \"url\": url,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_goto_url_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_page_close_action() -> Action:\\n    \"\"\"Return a valid action object with type PAGE_CLOSE.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.PAGE_CLOSE,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_page_close_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_mouse_click_action(\\n    left: float | None = None, top: float | None = None\\n) -> Action:\\n    \"\"\"Return a valid action object with type COORD_CLICK.\"\"\"\\n    action = create_none_action()\\n    if left and top:\\n        action.update(\\n            {\\n                \"action_type\": ActionTypes.MOUSE_CLICK,\\n                \"coords\": np.array([left, top], dtype=np.float32),\\n            }\\n        )\\n    elif (not left) and (not top):\\n        action.update(\\n            {\\n                \"action_type\": ActionTypes.CLICK,\\n            }\\n        )\\n    else:\\n        raise ValueError(\"left and top must be both None or both not None\")\\n    return action\\n\\n',\n",
       "  'function_name': 'create_mouse_click_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_keyboard_type_action(keys: list[int | str] | str) -> Action:\\n    \"\"\"Return a valid action object with type TYPE.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.KEYBOARD_TYPE,\\n            \"text\": _keys2ids(keys),\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_keyboard_type_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_click_action(\\n    element_id: str = \"\",\\n    element_role: RolesType = \"link\",\\n    element_name: str = \"\",\\n    pw_code: str = \"\",\\n    nth: int = 0,\\n) -> Action:\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.CLICK,\\n            \"element_id\": element_id,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"nth\": nth,\\n            \"pw_code\": pw_code,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_click_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_hover_action(\\n    element_id: str = \"\",\\n    element_role: RolesType = \"link\",\\n    element_name: str = \"\",\\n    pw_code: str = \"\",\\n    nth: int = 0,\\n) -> Action:\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.HOVER,\\n            \"element_id\": element_id,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"nth\": nth,\\n            \"pw_code\": pw_code,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_hover_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_type_action(\\n    text: str,\\n    element_id: str = \"\",\\n    element_role: RolesType = \"link\",\\n    element_name: str = \"\",\\n    pw_code: str = \"\",\\n    nth: int = 0,\\n) -> Action:\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.TYPE,\\n            \"element_id\": element_id,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"nth\": nth,\\n            \"text\": _keys2ids(text),\\n            \"pw_code\": pw_code,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_type_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_check_action(pw_code: str) -> Action:\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.CHECK,\\n            \"pw_code\": pw_code,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_check_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_select_option_action(\\n    pw_code: str,\\n) -> Action:\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.SELECT_OPTION,\\n            \"pw_code\": pw_code,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_select_option_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_focus_action(\\n    element_role: RolesType, element_name: str = \"\", nth: int = 0\\n) -> Action:\\n    \"\"\"Return a valid action object with type CLICK.\\n\\n    Keep compatible with the old version.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.CLICK,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"nth\": nth,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_focus_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_focus_and_click_action(\\n    element_role: RolesType, element_name: str = \"\", nth: int = 0\\n) -> Action:\\n    \"\"\"Return a valid action object with type CLICK.\\n\\n    Keep compatible with the old version.\"\"\"\\n\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.CLICK,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"nth\": nth,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_focus_and_click_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_focus_and_type_action(\\n    keys: list[int | str] | str,\\n    element_role: RolesType,\\n    element_name: str = \"\",\\n    nth: int = 0,\\n) -> Action:\\n    \"\"\"Return a valid action object with type TYPE.\\n\\n    Keep compatible with the old version.\"\"\"\\n    action = create_none_action()\\n    action.update(\\n        {\\n            \"action_type\": ActionTypes.TYPE,\\n            \"element_role\": _role2id[element_role],\\n            \"element_name\": element_name,\\n            \"text\": _keys2ids(keys),\\n            \"nth\": nth,\\n        }\\n    )\\n    return action\\n\\n',\n",
       "  'function_name': 'create_focus_and_type_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_scroll(direction: str, page: Page) -> None:\\n    # perform the action\\n    # code from natbot\\n    if direction == \"up\":\\n        page.evaluate(\\n            \"(document.scrollingElement || document.body).scrollTop = (document.scrollingElement || document.body).scrollTop - window.innerHeight;\"\\n        )\\n    elif direction == \"down\":\\n        page.evaluate(\\n            \"(document.scrollingElement || document.body).scrollTop = (document.scrollingElement || document.body).scrollTop + window.innerHeight;\"\\n        )\\n\\n',\n",
       "  'function_name': 'execute_scroll',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_scroll(direction: str, page: APage) -> None:\\n    # perform the action\\n    # code from natbot\\n    if direction == \"up\":\\n        await page.evaluate(\\n            \"(document.scrollingElement || document.body).scrollTop = (document.scrollingElement || document.body).scrollTop - window.innerHeight;\"\\n        )\\n    elif direction == \"down\":\\n        await page.evaluate(\\n            \"(document.scrollingElement || document.body).scrollTop = (document.scrollingElement || document.body).scrollTop + window.innerHeight;\"\\n        )\\n\\n',\n",
       "  'function_name': 'aexecute_scroll',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_key_press(key: str, page: Page) -> None:\\n    \"\"\"Press a key.\"\"\"\\n    page.keyboard.press(key)\\n\\n',\n",
       "  'function_name': 'execute_key_press',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_key_press(key: str, page: APage) -> None:\\n    \"\"\"Press a key.\"\"\"\\n    await page.keyboard.press(key)\\n\\n',\n",
       "  'function_name': 'aexecute_key_press',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_mouse_hover(left: float, top: float, page: Page) -> None:\\n    \"\"\"Click at coordinates (left, top).\"\"\"\\n    viewport_size = page.viewport_size\\n    assert viewport_size\\n    page.mouse.move(\\n        left * viewport_size[\"width\"], top * viewport_size[\"height\"]\\n    )\\n\\n',\n",
       "  'function_name': 'execute_mouse_hover',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_mouse_hover(left: float, top: float, page: APage) -> None:\\n    \"\"\"Click at coordinates (left, top).\"\"\"\\n    viewport_size = page.viewport_size\\n    assert viewport_size\\n    await page.mouse.move(\\n        left * viewport_size[\"width\"], top * viewport_size[\"height\"]\\n    )\\n\\n',\n",
       "  'function_name': 'aexecute_mouse_hover',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_mouse_click(left: float, top: float, page: Page) -> None:\\n    \"\"\"Click at coordinates (left, top).\"\"\"\\n    viewport_size = page.viewport_size\\n    assert viewport_size\\n    page.mouse.click(\\n        left * viewport_size[\"width\"], top * viewport_size[\"height\"]\\n    )\\n\\n',\n",
       "  'function_name': 'execute_mouse_click',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_mouse_click(left: float, top: float, page: APage) -> None:\\n    \"\"\"Click at coordinates (left, top).\"\"\"\\n    viewport_size = page.viewport_size\\n    assert viewport_size\\n    await page.mouse.click(\\n        left * viewport_size[\"width\"], top * viewport_size[\"height\"]\\n    )\\n\\n',\n",
       "  'function_name': 'aexecute_mouse_click',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_keyboard_type(text: str, page: Page) -> None:\\n    \"\"\"Fill the focused element with text.\"\"\"\\n    page.keyboard.type(text)\\n\\n',\n",
       "  'function_name': 'execute_keyboard_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_keyboard_type(text: str, page: APage) -> None:\\n    \"\"\"Fill the focused element with text.\"\"\"\\n    await page.keyboard.type(text)\\n\\n',\n",
       "  'function_name': 'aexecute_keyboard_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_click_current(page: Page) -> None:\\n    \"\"\"Click at the current mouse position.\"\"\"\\n    locators = page.locator(\"*:focus\")\\n    if not locators.count():\\n        for frame in page.frames[1:]:\\n            locators = frame.locator(\"*:focus\")\\n            if locators.count():\\n                break\\n    locators.click()\\n\\n',\n",
       "  'function_name': 'execute_click_current',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_click_current(page: APage) -> None:\\n    \"\"\"Click at the current mouse position.\"\"\"\\n    locators = page.locator(\"*:focus\")\\n    locator_count = await locators.count()\\n    if not locator_count:\\n        for frame in page.frames[1:]:\\n            locators = frame.locator(\"*:focus\")\\n            locator_count = await locators.count()\\n            if locator_count:\\n                break\\n    await locators.click()\\n    await page.wait_for_load_state(\"load\")\\n\\n',\n",
       "  'function_name': 'aexecute_click_current',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_type(keys: list[int], page: Page) -> None:\\n    \"\"\"Send keystrokes to the focused element.\"\"\"\\n    text = \"\".join([_id2key[key] for key in keys])\\n    page.keyboard.type(text)\\n\\n',\n",
       "  'function_name': 'execute_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_type(keys: list[int], page: APage) -> None:\\n    \"\"\"Send keystrokes to the focused element.\"\"\"\\n    text = \"\".join([_id2key[key] for key in keys])\\n    await page.keyboard.type(text)\\n\\n',\n",
       "  'function_name': 'aexecute_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_focus(\\n    element_role: int, element_name: str, nth: int, page: Page\\n) -> None:\\n    \"\"\"Click the specified DOM element.\"\"\"\\n    element_role_str = _id2role[element_role]\\n    if page.viewport_size is None:\\n        raise ValueError(\"Viewport size is not set for the current page\")\\n    element_location_list: list[tuple[Locator, float, float]] = []\\n    for frame in page.frames:\\n        match element_role_str:\\n            case \"alt_text\":\\n                locators = frame.get_by_alt_text(element_name)\\n            case \"label\":\\n                locators = frame.get_by_label(element_name)\\n            case \"placeholder\":\\n                locators = frame.get_by_placeholder(element_name)\\n            case _:\\n                locators = frame.get_by_role(\\n                    role=element_role_str, name=element_name\\n                )\\n        for locator_idx in range(locators.count()):\\n            locator = locators.nth(locator_idx)\\n            if is_in_viewport(locator, page.viewport_size):\\n                bounding_box = locator.bounding_box()\\n                assert bounding_box\\n                element_location_list.append(\\n                    (locator, bounding_box[\"x\"], bounding_box[\"y\"])\\n                )\\n    if len(element_location_list) <= nth:\\n        raise ValueError(\\n            f\"There are only {len(element_location_list)} elements found in viewport, but {nth + 1} is requested\"\\n        )\\n    element_location_list.sort(key=lambda x: (x[2], x[1]))  # row major order\\n    element_location_list[nth][0].focus()\\n\\n',\n",
       "  'function_name': 'execute_focus',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_focus(\\n    element_role: int, element_name: str, nth: int, page: APage\\n) -> None:\\n    \"\"\"Click the specified DOM element.\"\"\"\\n    element_role_str = _id2role[element_role]\\n    if page.viewport_size is None:\\n        raise ValueError(\"Viewport size is not set for the current page\")\\n    element_location_list: list[tuple[ALocator, float, float]] = []\\n    for frame in page.frames:\\n        match element_role_str:\\n            case \"alt_text\":\\n                locators = frame.get_by_alt_text(element_name)\\n            case \"label\":\\n                locators = frame.get_by_label(element_name)\\n            case \"placeholder\":\\n                locators = frame.get_by_placeholder(element_name)\\n            case _:\\n                locators = frame.get_by_role(\\n                    role=element_role_str, name=element_name\\n                )\\n        for locator_idx in range(await locators.count()):\\n            locator = locators.nth(locator_idx)\\n            if await async_is_in_viewport(locator, page.viewport_size):\\n                bounding_box = await locator.bounding_box()\\n                assert bounding_box\\n                element_location_list.append(\\n                    (locator, bounding_box[\"x\"], bounding_box[\"y\"])\\n                )\\n    if len(element_location_list) <= nth:\\n        raise ValueError(\\n            f\"There are only {len(element_location_list)} elements found in viewport, but {nth + 1} is requested\"\\n        )\\n    element_location_list.sort(key=lambda x: (x[2], x[1]))  # row major order\\n    await element_location_list[nth][0].focus()\\n\\n',\n",
       "  'function_name': 'aexecute_focus',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def locate(locator_calls: list[ParsedPlaywrightCode], page: Page) -> Locator:\\n    locator = page\\n    for call in locator_calls:\\n        function_name = call[\"function_name\"]\\n        arguments = call[\"arguments\"]\\n        keywords = call[\"keywords\"]\\n        locator = getattr(locator, function_name)(*arguments, **keywords)\\n    return locator  # type: ignore[return-value]\\n\\n',\n",
       "  'function_name': 'locate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def alocate(\\n    locator_calls: list[ParsedPlaywrightCode], page: APage\\n) -> ALocator:\\n    locator = page\\n    for call in locator_calls:\\n        function_name = call[\"function_name\"]\\n        arguments = call[\"arguments\"]\\n        keywords = call[\"keywords\"]\\n        locator = await getattr(locator, function_name)(*arguments, **keywords)\\n    return locator  # type: ignore[return-value]\\n\\n',\n",
       "  'function_name': 'alocate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_playwright_click(\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: Page,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = locate(locator_code, page)\\n\\n    # perform the action\\n    locator.click(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'execute_playwright_click',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_playwright_click(\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: APage,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = await alocate(locator_code, page)\\n\\n    # perform the action\\n    await locator.click(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'aexecute_playwright_click',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_playwright_hover(\\n    locator_code: list[ParsedPlaywrightCode], page: Page\\n) -> None:\\n    locator = locate(locator_code, page)\\n\\n    # perform the action\\n    locator.hover()\\n\\n',\n",
       "  'function_name': 'execute_playwright_hover',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_playwright_hover(\\n    locator_code: list[ParsedPlaywrightCode], page: APage\\n) -> None:\\n    locator = await alocate(locator_code, page)\\n\\n    # perform the action\\n    await locator.hover()\\n\\n',\n",
       "  'function_name': 'aexecute_playwright_hover',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_playwright_type(\\n    text: str,\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: Page,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = locate(locator_code, page)\\n    # perform the action\\n    pw_action_args = [text] + pw_action_args  # text is the first argument\\n    locator.type(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'execute_playwright_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_playwright_type(\\n    text: str,\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: APage,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = await alocate(locator_code, page)\\n    # perform the action\\n    pw_action_args = [text] + pw_action_args  # text is the first argument\\n    await locator.type(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'aexecute_playwright_type',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_playwright_select_option(\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: Page,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = locate(locator_code, page)\\n    # perform the action\\n    locator.select_option(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'execute_playwright_select_option',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_playwright_select_option(\\n    locator_code: list[ParsedPlaywrightCode],\\n    page: APage,\\n    pw_action_args: list[str] = [],\\n    pw_action_kwargs: dict[str, Any] = {},\\n) -> None:\\n    locator = await alocate(locator_code, page)\\n    # perform the action\\n    await locator.select_option(*pw_action_args, **pw_action_kwargs)\\n\\n',\n",
       "  'function_name': 'aexecute_playwright_select_option',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_playwright_check(\\n    locator_code: list[ParsedPlaywrightCode], page: Page\\n) -> None:\\n    locator = locate(locator_code, page)\\n    # perform the action\\n    locator.check()\\n\\n',\n",
       "  'function_name': 'execute_playwright_check',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_playwright_check(\\n    locator_code: list[ParsedPlaywrightCode], page: APage\\n) -> None:\\n    locator = await alocate(locator_code, page)\\n    # perform the action\\n    await locator.check()\\n\\n',\n",
       "  'function_name': 'aexecute_playwright_check',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def execute_action(\\n    action: Action,\\n    page: Page,\\n    browser_ctx: BrowserContext,\\n    obseration_processor: ObservationProcessor,\\n) -> Page:\\n    \"\"\"Execute the action on the ChromeDriver.\"\"\"\\n    action_type = action[\"action_type\"]\\n    match action_type:\\n        case ActionTypes.NONE:\\n            pass\\n\\n        case ActionTypes.SCROLL:\\n            direction = \"up\" if \"up\" in action[\"direction\"] else \"down\"\\n            execute_scroll(direction, page)\\n        case ActionTypes.KEY_PRESS:\\n            keys = action[\"key_comb\"]\\n            execute_key_press(keys, page)\\n\\n        case ActionTypes.MOUSE_CLICK:\\n            execute_mouse_click(action[\"coords\"][0], action[\"coords\"][1], page)\\n        case ActionTypes.MOUSE_HOVER:\\n            execute_mouse_hover(action[\"coords\"][0], action[\"coords\"][1], page)\\n        case ActionTypes.KEYBOARD_TYPE:\\n            execute_type(action[\"text\"], page)\\n\\n        case ActionTypes.CLICK:\\n            # check each kind of locator in order\\n            # TODO[shuyanzh]: order is temp now\\n            if action[\"element_id\"]:\\n                element_id = action[\"element_id\"]\\n                element_center = obseration_processor.get_element_center(element_id)  # type: ignore[attr-defined]\\n                execute_mouse_click(element_center[0], element_center[1], page)\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                execute_focus(element_role, element_name, nth, page)\\n                execute_click_current(page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                execute_playwright_click(locator_code=locator_code, page=page)\\n            else:\\n                raise ValueError(\"No proper locator found for click action\")\\n        case ActionTypes.HOVER:\\n            if action[\"element_id\"]:\\n                element_id = action[\"element_id\"]\\n                element_center = obseration_processor.get_element_center(element_id)  # type: ignore[attr-defined]\\n                execute_mouse_hover(element_center[0], element_center[1], page)\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                execute_focus(element_role, element_name, nth, page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                execute_playwright_hover(locator_code=locator_code, page=page)\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for hover action\"\\n                )\\n        case ActionTypes.TYPE:\\n            if action[\"element_id\"]:\\n                element_id = action[\"element_id\"]\\n                element_center = obseration_processor.get_element_center(element_id)  # type: ignore[attr-defined]\\n                execute_mouse_click(element_center[0], element_center[1], page)\\n                execute_type(action[\"text\"], page)\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                execute_focus(element_role, element_name, nth, page)\\n                execute_type(action[\"text\"], page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                text = parsed_code[-1][\"arguments\"][0]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                execute_playwright_type(\\n                    text=text, locator_code=locator_code, page=page\\n                )\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for type action\"\\n                )\\n\\n        case ActionTypes.PAGE_FOCUS:\\n            page = browser_ctx.pages[action[\"page_number\"]]\\n            page.bring_to_front()\\n        case ActionTypes.NEW_TAB:\\n            page = browser_ctx.new_page()\\n            page.client = page.context.new_cdp_session(page)  # type: ignore[attr-defined]\\n        case ActionTypes.GO_BACK:\\n            page.go_back()\\n        case ActionTypes.GO_FORWARD:\\n            page.go_forward()\\n        case ActionTypes.GOTO_URL:\\n            page.goto(action[\"url\"])\\n        case ActionTypes.PAGE_CLOSE:\\n            page.close()\\n            if len(browser_ctx.pages) > 0:\\n                page = browser_ctx.pages[-1]\\n            else:\\n                page = browser_ctx.new_page()\\n                page.client = page.context.new_cdp_session(page)\\n\\n        case ActionTypes.SELECT_OPTION:\\n            if action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                execute_playwright_select_option(locator_code, page)\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for select option action\"\\n                )\\n        case ActionTypes.CHECK:\\n            if action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                execute_playwright_check(locator_code, page)\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for select option action\"\\n                )\\n\\n        case _:\\n            raise ValueError(f\"Unknown action type: {action_type}\")\\n\\n    return page\\n\\n',\n",
       "  'function_name': 'execute_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'async def aexecute_action(\\n    action: Action, page: APage, browser_ctx: ABrowserContext\\n) -> APage:\\n    \"\"\"Execute the async action on the ChromeDriver.\"\"\"\\n    raise NotImplementedError(\"Not implemented yet\")\\n    action_type = action[\"action_type\"]\\n    match action_type:\\n        case ActionTypes.NONE:\\n            pass\\n        case ActionTypes.SCROLL:\\n            direction = \"up\" if \"up\" in action[\"direction\"] else \"down\"\\n            await aexecute_scroll(direction, page)\\n        case ActionTypes.KEY_PRESS:\\n            keys = action[\"key_comb\"]\\n            await aexecute_key_press(keys, page)\\n\\n        case ActionTypes.MOUSE_CLICK:\\n            await aexecute_mouse_click(\\n                action[\"coords\"][0], action[\"coords\"][1], page\\n            )\\n        case ActionTypes.MOUSE_HOVER:\\n            await aexecute_mouse_hover(\\n                action[\"coords\"][0], action[\"coords\"][1], page\\n            )\\n        case ActionTypes.KEYBOARD_TYPE:\\n            await aexecute_type(action[\"text\"], page)\\n\\n        case ActionTypes.CLICK:\\n            # check each kind of locator in order\\n            # TODO[shuyanzh]: order is temp now\\n            if action[\"element_id\"]:\\n                raise NotImplementedError\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                await aexecute_focus(element_role, element_name, nth, page)\\n                await aexecute_click_current(page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                await aexecute_playwright_click(\\n                    locator_code=locator_code, page=page\\n                )\\n            else:\\n                raise ValueError(\"No proper locator found for click action\")\\n        case ActionTypes.HOVER:\\n            if action[\"element_id\"]:\\n                raise NotImplementedError\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                await aexecute_focus(element_role, element_name, nth, page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                await aexecute_playwright_hover(\\n                    locator_code=locator_code, page=page\\n                )\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for hover action\"\\n                )\\n        case ActionTypes.TYPE:\\n            if action[\"element_id\"]:\\n                raise NotImplementedError\\n            elif action[\"element_role\"] and action[\"element_name\"]:\\n                element_role = int(action[\"element_role\"])\\n                element_name = action[\"element_name\"]\\n                nth = action[\"nth\"]\\n                await aexecute_focus(element_role, element_name, nth, page)\\n                await aexecute_type(action[\"text\"], page)\\n            elif action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                text = parsed_code[-1][\"arguments\"][0]\\n                # [shuyanzh], don\\'t support action args and kwargs now\\n                await aexecute_playwright_type(\\n                    text=text, locator_code=locator_code, page=page\\n                )\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for type action\"\\n                )\\n\\n        case ActionTypes.PAGE_FOCUS:\\n            page = browser_ctx.pages[action[\"page_number\"]]\\n            await page.bring_to_front()\\n        case ActionTypes.NEW_TAB:\\n            page = await browser_ctx.new_page()\\n        case ActionTypes.GO_BACK:\\n            await page.go_back()\\n        case ActionTypes.GO_FORWARD:\\n            await page.go_forward()\\n        case ActionTypes.GOTO_URL:\\n            await page.goto(action[\"url\"])\\n        case ActionTypes.PAGE_CLOSE:\\n            await page.close()\\n            if len(browser_ctx.pages) > 0:\\n                page = browser_ctx.pages[-1]\\n            else:\\n                page = await browser_ctx.new_page()\\n\\n        case ActionTypes.SELECT_OPTION:\\n            if action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                await aexecute_playwright_select_option(locator_code, page)\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for select option action\"\\n                )\\n        case ActionTypes.CHECK:\\n            if action[\"pw_code\"]:\\n                parsed_code = parse_playwright_code(action[\"pw_code\"])\\n                locator_code = parsed_code[:-1]\\n                await aexecute_playwright_check(locator_code, page)\\n            else:\\n                raise NotImplementedError(\\n                    \"No proper locator found for select option action\"\\n                )\\n\\n        case _:\\n            raise ValueError(f\"Unknown action type: {action_type}\")\\n\\n    return page\\n\\n',\n",
       "  'function_name': 'aexecute_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def parse_playwright_code(code: str) -> list[ParsedPlaywrightCode]:\\n    # extract function calls\\n    if not code.startswith(\"page.\"):\\n        raise ValueError(\\n            f\\'Playwright action must start with \"page.\", but got {code}\\'\\n        )\\n\\n    regex = r\"\\\\.(?![^\\\\(\\\\)]*\\\\))\"\\n    chain = re.split(regex, code)[1:]\\n\\n    parsed_chain = []\\n\\n    for item in chain:\\n        tree = ast.parse(item)\\n        funcs = []\\n        for node in ast.walk(tree):\\n            if isinstance(node, ast.Call):\\n                function_name = node.func.id  # type: ignore[attr-defined]\\n                arguments = [\\n                    ast.literal_eval(arg) if isinstance(arg, ast.Str) else arg\\n                    for arg in node.args\\n                ]\\n                keywords = {\\n                    str(kw.arg): ast.literal_eval(kw.value)\\n                    for kw in node.keywords\\n                }\\n                funcs.append(\\n                    ParsedPlaywrightCode(\\n                        {\\n                            \"function_name\": function_name,\\n                            \"arguments\": arguments,\\n                            \"keywords\": keywords,\\n                        }\\n                    )\\n                )\\n\\n        if len(funcs) != 1:\\n            raise ValueError(f\"Fail to parse {item} in {code}\")\\n\\n        if (\\n            funcs[0][\"function_name\"]\\n            not in PLAYWRIGHT_LOCATORS + PLAYWRIGHT_ACTIONS\\n        ):\\n            raise ValueError(\\n                f\"Invalid playwright code {item}, \",\\n                f\"the function needs to be one of {PLAYWRIGHT_LOCATORS + PLAYWRIGHT_ACTIONS}\",\\n            )\\n\\n        parsed_chain.append(funcs[0])\\n\\n    last_action = parsed_chain[-1]\\n    if last_action[\"function_name\"] not in PLAYWRIGHT_ACTIONS:\\n        raise ValueError(\\n            f\"Invalid playwright action {last_action},\",\\n            f\"the action needs to be one of {PLAYWRIGHT_ACTIONS}\",\\n        )\\n\\n    return parsed_chain\\n\\n',\n",
       "  'function_name': 'parse_playwright_code',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_playwright_action(playwright_code: str) -> Action:\\n    \"\"\"Main function to return individual playwright action\"\"\"\\n    # get the last action\\n    regex = r\"\\\\.(?![^\\\\(\\\\)]*\\\\))\"\\n    action = re.split(regex, playwright_code)[-1].split(\"(\")[0]\\n    match action:\\n        case \"press\":\\n            p = r\\'press\\\\((?:\"|\\\\\\')(.+?)(?:\"|\\\\\\')\\\\)\\'\\n            match = re.search(p, playwright_code)\\n            if not match:\\n                raise ActionParsingError(\\n                    f\"Invalid press action, required to be page.press(KEY_COMB_STR)\"\\n                )\\n            key_comb = match.group(1)\\n            return create_key_press_action(key_comb=key_comb)\\n        case \"scroll\":\\n            direction = \"up\" if \"up\" in playwright_code else \"down\"\\n            return create_scroll_action(direction=direction)\\n        case \"click\":\\n            return create_click_action(pw_code=playwright_code)\\n        case \"hover\":\\n            return create_hover_action(pw_code=playwright_code)\\n        case \"type\" | \"fill\":\\n            p = r\\'type|fill\\\\((?:\"|\\\\\\')(.+?)(?:\"|\\\\\\')\\\\)\\'\\n            match = re.search(p, playwright_code)\\n            if not match:\\n                raise ActionParsingError(\\n                    f\"Invalid type/fill action, required to be page.type(TEXT)\"\\n                )\\n            text = match.group(1)\\n            return create_type_action(text=text, pw_code=playwright_code)\\n        case \"select_option\":\\n            return create_select_option_action(pw_code=playwright_code)\\n        case \"check\":\\n            return create_check_action(pw_code=playwright_code)\\n        case \"goto\":\\n            p = r\\'goto\\\\((?:\"|\\\\\\')(.+?)(?:\"|\\\\\\')\\\\)\\'\\n            match = re.search(p, playwright_code)\\n            if not match:\\n                raise ActionParsingError(\\n                    f\"Invalid goto action, required to be page.goto(URL_STR)\"\\n                )\\n            url = match.group(1)\\n            return create_goto_url_action(url)\\n        case \"page_focus\":\\n            # get the page number\\n            p = r\"page_focus\\\\((\\\\d+)\\\\)\"\\n            match = re.search(p, playwright_code)\\n            if not match:\\n                raise ActionParsingError(\"page focus requires a page number\")\\n            page_num = int(match.group(1))\\n            return create_page_focus_action(page_num)\\n        case \"new_tab\":\\n            return create_new_tab_action()\\n        case \"go_back\":\\n            return create_go_back_action()\\n        case \"go_forward\":\\n            return create_go_forward_action()\\n        case \"page_close\":\\n            return create_page_close_action()\\n        case \"stop\":  # page.stop(answer)\\n            p = r\\'stop\\\\(?\"(.+)?\"\\\\)\\'\\n            match = re.search(p, playwright_code)\\n            if not match:\\n                answer = \"\"\\n            else:\\n                answer = match.group(1)\\n            return create_stop_action(answer)\\n\\n    raise ActionParsingError(f\"Unknown playwright action {action}\")\\n\\n',\n",
       "  'function_name': 'create_playwright_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def create_id_based_action(action_str: str) -> Action:\\n    \"\"\"Main function to return individual id based action\"\"\"\\n    action_str = action_str.strip()\\n    action = (\\n        action_str.split(\"[\")[0].strip()\\n        if \"[\" in action_str\\n        else action_str.split()[0].strip()\\n    )\\n    match action:\\n        case \"click\":\\n            match = re.search(r\"click ?\\\\[(\\\\d+)\\\\]\", action_str)\\n            if not match:\\n                raise ActionParsingError(f\"Invalid click action {action_str}\")\\n            element_id = match.group(1)\\n            return create_click_action(element_id=element_id)\\n        case \"hover\":\\n            match = re.search(r\"hover ?\\\\[(\\\\d+)\\\\]\", action_str)\\n            if not match:\\n                raise ActionParsingError(f\"Invalid hover action {action_str}\")\\n            element_id = match.group(1)\\n            return create_hover_action(element_id=element_id)\\n        case \"type\":\\n            # add default enter flag\\n            if not (action_str.endswith(\"[0]\") or action_str.endswith(\"[1]\")):\\n                action_str += \" [1]\"\\n\\n            match = re.search(\\n                r\"type ?\\\\[(\\\\d+)\\\\] ?\\\\[(.+)\\\\] ?\\\\[(\\\\d+)\\\\]\", action_str\\n            )\\n            if not match:\\n                raise ActionParsingError(f\"Invalid type action {action_str}\")\\n            element_id, text, enter_flag = (\\n                match.group(1),\\n                match.group(2),\\n                match.group(3),\\n            )\\n            if enter_flag == \"1\":\\n                text += \"\\\\n\"\\n            return create_type_action(text=text, element_id=element_id)\\n        case \"press\":\\n            match = re.search(r\"press ?\\\\[(.+)\\\\]\", action_str)\\n            if not match:\\n                raise ActionParsingError(f\"Invalid press action {action_str}\")\\n            key_comb = match.group(1)\\n            return create_key_press_action(key_comb=key_comb)\\n        case \"scroll\":\\n            # up or down\\n            match = re.search(r\"scroll ?\\\\[?(up|down)\\\\]?\", action_str)\\n            if not match:\\n                raise ActionParsingError(f\"Invalid scroll action {action_str}\")\\n            direction = match.group(1)\\n            return create_scroll_action(direction=direction)\\n        case \"goto\":\\n            match = re.search(r\"goto ?\\\\[(.+)\\\\]\", action_str)\\n            if not match:\\n                raise ActionParsingError(f\"Invalid goto action {action_str}\")\\n            url = match.group(1)\\n            return create_goto_url_action(url=url)\\n        case \"new_tab\":\\n            return create_new_tab_action()\\n        case \"go_back\":\\n            return create_go_back_action()\\n        case \"go_forward\":\\n            return create_go_forward_action()\\n        case \"tab_focus\":\\n            match = re.search(r\"tab_focus ?\\\\[(\\\\d+)\\\\]\", action_str)\\n            if not match:\\n                raise ActionParsingError(\\n                    f\"Invalid tab_focus action {action_str}\"\\n                )\\n            page_number = int(match.group(1))\\n            return create_page_focus_action(page_number)\\n        case \"close_tab\":\\n            return create_page_close_action()\\n        case \"stop\":  # stop answer\\n            match = re.search(r\"stop ?\\\\[(.+)\\\\]\", action_str)\\n            if not match:  # some tasks don\\'t require an answer\\n                answer = \"\"\\n            else:\\n                answer = match.group(1)\\n            return create_stop_action(answer)\\n\\n    raise ActionParsingError(f\"Invalid action {action_str}\")\\n',\n",
       "  'function_name': 'create_id_based_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/browser_env/actions.py'},\n",
       " {'code': 'def retry_with_exponential_backoff(  # type: ignore\\n    func,\\n    initial_delay: float = 1,\\n    exponential_base: float = 2,\\n    jitter: bool = True,\\n    max_retries: int = 10,\\n    errors: tuple[Any] = (openai.error.RateLimitError,),\\n):\\n    \"\"\"Retry a function with exponential backoff.\"\"\"\\n\\n    def wrapper(*args, **kwargs):  # type: ignore\\n        # Initialize variables\\n        num_retries = 0\\n        delay = initial_delay\\n\\n        # Loop until a successful response or max_retries is hit or an exception is raised\\n        while True:\\n            try:\\n\\n                return func(*args, **kwargs)\\n\\n            # Retry on specified errors\\n            except errors as e:\\n                # Increment retries\\n                num_retries += 1\\n\\n                # Check if max retries has been reached\\n                if num_retries > max_retries:\\n                    raise Exception(\\n                        f\"Maximum number of retries ({max_retries}) exceeded.\"\\n                    )\\n\\n                # Increment the delay\\n                delay *= exponential_base * (1 + jitter * random.random())\\n\\n                # Sleep for the delay\\n                time.sleep(delay)\\n\\n            # Raise exceptions for any errors not specified\\n            except Exception as e:\\n                raise e\\n\\n    return wrapper\\n\\n',\n",
       "  'function_name': 'retry_with_exponential_backoff',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'async def _throttled_openai_completion_acreate(\\n    engine: str,\\n    prompt: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    limiter: aiolimiter.AsyncLimiter,\\n) -> dict[str, Any]:\\n    async with limiter:\\n        for _ in range(3):\\n            try:\\n                return await openai.Completion.acreate(  # type: ignore\\n                    engine=engine,\\n                    prompt=prompt,\\n                    temperature=temperature,\\n                    max_tokens=max_tokens,\\n                    top_p=top_p,\\n                )\\n            except openai.error.RateLimitError:\\n                logging.warning(\\n                    \"OpenAI API rate limit exceeded. Sleeping for 10 seconds.\"\\n                )\\n                await asyncio.sleep(10)\\n            except openai.error.APIError as e:\\n                logging.warning(f\"OpenAI API error: {e}\")\\n                break\\n        return {\"choices\": [{\"message\": {\"content\": \"\"}}]}\\n\\n',\n",
       "  'function_name': '_throttled_openai_completion_acreate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'async def agenerate_from_openai_completion(\\n    prompts: list[str],\\n    engine: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    context_length: int,\\n    requests_per_minute: int = 300,\\n) -> list[str]:\\n    \"\"\"Generate from OpenAI Completion API.\\n\\n    Args:\\n        prompts: list of prompts\\n        temperature: Temperature to use.\\n        max_tokens: Maximum number of tokens to generate.\\n        top_p: Top p to use.\\n        context_length: Length of context to use.\\n        requests_per_minute: Number of requests per minute to allow.\\n\\n    Returns:\\n        List of generated responses.\\n    \"\"\"\\n    if \"OPENAI_API_KEY\" not in os.environ:\\n        raise ValueError(\\n            \"OPENAI_API_KEY environment variable must be set when using OpenAI API.\"\\n        )\\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n    if os.environ.get(\\'OPENAI_API_BASE\\'): openai.api_base = os.environ.get(\\'OPENAI_API_BASE\\')\\n\\n    limiter = aiolimiter.AsyncLimiter(requests_per_minute)\\n    async_responses = [\\n        _throttled_openai_completion_acreate(\\n            engine=engine,\\n            prompt=prompt,\\n            temperature=temperature,\\n            max_tokens=max_tokens,\\n            top_p=top_p,\\n            limiter=limiter,\\n        )\\n        for prompt in prompts\\n    ]\\n    responses = await tqdm_asyncio.gather(*async_responses)\\n    return [x[\"choices\"][0][\"text\"] for x in responses]\\n\\n',\n",
       "  'function_name': 'agenerate_from_openai_completion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'def generate_from_openai_completion(\\n    prompt: str,\\n    engine: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    context_length: int,\\n    stop_token: str | None = None,\\n) -> str:\\n    if \"OPENAI_API_KEY\" not in os.environ:\\n        raise ValueError(\\n            \"OPENAI_API_KEY environment variable must be set when using OpenAI API.\"\\n        )\\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n    if os.environ.get(\\'OPENAI_API_BASE\\'): openai.api_base = os.environ.get(\\'OPENAI_API_BASE\\')\\n    response = openai.Completion.create(  # type: ignore\\n        prompt=prompt,\\n        engine=engine,\\n        temperature=temperature,\\n        max_tokens=max_tokens,\\n        top_p=top_p,\\n        stop=[stop_token],\\n    )\\n    answer: str = response[\"choices\"][0][\"text\"]\\n    return answer\\n\\n',\n",
       "  'function_name': 'generate_from_openai_completion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'async def _throttled_openai_chat_completion_acreate(\\n    model: str,\\n    messages: list[dict[str, str]],\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    limiter: aiolimiter.AsyncLimiter,\\n) -> dict[str, Any]:\\n    async with limiter:\\n        for _ in range(3):\\n            try:\\n                return await openai.ChatCompletion.acreate(  # type: ignore\\n                    model=model,\\n                    messages=messages,\\n                    temperature=temperature,\\n                    max_tokens=max_tokens,\\n                    top_p=top_p,\\n                )\\n            except openai.error.RateLimitError:\\n                logging.warning(\\n                    \"OpenAI API rate limit exceeded. Sleeping for 10 seconds.\"\\n                )\\n                await asyncio.sleep(10)\\n            except asyncio.exceptions.TimeoutError:\\n                logging.warning(\"OpenAI API timeout. Sleeping for 10 seconds.\")\\n                await asyncio.sleep(10)\\n            except openai.error.APIError as e:\\n                logging.warning(f\"OpenAI API error: {e}\")\\n                break\\n        return {\"choices\": [{\"message\": {\"content\": \"\"}}]}\\n\\n',\n",
       "  'function_name': '_throttled_openai_chat_completion_acreate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'async def agenerate_from_openai_chat_completion(\\n    messages_list: list[list[dict[str, str]]],\\n    engine: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    context_length: int,\\n    requests_per_minute: int = 300,\\n) -> list[str]:\\n    \"\"\"Generate from OpenAI Chat Completion API.\\n\\n    Args:\\n        messages_list: list of message list\\n        temperature: Temperature to use.\\n        max_tokens: Maximum number of tokens to generate.\\n        top_p: Top p to use.\\n        context_length: Length of context to use.\\n        requests_per_minute: Number of requests per minute to allow.\\n\\n    Returns:\\n        List of generated responses.\\n    \"\"\"\\n    if \"OPENAI_API_KEY\" not in os.environ:\\n        raise ValueError(\\n            \"OPENAI_API_KEY environment variable must be set when using OpenAI API.\"\\n        )\\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n    if os.environ.get(\\'OPENAI_API_BASE\\'): openai.api_base = os.environ.get(\\'OPENAI_API_BASE\\')\\n\\n    limiter = aiolimiter.AsyncLimiter(requests_per_minute)\\n    async_responses = [\\n        _throttled_openai_chat_completion_acreate(\\n            model=engine,\\n            messages=message,\\n            temperature=temperature,\\n            max_tokens=max_tokens,\\n            top_p=top_p,\\n            limiter=limiter,\\n        )\\n        for message in messages_list\\n    ]\\n    responses = await tqdm_asyncio.gather(*async_responses)\\n    return [x[\"choices\"][0][\"message\"][\"content\"] for x in responses]\\n\\n',\n",
       "  'function_name': 'agenerate_from_openai_chat_completion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'def generate_from_openai_chat_completion(\\n    messages: list[dict[str, str]],\\n    model: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    context_length: int,\\n    stop_token: str | None = None,\\n) -> str:\\n    if \"OPENAI_API_KEY\" not in os.environ:\\n        raise ValueError(\\n            \"OPENAI_API_KEY environment variable must be set when using OpenAI API.\"\\n        )\\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n    if os.environ.get(\\'OPENAI_API_BASE\\'): openai.api_base = os.environ.get(\\'OPENAI_API_BASE\\')\\n\\n    response = openai.ChatCompletion.create(  # type: ignore\\n        model=model,\\n        messages=messages,\\n        temperature=temperature,\\n        max_tokens=max_tokens,\\n        top_p=top_p,\\n        stop=[stop_token] if stop_token else None,\\n    )\\n    answer: str = response[\"choices\"][0][\"message\"][\"content\"]\\n    return answer\\n\\n',\n",
       "  'function_name': 'generate_from_openai_chat_completion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'def fake_generate_from_openai_chat_completion(\\n    messages: list[dict[str, str]],\\n    model: str,\\n    temperature: float,\\n    max_tokens: int,\\n    top_p: float,\\n    context_length: int,\\n    stop_token: str | None = None,\\n) -> str:\\n    if \"OPENAI_API_KEY\" not in os.environ:\\n        raise ValueError(\\n            \"OPENAI_API_KEY environment variable must be set when using OpenAI API.\"\\n        )\\n    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\\n    if os.environ.get(\\'OPENAI_API_BASE\\'): openai.api_base = os.environ.get(\\'OPENAI_API_BASE\\')\\n    answer = \"Let\\'s think step-by-step. This page shows a list of links and buttons. There is a search box with the label \\'Search query\\'. I will click on the search box to type the query. So the action I will perform is \\\\\"click [60]\\\\\".\"\\n    return answer\\n',\n",
       "  'function_name': 'fake_generate_from_openai_chat_completion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/webarena/llms/providers/openai_utils.py'},\n",
       " {'code': 'def parse_opt():\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--env\", type=str, default=\"click-button\")\\n    parser.add_argument(\"--num-episodes\", type=int, default=10)\\n    parser.add_argument(\"--llm\", type=str, default=\"chatgpt\")\\n    parser.add_argument(\"--erci\", type=int, default=0)\\n    parser.add_argument(\"--step\", type=int, default=-1)\\n    parser.add_argument(\"--irci\", type=int, default=1)\\n    parser.add_argument(\"--sgrounding\", action=\"store_true\", default=False)\\n    parser.add_argument(\"--headless\", action=\"store_true\", default=True)\\n\\n    opt = parser.parse_args()\\n\\n    return opt\\n\\n',\n",
       "  'function_name': 'parse_opt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def web(opt, url):\\n    driver = get_webdriver(url)\\n\\n    while True:\\n        llm_agent = LLMAgent(\\n            opt.env, rci_plan_loop=opt.erci, rci_limit=opt.irci, llm=opt.llm\\n        )\\n\\n        html_body = get_html_state_from_real(driver, opt)\\n\\n        llm_agent.update_html_state(html_body)\\n\\n        # Set objective (e.g., login with id and pw)\\n        goal = input(\"Type your command (type \\'exit\\' to quit): \")\\n        if goal == \"exit\":\\n            break\\n        llm_agent.set_goal(goal)\\n\\n        llm_agent.initialize_plan()\\n\\n        step = llm_agent.get_plan_step()\\n        logging.info(f\"The number of generated action steps: {step}\")\\n        for _ in range(step):\\n            instruction = llm_agent.generate_action()\\n            print(instruction)\\n\\n            perform_instruction(driver, instruction)\\n\\n            html_body = get_html_state_from_real(driver, opt)\\n            llm_agent.update_html_state(html_body)\\n\\n    driver.quit()\\n\\n',\n",
       "  'function_name': 'web',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def get_html_state_from_real(driver, opt):\\n    if opt.env == \"facebook\":\\n        main_html_xpath = \\'//*[@id=\"content\"]\\'\\n        html_body = driver.find_element(By.XPATH, main_html_xpath).get_attribute(\\n            \"outerHTML\"\\n        )\\n    else:\\n        raise NotImplemented\\n\\n    return html_body\\n\\n',\n",
       "  'function_name': 'get_html_state_from_real',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def perform_instruction(driver, instruction):\\n    instruction = instruction.split(\" \")\\n    inst_type = instruction[0]\\n    inst_type = inst_type.lower()\\n\\n    if inst_type == \"type\":\\n        characters = \" \".join(instruction[1:])\\n        characters = characters.replace(\\'\"\\', \"\")\\n        chain = ActionChains(driver)\\n        chain.send_keys(characters)\\n        chain.perform()\\n    elif inst_type == \"clickxpath\":\\n        xpath = \" \".join(instruction[1:])\\n        element = driver.find_element(By.XPATH, str(xpath))\\n        chain = ActionChains(driver)\\n        chain.move_to_element(element).click().perform()\\n    elif inst_type == \"press\":\\n        key_type = instruction[1]\\n        # TODO: press special key\\n        if key_type == \"enter\":\\n            chain = ActionChains(driver)\\n            chain.send_keys(\"\\\\n\")\\n            chain.perform()\\n        elif key_type == \"space\":\\n            chain = ActionChains(driver)\\n            chain.send_keys(\" \")\\n            chain.perform()\\n        else:\\n            raise NotImplemented\\n    else:\\n        raise ValueError(\"Invalid instruction\")\\n\\n',\n",
       "  'function_name': 'perform_instruction',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def get_webdriver(url):\\n    options = webdriver.ChromeOptions()\\n    options.add_argument(\"--headless=new\")\\n    options.add_argument(\"disable-gpu\")\\n    options.add_argument(\"no-sandbox\")\\n\\n    driver = webdriver.Chrome(chrome_options=options)\\n    driver.implicitly_wait(5)\\n    driver.maximize_window()\\n    driver.implicitly_wait(5)\\n\\n    driver.get(url)\\n    driver.implicitly_wait(10)\\n    return driver\\n\\n',\n",
       "  'function_name': 'get_webdriver',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def miniwob(opt):\\n    env = gym.make(\"MiniWoBEnv-v0\", env_name=opt.env, headless=opt.headless)\\n\\n    success = 0\\n    for _ in range(opt.num_episodes):\\n        llm_agent = LLMAgent(\\n            opt.env,\\n            rci_plan_loop=opt.erci,\\n            rci_limit=opt.irci,\\n            llm=opt.llm,\\n            state_grounding=opt.sgrounding,\\n        )\\n        # initialize environment\\n        states = env.reset(seeds=[random.random()], record_screenshots=True)\\n        llm_agent.set_goal(states[0].utterance)\\n        html_state = get_html_state(opt, states)\\n\\n        llm_agent.update_html_state(html_state)\\n\\n        try:\\n            llm_agent.initialize_plan()\\n        except:\\n            continue\\n\\n        if opt.step == -1:\\n            step = llm_agent.get_plan_step()\\n        else:\\n            step = opt.step\\n\\n        logging.info(f\"The number of generated action steps: {step}\")\\n\\n        for _ in range(step):\\n            assert len(states) == 1\\n            try:\\n                instruction = llm_agent.generate_action()\\n                logging.info(f\"The executed instruction: {instruction}\")\\n\\n                miniwob_action = llm_agent.convert_to_miniwob_action(instruction)\\n\\n                states, rewards, dones, _ = env.step([miniwob_action])\\n            except ValueError:\\n                print(\"Invalid action or rci action fail\")\\n                rewards = [0]\\n                dones = [True]\\n                break\\n\\n            if rewards[0] != 0:\\n                break\\n\\n            if all(dones):  # or llm_agent.check_finish_plan():\\n                break\\n\\n            html_state = get_html_state(opt, states)\\n            llm_agent.update_html_state(html_state)\\n\\n        if rewards[0] > 0:\\n            success += 1\\n            llm_agent.save_result(True)\\n        else:\\n            llm_agent.save_result(False)\\n\\n        print(f\"success rate: {success / opt.num_episodes}\")\\n\\n    env.close()\\n\\n',\n",
       "  'function_name': 'miniwob',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def get_html_state(opt, states):\\n    extra_html_task = [\\n        \"click-dialog\",\\n        \"click-dialog-2\",\\n        \"use-autocomplete\",\\n        \"choose-date\",\\n    ]\\n\\n    html_body = states[0].html_body\\n    if opt.env in extra_html_task:\\n        html_body += states[0].html_extra\\n    return html_body\\n\\n',\n",
       "  'function_name': 'get_html_state',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/main.py'},\n",
       " {'code': 'def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\\n    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\\n    try:\\n        encoding = tiktoken.encoding_for_model(model)\\n    except KeyError:\\n        print(\"Warning: model not found. Using cl100k_base encoding.\")\\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\\n    if model in {\\n        \"gpt-3.5-turbo-0613\",\\n        \"gpt-3.5-turbo-16k-0613\",\\n        \"gpt-4-0314\",\\n        \"gpt-4-32k-0314\",\\n        \"gpt-4-0613\",\\n        \"gpt-4-32k-0613\",\\n        }:\\n        tokens_per_message = 3\\n        tokens_per_name = 1\\n    elif model == \"gpt-3.5-turbo-0301\":\\n        tokens_per_message = 4  # every message follows <|start|>{role/name}\\\\n{content}<|end|>\\\\n\\n        tokens_per_name = -1  # if there\\'s a name, the role is omitted\\n    elif \"gpt-3.5-turbo\" in model:\\n        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\\n        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\\n    elif \"gpt-4\" in model:\\n        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\\n        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\\n    else:\\n        raise NotImplementedError(\\n            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\\n        )\\n    num_tokens = 0\\n    for message in messages:\\n        num_tokens += tokens_per_message\\n        for key, value in message.items():\\n            num_tokens += len(encoding.encode(value))\\n            if key == \"name\":\\n                num_tokens += tokens_per_name\\n    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\\n    return num_tokens\\n',\n",
       "  'function_name': 'num_tokens_from_messages',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/llm_agent.py'},\n",
       " {'code': 'def llm_gpt(prompt: list[dict[str, str]], model=\\'gpt-3.5-turbo\\') -> str:\\n    api_key = os.environ.get(\"OPENAI_API_KEY\")\\n    api_base = os.environ.get(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\\n    for _ in range(7):\\n        try:\\n            response = requests.post(\\n                f\"{api_base}/v1/chat/completions\",\\n                headers={\\n                    \\'Authorization\\': f\\'Bearer {api_key}\\'\\n                },\\n                json={\\n                    \\'model\\': model,\\n                    \\'messages\\': prompt,\\n                    \\'temperature\\': 0.0,\\n                    \\'max_tokens\\': 256,\\n                },\\n                timeout=120,\\n            )\\n            text = response.json()[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n            return text.strip()\\n        # if timeout or connection error, retry\\n        except Timeout: \\n            print(\"Timeout, retrying...\")\\n        except ConnectionError:\\n            print(\"Connection error, retrying...\")\\n        except Exception:\\n            traceback.print_exc()\\n            try:\\n                print(response)\\n                print(response.text)\\n                print(\\'===REQUEST===\\')\\n                print(response.request)\\n                print(response.request.body)\\n            except:\\n                pass\\n        time.sleep(5 * random.random())\\n    else:\\n        raise Exception(\"Timeout after 7 retries.\")\\n',\n",
       "  'function_name': 'llm_gpt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/llm_agent.py'},\n",
       " {'code': 'def get_prompt(conv: Conversation) -> str:\\n    if conv.name == \\'openchat\\':\\n        ret = \\'\\'\\n        for role, message in conv.messages:\\n            if message:\\n                ret += role + \": \" + message + conv.sep\\n            else:\\n                ret += role + \":\"\\n        return ret\\n    else:\\n        return conv.get_prompt()\\n',\n",
       "  'function_name': 'get_prompt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/llm_agent.py'},\n",
       " {'code': 'def strip_punctuation(uni):\\n    \"\"\"Strips punctuation from a unicode string. Returns the new unicode.\\n\\n    Args:\\n        uni (unicode)\\n\\n    Returns:\\n        unicode\\n    \"\"\"\\n    return re.sub(r\"\\\\p{P}+\", \" \", uni)\\n\\n',\n",
       "  'function_name': 'strip_punctuation',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/utils.py'},\n",
       " {'code': 'def strip_whitespace(uni):\\n    \"\"\"Strips all whitespace from a unicode string.\\n\\n    Args:\\n        uni (unicode)\\n\\n    Returns:\\n        unicode\\n    \"\"\"\\n    return re.sub(r\"\\\\s+\", \"\", uni)\\n\\n',\n",
       "  'function_name': 'strip_whitespace',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/utils.py'},\n",
       " {'code': 'def find_sublist(l, sublist):\\n    \"\"\"Returns the index of the first occurence of sublist in the list l if\\n    it exists, otherwise -1. Like string.find\\n\\n    Args:\\n        l (list[Object]):\\n        sublist (list[Object])\\n\\n    Returns\\n        int\\n    \"\"\"\\n    for i in range(len(l)):\\n        # Check index 0 first for optimization\\n        if l[i] == sublist[0] and l[i : i + len(sublist)] == sublist:\\n            return i\\n    return -1\\n\\n',\n",
       "  'function_name': 'find_sublist',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/utils.py'},\n",
       " {'code': 'def word_tokenize(text):\\n    \"\"\"Tokenize without keeping the mapping to the original string.\\n\\n    Args:\\n        text (str or unicode)\\n    Return:\\n        list[unicode]\\n    \"\"\"\\n    return Phrase.TOKENIZER.findall(text)\\n',\n",
       "  'function_name': 'word_tokenize',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/utils.py'},\n",
       " {'code': 'def get_original_reward(metadata):\\n    return float(metadata[\"env_reward\"])\\n\\n',\n",
       "  'function_name': 'get_original_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/reward.py'},\n",
       " {'code': 'def get_raw_reward(metadata):\\n    \"\"\"Get the raw reward without time penalty.\\n    This is usually 1 for success and -1 for failure, but not always.\\n    \"\"\"\\n    return float(metadata[\"raw_reward\"])\\n\\n',\n",
       "  'function_name': 'get_raw_reward',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/reward.py'},\n",
       " {'code': 'def get_click_checkboxes_hard(metadata):\\n    \"\"\"(click-checkboxes task) Reward without partial credits.\\n    Give 1 if the raw reward is 1. Otherwise, give -1.\\n    \"\"\"\\n    if not metadata[\"done\"]:\\n        return 0.0\\n    return 1.0 if metadata[\"raw_reward\"] == 1.0 else -1.0\\n\\n',\n",
       "  'function_name': 'get_click_checkboxes_hard',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/reward.py'},\n",
       " {'code': 'def raw_reward_threshold(threshold):\\n    \"\"\"Return a reward processor that cut off at a threshold.\"\"\"\\n\\n    def fn(metadata):\\n        if metadata[\"raw_reward\"] > threshold:\\n            return 1.0\\n        elif metadata[\"raw_reward\"] > 0:\\n            return -1\\n        return metadata[\"raw_reward\"]\\n\\n    return fn\\n\\n',\n",
       "  'function_name': 'raw_reward_threshold',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/reward.py'},\n",
       " {'code': 'def get_reward_processor(config):\\n    if config.type == \"time_independent\":\\n        return get_raw_reward\\n    elif config.type == \"time_discounted\":\\n        return get_original_reward\\n    elif config.type == \"click_checkboxes_hard\":\\n        return get_click_checkboxes_hard\\n    else:\\n        raise ValueError(\"{} not a valid reward processor type\".format(config.type))\\n',\n",
       "  'function_name': 'get_reward_processor',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/reward.py'},\n",
       " {'code': 'def test_environment():\\n    try:\\n        task_name = sys.argv[1]\\n    except IndexError:\\n        print(\"Usage: python {} TASK_NAME\".format(sys.argv[0]))\\n        exit(1)\\n    env = MiniWoBEnvironment(task_name)\\n    base_url = os.environ.get(\"MINIWOB_BASE_URL\")\\n    env.configure(num_instances=1, seeds=[0], base_url=base_url)\\n    states = env.reset()\\n    print(states[0].dom.visualize())\\n    env.close()\\n\\n',\n",
       "  'function_name': 'test_environment',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/environment.py'},\n",
       " {'code': 'def get_field_extractor(task_name):\\n    try:\\n        return FIELD_EXTRACTORS[task_name]\\n    except KeyError:\\n\\n        def extractor(utterance):\\n            raise ValueError(\"{} does not have a field extractor.\".format(task_name))\\n\\n        return extractor\\n\\n',\n",
       "  'function_name': 'get_field_extractor',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def _add(task_name, regex, keys):\\n    def extractor(utterance):\\n        match = re.match(regex, utterance)\\n        return Fields(dict(zip(keys, match.groups())))\\n\\n    FIELD_EXTRACTORS[task_name] = extractor\\n\\n',\n",
       "  'function_name': '_add',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_click_checkboxes(utterance):\\n    targets = re.match(r\"Select (.*) and click Submit\\\\.\", utterance).group(1)\\n    if targets == \"nothing\":\\n        targets = []\\n    else:\\n        targets = re.split(\", ?\", targets)\\n    fields = dict(zip([\"target {}\".format(i) for i in range(len(targets))], targets))\\n    fields[\"button\"] = \"submit\"\\n    return Fields(fields)\\n\\n',\n",
       "  'function_name': 'extract_click_checkboxes',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_click_checkboxes_soft(utterance):\\n    targets = re.match(\\n        r\"Select words similar to (.*) and click Submit\\\\.\", utterance\\n    ).group(1)\\n    targets = re.split(\", ?\", targets)\\n    fields = dict(zip([\"target {}\".format(i) for i in range(len(targets))], targets))\\n    fields[\"button\"] = \"submit\"\\n    return Fields(fields)\\n\\n',\n",
       "  'function_name': 'extract_click_checkboxes_soft',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def parse_shape_desc(words):\\n    fields = {}\\n    for word in words:\\n        if word in (\"large\", \"small\"):\\n            fields[\"size\"] = word\\n        elif word in (\"red\", \"green\", \"blue\", \"aqua\", \"black\", \"magenta\", \"yellow\"):\\n            fields[\"color\"] = word\\n        elif word in (\"shape\", \"digit\", \"letter\", \"item\"):\\n            fields[\"type\"] = word\\n        else:\\n            fields[\"target\"] = word\\n    return fields\\n\\n',\n",
       "  'function_name': 'parse_shape_desc',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_click_shape(utterance):\\n    words = re.match(r\"Click on a (.*)\", utterance).group(1).split()\\n    return Fields(parse_shape_desc(words))\\n\\n',\n",
       "  'function_name': 'extract_click_shape',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_count_shape(utterance):\\n    words = re.match(r\"How many (.*)s are there\\\\?\", utterance).group(1).split()\\n    return Fields(parse_shape_desc(words))\\n\\n',\n",
       "  'function_name': 'extract_count_shape',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_email_inbox(utterance):\\n    for task, regex, keys in EMAIL_INBOX_PATTERNS:\\n        match = re.match(regex, utterance)\\n        if match:\\n            return Fields(dict(zip(keys, match.groups())))\\n    raise ValueError(\"Bad email-inbox utterance: {}\".format(utterance))\\n\\n',\n",
       "  'function_name': 'extract_email_inbox',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_email_inbox_nl(utterance):\\n    return Fields({})\\n\\n',\n",
       "  'function_name': 'extract_email_inbox_nl',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_enter_time(utterance):\\n    target = re.match(r\"Enter (.*) as the time and press submit\\\\.\", utterance).group(1)\\n    return Fields({\"target\": target.replace(\" \", \"\")})\\n\\n',\n",
       "  'function_name': 'extract_enter_time',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_use_autocomplete(utterance):\\n    match = re.match(\\n        r\\'Enter an item that starts with \"([^\"]*)\" and ends with \"([^\"]*)\"\\\\.\\', utterance\\n    )\\n    if match:\\n        return Fields({\"start\": match.group(1), \"end\": match.group(2)})\\n    else:\\n        match = re.match(r\\'Enter an item that starts with \"([^\"]*)\"\\', utterance)\\n        return Fields({\"start\": match.group(1)})\\n\\n',\n",
       "  'function_name': 'extract_use_autocomplete',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_flight_subtasks(utterance):\\n    fields = json.loads(utterance)\\n    return Fields({str(x): str(y) for (x, y) in fields.items()})\\n\\n',\n",
       "  'function_name': 'extract_flight_subtasks',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def extract_utterances():\\n    try:\\n        task_name = sys.argv[1]\\n    except:\\n        print(sys.stderr, \"Usage: {} task_name\".format(sys.argv[0]))\\n        exit(1)\\n    FIELD_EXTRACTORS[task_name] = lambda utt: Fields({})\\n    from miniwob.environment import MiniWoBEnvironment\\n\\n    env = MiniWoBEnvironment(task_name)\\n    base_url = os.environ.get(\"MINIWOB_BASE_URL\")\\n    env.configure(num_instances=4, seeds=range(4), base_url=base_url)\\n    for i in range(25):\\n        states = env.reset()\\n        for state in states:\\n            print(\"UTT:\\\\t{}\".format(state.utterance.replace(\"\\\\n\", \" \")))\\n    env.close()\\n\\n',\n",
       "  'function_name': 'extract_utterances',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/fields.py'},\n",
       " {'code': 'def get_screenshot(driver, width=160, height=210):\\n    \"\"\"Return a cropped screenshot taken by the Selenium instance.\\n\\n    Args:\\n        driver (Chrome WebDriver)\\n        width (int)\\n        height (int)\\n    Returns:\\n        PIL Image object\\n    \"\"\"\\n    png_data = driver.get_screenshot_as_png()\\n    pil_image = Image.open(BytesIO(png_data))\\n    pil_image = pil_image.crop((0, 0, 320, 420)).convert(\"RGB\")\\n    pil_image = pil_image.convert(\"RGB\")\\n    return pil_image\\n\\n',\n",
       "  'function_name': 'get_screenshot',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/screenshot.py'},\n",
       " {'code': 'def pil_to_numpy_array(pil_image):\\n    \"\"\"Convert PIL image to a numpy array.\\n\\n    Args:\\n        pil_image (PIL Image)\\n    Returns:\\n        numpy array of shape (height, width, 3)\\n        where 3 is the number of channels (RGB).\\n    \"\"\"\\n    return np.array(pil_image).astype(np.float32)\\n\\n',\n",
       "  'function_name': 'pil_to_numpy_array',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/screenshot.py'},\n",
       " {'code': 'def create_gif(path_prefix):\\n    \"\"\"Create and save an animated gif based on the dumped screenshots.\\n\\n    The event file is read from <path_prefix>.json, while the images are\\n    loaded from <path_prefix>-<step>.png\\n\\n    Args:\\n        path_prefix (str): Something like\\n            data/experiments/123_unnamed/traces/test/2000-img/2000-3\\n            (control step 2000; episode 3)\\n    \"\"\"\\n    # Read the event file\\n    with open(path_prefix + \".json\") as fin:\\n        events = json.load(fin)\\n    # Read the image files\\n    images = []\\n    for i, event in enumerate(events):\\n        img = Image.open(\"{}-{}.png\".format(path_prefix, i)).convert(\"RGBA\")\\n        images.append(img)\\n        # Highlight the element\\n        if \"element\" in event:\\n            elt = event[\"element\"]\\n            highlight = Image.new(\"RGBA\", img.size, (255, 255, 255, 0))\\n            draw = ImageDraw.Draw(highlight)\\n            x0 = elt[\"left\"]\\n            x1 = x0 + elt[\"width\"]\\n            y0 = elt[\"top\"]\\n            y1 = y0 + elt[\"height\"]\\n            draw.rectangle(\\n                [x0, y0, x1, y1], fill=(255, 0, 0, 128), outline=(0, 0, 255, 255)\\n            )\\n            del draw\\n            images.append(Image.alpha_composite(img, highlight))\\n    # Save the image file\\n    durations = [250] * len(images)\\n    durations[-1] = 1000\\n    images[0].save(\\n        path_prefix + \".gif\",\\n        append_images=images[1:],\\n        save_all=True,\\n        loop=0,\\n        duration=durations,\\n    )\\n\\n',\n",
       "  'function_name': 'create_gif',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/miniwob++/computergym/computergym/miniwob/miniwob_interface/screenshot.py'},\n",
       " {'code': 'def is_action_failed(obs):\\n    return obs == \"No known action matches that input.\" or \"can\\'t\" in obs or \"not\" in obs or \"doesn\\'t\" in obs\\n',\n",
       "  'function_name': 'is_action_failed',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': \"def find_non_alpha_index(s):\\n    for i, c in enumerate(s):\\n        if not c.isalpha() and c != ' ':\\n            return i\\n    return -1  # if no non-alpha character found \\n\",\n",
       "  'function_name': 'find_non_alpha_index',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def clean_look(look, version=\"not_lite\"):\\n    \\n    if \"You also see:\" in look:\\n        end_ind = look.index(\"You also see:\")\\n        look = look[:end_ind]\\n\\n    clean_looks = []\\n    for line in look.splitlines():\\n        if not line.strip():\\n            continue\\n        if \"In it, you see:\"  in line:\\n            if version != \"lite\":\\n                clean_looks.append(line)\\n            continue\\n        if \"the agent\" in line or \" air\" in line:\\n            continue\\n        line = line.replace(\"substance called \", \" \").strip()\\n        if version == \"lite\":\\n            end_ind = find_non_alpha_index(line.strip())\\n            if end_ind > 0:\\n                line = line[:end_ind].strip()\\n        clean_looks.append(line)\\n    if version == \"lite\":\\n        return \", \".join(clean_looks)        \\n    else:\\n        return \"\\\\n \\\\t - \".join(clean_looks[:])        \\n\\n\\n ',\n",
       "  'function_name': 'clean_look',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def get_current_room(look):\\n    global rooms \\n    first_sent = look.split(\".\")[0]\\n    for r in rooms:\\n        if \"called the \"+ r in first_sent:\\n            return r  \\n    return None \\n\\n',\n",
       "  'function_name': 'get_current_room',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def load_model(args, device):\\n    tokenizer = AutoTokenizer.from_pretrained(args[\"lm_path\"])\\n    lm_model = AutoModelForSeq2SeqLM.from_pretrained(args[\"lm_path\"])\\n    lm_model.eval() \\n    lm_model.to(device)\\n    if args[\"sbert\"]:\\n        sbert_model = SentenceTransformer(\\'paraphrase-MiniLM-L6-v2\\')\\n    else:\\n        sbert_model = None \\n    \\n    if args[\"local_llm\"] == \"xgen\":\\n        local_llm.load()\\n        assert local_llm.llm_model is not None \\n        assert local_llm.llm_tokenizer is not None \\n        print(\"Testing local LLM:\" + args[\"local_llm\"])\\n        print(local_llm.generate(\"Hello, who are you?\")) # for testing \\n        llm_model = local_llm.llm_model\\n    else:\\n        llm_model = None \\n    return lm_model, tokenizer, sbert_model, llm_model\\n\\n\\n\\n',\n",
       "  'function_name': 'load_model',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def load_variation(env, args, task_num, logger):\\n    variations = []\\n    if (args[\"set\"] == \"train\"):\\n        variations = list(env.getVariationsTrain())\\n        if task_num == 26: \\n            variations = variations[:int(len(variations)/10)]\\n        elif task_num == 29: \\n            variations = variations[:int(len(variations)/2)]\\n    elif (args[\"set\"] == \"test\"):\\n        variations = list(env.getVariationsTest())\\n        if True or args[\"cut_off\"]:\\n            test_len = min(10, len(variations))\\n            if task_num == 25:\\n                test_len = 5\\n            elif task_num == 15:\\n                test_len = 9\\n            random.seed(1)\\n            random.shuffle(variations)\\n            variations = variations[:test_len]\\n        print(f\\'{task_num}: {len(variations)}\\')\\n    elif (args[\"set\"] == \"dev\"):\\n        variations = list(env.getVariationsDev()) \\n        variations = variations[:3]\\n    elif (args[\"set\"] == \"test_mini_2\"):\\n        variations = list(env.getVariationsTest()) \\n        # random.seed(1)\\n        # random.shuffle(variations)\\n        variations = variations[3:10] \\n    elif (args[\"set\"] == \"test_mini\"):\\n        variations = list(env.getVariationsTest()) \\n        # random.seed(1)\\n        # random.shuffle(variations)\\n        variations = variations[:3] \\n    elif (args[\"set\"] == \"test_mini_mini\"):\\n        variations = list(env.getVariationsTest()) \\n        # random.seed(1)\\n        # random.shuffle(variations)\\n        variations = variations[:1] \\n    else:\\n        logger.info(\"ERROR: Unknown set to evaluate on (\" + str(args[\"set\"]) + \")\")\\n        exit(1)\\n \\n    logger.info(variations)\\n    return variations\\n\\n\\n\\n',\n",
       "  'function_name': 'load_variation',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def findValidActionNew(predictions, env, look, recent_actions, sbert_model, logger, k=5):\\n    global rooms\\n    valid_open_door = [\"open door to \" + i for i in rooms] \\n    invalid_focus = [\"focus on \"+x for x in [\"agent\", \"air\"]+rooms]\\n    validActions = set(env.getValidActionObjectCombinations())\\n    validActions.update(valid_open_door)\\n    validActions.difference_update(invalid_focus)\\n\\n    inventory = env.inventory().lower()\\n    \\n    validActions.difference_update(recent_actions[-3:]) \\n\\n    for va in list(validActions):\\n        if \"door\" in va and \"open\" not in va:\\n            validActions.remove(va)\\n            continue\\n        if va.startswith(\"focus on\"): \\n            pattern = re.compile(r\"\\\\b(?:focus|on|in|to)\\\\b\", re.IGNORECASE)\\n            used_objs = pattern.sub(\"\", va).split(\" \")\\n            valid = True\\n            for obj in used_objs:\\n                if obj not in look + \" \" + inventory:\\n                    valid = False\\n            if not valid:\\n                validActions.remove(va)\\n    \\n\\n    # 1) if acton in top k is valid, choose it\\n    found_valid_in_top = False\\n    action = None\\n    for pred in predictions[:k]:\\n        pred = pred.replace(\"green house\", \"greenhouse\") \\n        if pred.strip() in validActions:\\n            found_valid_in_top = True\\n            action = pred.strip()\\n            break\\n    if found_valid_in_top:\\n        return action \\n    else:\\n        logger.info(f\"No valid action found in top k={k} predictions.\")\\n        validActions = list(validActions)\\n        validActions.sort(key=lambda x: len(x))\\n        logger.info(\"Valid Predictions: \"+ str(validActions)) \\n \\n\\n    # 2) else, find most similar action\\n\\n    if sbert_model:    \\n        pred_vectors = sbert_model.encode(predictions[:5], batch_size=5, show_progress_bar=False)\\n        valid_action_vectors = sbert_model.encode(validActions, batch_size=min(len(validActions), 128), show_progress_bar=False)\\n\\n\\n        # Calculate cosine similarity between each vector in pred_vectors and all vectors in valid_action_vectors\\n        similarity_matrix = cosine_similarity(pred_vectors, valid_action_vectors)\\n\\n        # Take the sum of cosine similarities for each vector in valid_action_vectors\\n        sum_similarities = similarity_matrix.sum(axis=0)\\n\\n        # Find the indices of the k vectors with the highest sum of cosine similarities\\n        N = 5 # Change this to the number of top vectors you want to retrieve\\n        top_indices = np.argpartition(sum_similarities, -N)[-N:]\\n\\n        # Print the indices of the top vectors\\n        # print(f\"The indices of the top {k} vectors in valid_action_vectors are: {top_indices}\")\\n        logger.info(\"The most similar valid actions to the predictions:\")\\n        for ti in top_indices:\\n            logger.info(\"\\\\t\\\\t - \"+validActions[ti])\\n        action = validActions[top_indices[0]]\\n    else:\\n        # jaccard\\n        topValue = 0.0\\n        topAction = predictions[0]\\n        # embPred = sbert_model.encode(pred, convert_to_tensor=True)\\n        tokensPred = predictions[0].split(\" \")\\n        uniqueTokensPred = set(tokensPred)\\n\\n        for validAction in validActions: \\n            tokensAction = validAction.split(\" \")\\n            uniqueTokensAction = set(tokensAction)\\n\\n            intersection = uniqueTokensPred.intersection(uniqueTokensAction)\\n            if (len(intersection) > topValue):\\n                topAction = validAction\\n                topValue = len(intersection)\\n\\n        logger.info(\"TOP VALID ACTION: \" + topAction)\\n        # Sanitize top action\\n        topAction = re.sub(r\\'[^A-Za-z0-9 ]+\\', \\'\\', topAction)\\n        action = topAction\\n    return action\\n \\n',\n",
       "  'function_name': 'findValidActionNew',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def getFilteredValidActions(env, look, filter=True, task_id=None, task_desc=None):\\n    global rooms\\n    valid_open_door = [\"open door to \" + i for i in rooms] \\n    invalid_focus = [\"focus on \"+x for x in [\"agent\", \"air\"]+rooms]\\n    validActions = set(env.getValidActionObjectCombinations())\\n    validActions.update(valid_open_door)\\n    validActions.difference_update(invalid_focus)\\n\\n    inventory = env.inventory()\\n    \\n    validActions.add(\"wait\")\\n    validActions.add(\"wait1\") \\n    if task_id is not None and task_desc is not None: \\n        if task_id not in [5,6,7,8,17,18,19,20]:\\n            for va in list(validActions):\\n                if not va.startswith(\"focus on\"):\\n                    continue\\n                items = va.replace(\"focus on\", \"\").split()\\n                task_desc = task_desc.translate(str.maketrans(\\'\\', \\'\\', string.punctuation)).lower()\\n                if len(set(items) & set(task_desc.split())) == 0:\\n                    validActions.remove(va)\\n        if task_id not in [14,15,16]:\\n            for va in list(validActions):\\n                if not va.startswith(\"examine\"):\\n                    continue\\n                items = va.replace(\"examine\", \"\").split()\\n                task_desc = task_desc.translate(str.maketrans(\\'\\', \\'\\', string.punctuation)).lower()\\n                if len(set(items) & set(task_desc.split())) == 0:\\n                    validActions.remove(va)\\n    for va in list(validActions):\\n        if not va.startswith(\"mix\"):\\n            continue\\n        container_words = [\"cup\", \"bowl\", \"metal pot\", \"jug\"]\\n        if not any([\"mix\" + c for c in container_words]):\\n            validActions.remove(va)\\n    if not filter:\\n        return validActions\\n    for va in list(validActions):\\n        if \"door\" in va and \"open\" not in va:\\n            validActions.remove(va)\\n            continue\\n    return validActions\\n    ',\n",
       "  'function_name': 'getFilteredValidActions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def sbert_search(action_list, validActions, sbert_model, logger, k=1, N=1, return_scores=False):\\n    validActions = list(validActions)\\n    pred_vectors = sbert_model.encode(action_list[:k], batch_size=5, show_progress_bar=False)\\n    valid_action_vectors = sbert_model.encode(validActions, batch_size=min(len(validActions), 128), show_progress_bar=False)\\n\\n    # Calculate cosine similarity between each vector in pred_vectors and all vectors in valid_action_vectors\\n    similarity_matrix = cosine_similarity(pred_vectors, valid_action_vectors)\\n\\n    # Take the sum of cosine similarities for each vector in valid_action_vectors\\n    sum_similarities = similarity_matrix.sum(axis=0)\\n\\n    N = min(N, len(validActions))\\n    # Find the indices of the k vectors with the highest sum of cosine similarities\\n    # N = 10 # Change this to the number of top vectors you want to retrieve\\n    top_indices = np.argpartition(sum_similarities, -N)[-N:]\\n\\n    # Print the indices of the top vectors\\n    # print(f\"The indices of the top {k} vectors in valid_action_vectors are: {top_indices}\")\\n    # logger.info(\"The most similar valid actions to the predictions:\")\\n    # for ti in top_indices:\\n    #     logger.info(\"\\\\t\\\\t - \"+validActions[ti])\\n    if N == 1:\\n        action = validActions[top_indices[0]]\\n        score = sum_similarities[top_indices[0]]\\n        if return_scores:\\n            return action, score\\n        return action\\n    else:\\n        action_list = []\\n        for i in range(N):\\n            action = validActions[top_indices[i]]\\n            action_list.append(action)\\n        return action_list\\n\\n\\n\\n    \\n',\n",
       "  'function_name': 'sbert_search',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def find_object(action, objects_string): \\n    # Find the index of the target object in the words list\\n    target_object = \\' \\'.join(action.split()[2:])\\n    if target_object not in objects_string:\\n        return action \\n    target_object_index = objects_string.index(target_object)\\n    \\n    # Check if the target object is inside a container\\n    if objects_string[target_object_index - 8:target_object_index - 1] == \"called \":\\n        container_start_index = objects_string.rfind(\"(\", 0, target_object_index) - 1\\n        container_end_index = objects_string.rfind(\")\", 0, target_object_index) + 1\\n        container = objects_string[container_start_index:container_end_index]\\n        action = action.replace(target_object, f\"{container}\")\\n    \\n    return action\\n\\n',\n",
       "  'function_name': 'find_object',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def clean_obj_name(action):\\n    if \"unknown substance\" not in action:\\n        return action \\n    for n in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\\n        action = action.replace(f\" {n}\", \"\")\\n    return action \\n',\n",
       "  'function_name': 'clean_obj_name',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def try_to_replace(action, validActions, look=None, inventory=None):\\n    if action.startswith(\"wait\"):\\n        return \"wait\"\\n    if action in validActions:\\n        return action \\n    try_action = action.replace(\"green house\", \"greenhouse\") \\n    try_action = try_action.replace(\"adult\", \"adult adult\")\\n    try_action = try_action.replace(\"baby\", \"baby baby\")\\n    if try_action in validActions:\\n        return try_action \\n    if action.startswith(\"go to\"):\\n        if action.replace(\"go to\", \"teleport to\") in validActions:\\n            return action.replace(\"go to\", \"teleport to\")\\n        elif action.replace(\"go to\", \"open door to\") in validActions:\\n            return action.replace(\"go to\", \"open door to\") \\n    if action.startswith(\"pick up\"):\\n        action = find_object(action, look)\\n        if action in validActions:\\n            return action \\n        if action.replace(\"substance in \",\"\") in validActions:\\n            return action\\n    if action.startswith(\"focus on\"):\\n        obj = action.replace(\"focus on\", \"\").strip()\\n        todo = \"focus on substance in inventory\"\\n        if obj in inventory and  todo in validActions:\\n            return todo\\n    if action.startswith(\"move\") and \"to\" in action:\\n        pattern = r\"move (.*?) to\"\\n        obj = re.search(pattern, action)\\n        if obj is None:\\n            return action \\n        else:\\n            obj = obj.group(1)\\n        todo = action.replace(obj, \"substance in inventory\")\\n        if obj in inventory and todo in validActions:\\n            return todo\\n    \\n\\n    split_string = action.rsplit(\" in \", 1) # Split the string from the last occurrence of \" in \"\\n    if split_string[0] in validActions:\\n        return split_string[0]\\n\\n    if \" unknown substance \" in action:\\n        action = split_string[0]\\n        action = clean_obj_name(action)\\n        if action in validActions:\\n            return action \\n        \\n    for r in rooms:\\n        action = action.replace(\"in \" + r, \"\")\\n    return action \\n        \\n',\n",
       "  'function_name': 'try_to_replace',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def findValidActionWithSystem2(predictions, env, task_id, task_description, look, \\n                               recent_actions, recent_reward, recent_obs, recent_locs, recent_looks, failed_messages,\\n                               demo_data, logger, sbert_model, step, last_time_system2_steps, \\n                               useful_focus_on, focus_on_done, force_system_1, force_system_2, \\n                               gpt_version=\"gpt-4\", llm=None):\\n    \\n    inventory = env.inventory()\\n    #### Done preparing valid actions #### \\n    validActions = getFilteredValidActions(env, look, task_id=task_id, task_desc=task_description)\\n    enable_system2 = True \\n\\n    # if not force_system_2:\\n    if True:\\n        # 1) if acton in top 3 is valid, try to choose it\\n        found_valid_in_top = False\\n        action = None\\n        if recent_actions[-1].startswith(\"wait\") and predictions[0].startswith(\"wait\"):\\n            predictions = predictions[1:]\\n        for pred in predictions[:1]:\\n            # pred = pred.replace(\"green house\", \"greenhouse\") \\n            pred = try_to_replace(pred, validActions, look, inventory)\\n            action = pred.strip()\\n            if pred.strip().startswith(\"focus on\") and focus_on_done:\\n                break \\n            if pred.strip() in validActions:\\n                found_valid_in_top = True\\n                break\\n        \\n        \\n         \\n        logger.info(f\"found_valid_in_top={found_valid_in_top} ({action}) \") \\n        \\n\\n        \\n        \\n        if found_valid_in_top and len(recent_actions) < 10:\\n            # Use fast agent in the first 10 steps\\n            enable_system2 = False \\n\\n        if found_valid_in_top and step - last_time_system2_steps[-1] < 5:\\n            # only when we did not use System 2 in the past five time steps\\n            enable_system2 = False \\n\\n        if found_valid_in_top and sum(recent_reward[-5:]) > 0: \\n            logger.info(\"Recent scores has increased in recent 5 timesteps. Not doing System 2.\")\\n            enable_system2 = False\\n        \\n        if found_valid_in_top and action not in recent_actions[-3:]:\\n            logger.info(\"No such actions in recent 3 timesteps. Not doing System 2.\")\\n            enable_system2 = False \\n        \\n        if found_valid_in_top and not enable_system2 and not force_system_2:\\n            assert action is not None \\n            logger.info(\"Using Fast System output.\")\\n            return False, action\\n\\n        if ((not found_valid_in_top and step - last_time_system2_steps[-1] <= 2) or force_system_1) and not force_system_2:\\n            # only when we did not use System 2 in the past five time steps\\n            predictions = [try_to_replace(pred, validActions, look, inventory) for pred in predictions if not pred.startswith(\"focus on\")][:3]\\n            trial_action = None\\n            for pred in predictions:\\n                if pred in validActions:\\n                    trial_action = pred\\n                    break \\n            trial_action = predictions[0] if trial_action is None and predictions else trial_action\\n            return False, trial_action\\n\\n\\n    assert enable_system2  or force_system_2\\n    if found_valid_in_top:\\n        fast_action = action\\n    else:\\n        fast_action = None\\n    \\n    logger.info(\"Now, start using System 2: OpenAI for reasoning\")  \\n    real_action_list = []\\n    try:\\n        enc = tiktoken.encoding_for_model(gpt_version)\\n\\n        demos = demo_data[str(task_id)]\\n        \\n        prompt_to_plan = compose_prompt_to_plan(demos, useful_focus_on, task_description, recent_actions, recent_obs, recent_locs, recent_looks, failed_messages, look, inventory, fast_action, version=\"full\")  \\n        if gpt_version == \"gpt-3.5-turbo\":\\n            length = len(enc.encode(prompt_to_plan))\\n            if length >= 4000:\\n                prompt_to_plan = compose_prompt_to_plan(demos, useful_focus_on, task_description, recent_actions, recent_obs, recent_locs, recent_looks, failed_messages, look, inventory, fast_action, version=\"lite\")  \\n\\n        logger.info(\"-\"*30 + \"prompt_to_plan\" + \"-\"*30)\\n        logger.info(\"\\\\n\"+prompt_to_plan)\\n        logger.info(\"-\"*35 + \"-\"*35)\\n        if llm is None:\\n            response = completion_with_backoff(model=gpt_version, # try gpt-4? # gpt-3.5-turbo\\n                    messages=[{\"role\": \"user\", \"content\": prompt_to_plan}], n = 1, temperature=0, top_p=1)\\n            response_plan = response[\"choices\"][0][\"message\"][\"content\"]\\n        else:\\n            response_plan = local_llm.generate(prompt_to_plan, logger=logger.info)\\n            \\n        logger.info(\"-\"*30 + \"response_plan\" + \"-\"*30)\\n        logger.info(\"\\\\n\"+response_plan)\\n        logger.info(\"-\"*35 + \"-\"*35) \\n\\n        logger.info(\"Sleeping for 10s.\")\\n        time.sleep(10)\\n        ## 2) create actions    \\n        prompt_to_next_actions = compose_prompt_to_nextactions(demos, task_description, \\n                                                               recent_actions, recent_obs, recent_locs, failed_messages,\\n                                                                 look, inventory, response_plan, useful_focus_on, k=10, version=gpt_version)\\n        logger.info(\"-\"*30 + \"prompt_to_next_actions\" + \"-\"*30)\\n        logger.info(\"\\\\n\"+prompt_to_next_actions)\\n        logger.info(\"-\"*35 + \"-\"*35)\\n        if llm is None:\\n            response = completion_with_backoff(model=gpt_version,\\n                    messages=[{\"role\": \"user\", \"content\": prompt_to_next_actions}], n = 1, temperature=0, top_p=1)\\n            response_next_actions = response[\"choices\"][0][\"message\"][\"content\"]\\n        else:\\n            response_next_actions = local_llm.generate(prompt_to_next_actions)\\n        \\n        def post_process(response_next_actions):\\n            logger.info(\"-\"*30 + \"response_next_actions\" + \"-\"*30)\\n            logger.info(\"\\\\n\"+response_next_actions)\\n            logger.info(\"-\"*35 + \"-\"*35)\\n            action_list = response_next_actions.split(\"\\\\n\")[:5] # only the take the first 10\\n            logger.info(f\"action_list={action_list}\") \\n            real_action_list = []\\n            guess_obs_list = []\\n            for action in action_list:\\n                if \"repeat\" in action.lower():\\n\\n                    if \"wait\" in real_action_list[-1].lower():\\n                        todos = real_action_list[-3:]\\n                        todo_obs = guess_obs_list[-3:]\\n                    else:\\n                        todos = real_action_list[-2:]\\n                        todo_obs = guess_obs_list[-3:]\\n\\n                    real_action_list += todos*5\\n                    guess_obs_list += todo_obs*5\\n                    if \"until\" in action.lower():\\n                        break \\n                    continue\\n                if \":\" not in action or \"Action\" not in action or \"(\" not in action or \")\" not in action:\\n                    continue \\n                start_ind = action.index(\":\")\\n                end_ind = action.index(\")\")\\n                if \"-->\" in action:\\n                    guess_obs = action[action.index(\"-->\")+3:].strip().replace(\"You \", \"\").replace(\" the \", \" \").replace(\".\", \"\").strip()\\n                else:\\n                    guess_obs = \"None\"\\n                action = action[start_ind+1: end_ind+1].strip()\\n                action = recover_action(action)\\n                if action:\\n                    real_action_list.append(action)\\n                    guess_obs_list.append(guess_obs)\\n            logger.info(f\"real_action_list={real_action_list}\") \\n            return real_action_list, guess_obs_list\\n        real_action_list, guess_obs_list = post_process(response_next_actions)\\n    except Exception as e:\\n        logger.info(\"OpenAI error:\" + str(e))\\n        \\n    if len(real_action_list) == 0:\\n        logger.info(\"Error from System 2. Try again.\")\\n        prompt_again = []\\n        prompt_again.append(\"Your previous generation is wrong. I cannot use your output actions to complete the next subgoal or the task. Please rethink and generate the actions again. \")\\n        prompt_again.append(\"Note that I can only do actions with available objects in the current in environment or my inventory. If the needed object are not available, please teleport to the location first.\")\\n        prompt_again.append(\"Please use the below format to organize the response.\")\\n        prompt_again.append(\"Action 1: [...] -->  \\\\n Action 2: [...] --> \\\\n ...\")\\n        prompt_again = \"\\\\n\".join(prompt_again)\\n        logger.info(\"-\"*30 + \"prompt_again\" + \"-\"*30)\\n        logger.info(\"\\\\n\"+prompt_again)\\n        logger.info(\"-\"*35 + \"-\"*35)\\n\\n        if llm is None:        \\n            response_v2 = completion_with_backoff(model=gpt_version,\\n                    messages=[{\"role\": \"user\", \"content\": prompt_to_next_actions},\\n                            {\"role\": \"assistant\", \"content\": response_next_actions},\\n                            {\"role\": \"user\", \"content\": prompt_again},\\n                            ], n = 1, temperature=0, top_p=1)\\n            \\n            response_next_actions_v2 = response_v2[\"choices\"][0][\"message\"][\"content\"]\\n        else:\\n            # TODO: llm.generate()\\n            response_next_actions_v2 = local_llm.generate(prompt_to_next_actions \\n                                                          + \"### Assistant: \" \\n                                                          + response_next_actions \\n                                                          + \"### Human: \" \\n                                                          + prompt_again) \\n\\n        real_action_list, guess_obs_list = post_process(response_next_actions_v2)\\n    if len(real_action_list) == 0:\\n        logger.info(\"Error from System 2. Still does not work. Use Fast System (+ sbert)\")\\n        # if action is None:\\n        action_list = [try_to_replace(predictions[0], validActions, look, inventory)]\\n        action = sbert_search(action_list, list(validActions), sbert_model, logger)\\n        return False, action \\n    # TODO: select the action \\n    return True, (real_action_list, guess_obs_list)\\n',\n",
       "  'function_name': 'findValidActionWithSystem2',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def compose_prompt_to_nextactions(demos, task_desc, recent_actions, recent_obs, recent_locs, failed_messages, look, inventory, response_next_subgoal, useful_focus_on, fast_action=None, k=10, version=\"gpt-4\"):\\n\\n    prompt_to_next_actions = []\\n    prompt_to_next_actions.append(\"You are an experienced teacher who always guide students to complete the science experiments. Now let\\'s do science experiments with a sequence of actions.\")\\n    prompt_to_next_actions.append(\"In this environment, there are a few locations: art studio, workshop, kitchen, living room, bedroom, bathroom, foundry, greenhouse, outside, and a hallway connecting them.\")\\n        \\n    prompt_to_next_actions.append(\"You have done a few science experiments successfully and below are the action history of your experiments with similar tasks.\")\\n\\n    prompt_to_next_actions.append(\"Example task 1: \"+ demos[0][0])\\n    prompt_to_next_actions += demos[0][1:]\\n    if len(demos) >= 2:\\n        prompt_to_next_actions.append(\"Example task 2: \"+ demos[1][0])\\n        prompt_to_next_actions += demos[1][1:]\\n    # prompt_to_next_actions += [\"- Action: \"+ a for a in demos[1][1:]]\\n\\n\\n    prompt_to_next_actions.append(\"In a new science experiment that is similar to the above two, \" + task_desc.replace(\"Your\", \"my\"))\\n    \\n    # prompt_to_next_actions.append(\"Given the above completed subgoals, what should be your next subgoal to complete for finishing the task?\")\\n    \\n    prompt_to_next_actions.append(f\"My previous {k} actions and observations are as follows:\")\\n\\n    recent_actions, recent_obs, _, _, recent_locs = clean_history(recent_actions, recent_obs, [-1]*len(recent_actions), [-1]*len(recent_actions), recent_locs)\\n        \\n\\n    history = []\\n    repeat = 0    \\n    for ind, (l, a, o) in enumerate(zip(recent_locs[:], recent_actions[:], recent_obs[:])):\\n        if o == \"N/A\":\\n            continue \\n        fa = formalize_action(a)\\n        if \"(\" not in fa:\\n            continue\\n        at = fa[:fa.index(\"(\")]\\n        if at not in \"\\\\n\".join(demos[0][1:]):\\n            # Skipping the actions with types not in the demos\\n            continue\\n        to_add = f\"- (in {l}) Action: {fa} --> {o}\"\\n        if ind+1 < len(recent_actions) and a in recent_actions[max(0, ind-5):ind] and a in recent_actions[ind+1:min(len(recent_actions), ind+5)]:\\n            repeat += 1\\n            continue \\n        \\n        history.append(to_add) \\n        if repeat > 0:\\n            history.append(f\"Repeat the above action for {repeat} times.\")             \\n            repeat = 0\\n    # prompt_to_next_actions.append()\\n    prompt_to_next_actions += history[-k:]\\n\\n    if useful_focus_on:\\n        prompt_to_next_actions.append(\"Importantly, I have FOCUS on these things already: \" + \", \".join([fo.replace(\"focus on\", \"\") for fo in  useful_focus_on]))\\n    else:\\n        prompt_to_next_actions.append(\"Importantly, I have FOCUS on nothing yet.\")\\n\\n    pattern = r\"focus on\\\\s+(\\\\b\\\\w+\\\\b(\\\\s+\\\\b\\\\w+\\\\b)*)\"\\n    matches = re.findall(pattern, task_desc)\\n    to_focus = [match[0].replace(\"the \", \" \").strip() for match in matches]\\n    pattern = r\"find\\\\s+(\\\\b\\\\w+\\\\b(\\\\s+\\\\b\\\\w+\\\\b)*)\"\\n    matches = re.findall(pattern, task_desc.replace(\"a(n)\", \"a\"))\\n    to_focus_v2 = [match[0].replace(\"the \", \" \").strip() for match in matches]\\n\\n    # prompt_to_next_actions.append(\"You have completed these subgoals:\")\\n    # prompt_to_next_actions.append(response_previous_subgoals)\\n    prompt_to_next_actions.append(\"However, my actions so far cannot complete the task now. I do not know what to do for the next steps.\")\\n    if failed_messages:\\n        failed_messages = set(failed_messages)\\n        prompt_to_next_actions.append(\"There are some error messages about my previous actions:\")\\n        prompt_to_next_actions += failed_messages\\n    prompt_to_next_actions.append(\"I asked my teacher for advice and the teacher told me these advice:\")\\n    prompt_to_next_actions.append(response_next_subgoal.replace(\"Question\", \"Answer\").replace(\"Answer\", \"Advice\")) \\n    prompt_to_next_actions.append(\"\")\\n    prompt_to_next_actions.append(\"In current environment: \" + clean_look(look) + \"\\\\n\" + inventory)\\n    prompt_to_next_actions.append(\"What should be my next actions to complete the next subgoal in the current environment? \")\\n    prompt_to_next_actions.append(\"If any of the suggested next subgoals need knowledge to make decisions (e.g., determining or comparing the properties of objects and animals), please do that for me.\")\\n    prompt_to_next_actions.append(\"The ONLY allowed action types are:\")\\n    for ai in action_type_description:\\n        at = ai[\\'action_type\\']\\n        at = at[:at.index(\"(\")]\\n        if at not in \"\\\\n\".join(demos[0][1:] + demos[0][2:]):\\n            continue\\n        prompt_to_next_actions.append(f\"- {ai[\\'action_type\\']} : {ai[\\'desc\\']} \")   \\n\\n    prompt_to_next_actions.append(f\"Important! You can only use FOCUS actions on these items: {\\', \\'.join(to_focus)} . \") # (Hint: {\\',\\'.join(to_focus_v2)})\\n    prompt_to_next_actions.append(\"You cannot FOCUS on any other things. Please only use FOCUS as required by the task description. Also, please FOCUS more directly, try not to focus on the container.\")\\n\\n    prompt_to_next_actions.append(\"Please use the above mentioned action types to convert the unfinished subgoal to a short sequence of concrete actions.  DO NOT USER OTHER TYPES OF ACTIONS. Follow the report of the two example tasks shown to you previously.\")    \\n    prompt_to_next_actions.append(\"Please do not try to look for books or computers to look up information. You will need to use your own commonsense knowledge to make decisions (e.g., determining properties of objects and animals).\")\\n    prompt_to_next_actions.append(\"Note that I can only do actions with available objects in the current location or inventory!!\") \\n    prompt_to_next_actions.append(\"Please use the below format to organize the response.\")\\n    prompt_to_next_actions.append(\"Action 1: [...] -->  \\\\n Action 2: [...] --> \\\\n ...\")\\n    return \"\\\\n\".join(prompt_to_next_actions)\\n\\n ',\n",
       "  'function_name': 'compose_prompt_to_nextactions',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def compose_prompt_to_plan(demos, useful_focus_on, task_desc, recent_actions, recent_obs, recent_locs, recent_looks, failed_messages, look, inventory, fast_action, version=\"full\"):\\n    clean_obs = []\\n    assert len(recent_obs) == len(recent_locs)\\n    repeat = 0 \\n    for i, obs in enumerate(recent_obs[1:]):\\n        # if obs.startswith(\"This room is called\"):\\n        #     end_index = obs.index(\"In it\")\\n        #     obs = obs[:end_index]\\n        if obs.startswith(\"You move to the\") or obs.startswith(\"You go to the\") or obs.startswith(\"You teleport to the\"):\\n            obs = obs.replace(\"go to\", \"move to\").replace(\"teleport to\", \"move to\")\\n        if obs == \"The door is already open.\":\\n            continue\\n        # if obs.startswith(\"a substance called\"): \\n        if f\"In {recent_locs[i+1]}, {obs}\" in clean_obs:\\n            continue\\n        \\n        if recent_actions[i+1] in recent_actions[i+1-5:i+1] and recent_actions[i+1] in recent_actions[i+2:i+2+5]:\\n            repeat += 1\\n            continue\\n        if \"move to the\" in obs:\\n            clean_obs.append(f\"{obs}\")\\n        else:\\n            if version == \"lite\":\\n                clean_obs.append(f\"In {recent_locs[i+1]}, {obs}\")\\n            else:\\n                clean_obs.append(f\"In {recent_locs[i+1]}, {recent_actions[i+1]} --> {obs}\")\\n\\n        if repeat > 0: \\n            clean_obs.append(f\"Repeat the above {repeat} times.\")        \\n            repeat = 0\\n    final_obs = []\\n    for i, co in enumerate(clean_obs):\\n        if i+1 < len(clean_obs) and \"move to the\" in clean_obs[i] and \"move to the\" in clean_obs[i+1]:\\n            continue\\n        final_obs.append(co.replace(\"a substance called\", \"there is a\"))\\n    prev_obs = [f\"- {j+1}. {o}\" for j, o in enumerate(final_obs)]\\n\\n    \\n    prompt_to_plan  = []\\n\\n    prompt_to_plan.append(\"You are an experienced teacher who always guides students to complete the science experiments by giving executable advice and instructions with world knowledge.\")\\n\\n    prompt_to_plan.append(\"You have done a science experiment successfully and below is the action history of your experiment.\")\\n\\n    prompt_to_plan.append(\"Example task: \"+ demos[0][0])\\n    clean_actions = []\\n    for history in demos[0][1:]:\\n        if \"Action: \" not in history:\\n            continue\\n        start_ind = history.index(\"Action: \") + len(\"Action: \")\\n        end_ind = history.index(\" -->\")\\n        action = history[start_ind:end_ind]\\n        action = recover_action(action)\\n        if action is not None:\\n            clean_actions.append(history[:start_ind] + action + history[end_ind:])\\n    prompt_to_plan += clean_actions\\n\\n    prompt_to_plan.append(\"In a new science experiment that is similar to the above one, \" + task_desc.replace(\"Your\", \"my\")) \\n    prompt_to_plan.append(\"In this environment, there are a few rooms: art studio, workshop, kitchen, living room, bedroom, bathroom, foundry, greenhouse, outside, and a hallway connecting them.\")\\n    prompt_to_plan.append(\"To complete this task, I have done some actions and the observations are listed here:\")\\n    if version == \"lite\":\\n        prev_obs = prev_obs[-15:]\\n    prompt_to_plan += prev_obs\\n    # print(recent_looks)\\n    # print(recent_locs)\\n    if len(recent_looks) >= 2 and version != \"lite\":\\n        prompt_to_plan.append(\"In some previously visited locations:\")    \\n        for location, look_round in recent_looks.items():\\n            if location != recent_locs[-1]:\\n                prompt_to_plan.append(f\"In {location}: \" + clean_look(look_round, version=\"lite\"))\\n    prompt_to_plan.append(\"* Current location *: \" + clean_look(look)) # + look.replace(\" egg\", \" \").replace(\" adult \", \" \").replace(\" baby \", \" \")\\n    prompt_to_plan.append(inventory.replace(\"Your \", \"My \"))\\n    if useful_focus_on:\\n        prompt_to_plan.append(\"Importantly, I have FOCUS on these things already: \" + \", \".join([fo.replace(\"focus on\", \"\") for fo in  useful_focus_on]))\\n    else:\\n        prompt_to_plan.append(\"Importantly, I have FOCUS on nothing yet.\")\\n    # prompt_to_plan.append(\"However, my actions so far cannot complete the task. I do not know what to do for the next steps.\")\\n    prompt_to_plan.append(\"However, I do not know what to do for the next steps.\")\\n    if fast_action:\\n        prompt_to_plan.append(f\"My instinct tells me that it might be reasonable to {fast_action} now but I\\'m not so sure.\")\\n    if failed_messages:\\n        failed_messages = set(failed_messages)\\n        failed_messages = set(failed_messages)\\n        prompt_to_plan.append(\"There are some error messages about my previous actions:\")\\n        prompt_to_plan += failed_messages\\n    prompt_to_plan.append(\"Please review the task description and the previous observations and then answer the following questions to help me plan for efficiently completing the next subgoal.\")\\n    prompt_to_plan.append(\"Question 1: To efficiently complete the task, what substance and objects do I need to collect? Please list them and their possible locations one by one. Please ignore protective gears because I have them already.\")\\n    prompt_to_plan.append(\"Question 2: Based on your answer to Question 1, are there any substance or objects that are not in my inventory now and I should keep looking for?\" + \\\\\\n                          \" If so, which rooms are they likely to be? \" + \\\\\\n                          \"Note that some of your suggested items might not exist in the rooms. In that case, let\\'s try to use the similar ones in the environment.\" + \\\\\\n                          \" Note that I cannot do actions without them if they are not collected yet. \")\\n   \\n\\n    pattern = r\"focus on\\\\s+(\\\\b\\\\w+\\\\b(\\\\s+\\\\b\\\\w+\\\\b)*)\"\\n    matches = re.findall(pattern, task_desc)\\n    to_focus = [match[0].replace(\"the \", \" \").strip() for match in matches]\\n\\n    prompt_to_plan.append(\"Question 3: To most efficiently complete the task, what will be the important subgoals to finish? Please list up to five subgoals.\" + \\\\\\n                          f\" Importantly, please include the subgoals about \\'focus on\\' as required in the task description. Remember that it is ONLY possible focus on these items: {\\', \\'.join(to_focus)}! You should NOT focus on other things!! If you list a subgoal of focusing on, make sure that is mentioned and required by the task.\")\\n    prompt_to_plan.append(\"Question 4: In these subgoals, what have I already completed based on the previous observations? And which subgoals should I aim to do right now?\" + \\\\\\n                          \" These subgoals may need additional common knowledge to make decisions. Please recall the knowledge about the properties of objects or animals. Think step by step, and list the facts that are useful. And then use them for determining or comparing if needed. Finally, list the next subgoals based on the knowledge and current observations.\")\\n    prompt_to_plan.append(\"Question 5: Based on the observations, did I make any mistakes that prevent me from efficiently finishing the next subgoals? Did I forget to go to a location to pick up thing? Or did I forget to open/activate/move something? Did I repeat any actions too many times? If so, how should I fix it?\")\\n    prompt_to_plan.append(\"Please do not try to look for books or computers to look up information. You will need to use your own commonsense knowledge to make decisions (e.g., determining properties of objects and animals).\")\\n    prompt_to_plan.append(\"Please read the task description carefully, and think step by step to answer these questions one by one. Please be concise. Thank you very much.\")\\n    return \\'\\\\n\\'.join(prompt_to_plan)\\n',\n",
       "  'function_name': 'compose_prompt_to_plan',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def clean_history(recent_actions, recent_obs, recent_score, recent_reward, recent_locs):\\n    assert len(recent_actions) == len(recent_obs) == len(recent_score) == len(recent_reward) == len(recent_locs)\\n    N = len(recent_actions)\\n    inds_to_remove = []\\n    for ind in range(N):\\n        if recent_actions[ind].startswith(\"examine\"):\\n            inds_to_remove.append(ind)\\n        if recent_actions[ind].startswith(\"teleport to\") and recent_score[ind] >= 0:\\n            recent_actions[ind] = recent_actions[ind].replace(\"teleport\", \"go\")\\n            recent_obs[ind] = recent_obs[ind].replace(\"teleport\", \"go\")\\n        if recent_actions[ind].startswith(\"go to\") and recent_score[ind] < 0:\\n            recent_actions[ind] = recent_actions[ind].replace(\"go\", \"teleport\")\\n            recent_obs[ind] = recent_obs[ind].replace(\"go\", \"teleport\")\\n        if recent_actions[ind].startswith(\"open door\") and recent_score[ind] < 0:\\n            inds_to_remove.append(ind)\\n        if recent_actions[ind] in recent_actions[ind+1: min(ind+3, N)] and recent_score[ind] >= 0 :\\n            inds_to_remove.append(ind)\\n    \\n    recent_actions = [item for idx, item in enumerate(recent_actions) if idx not in inds_to_remove]\\n    recent_obs = [item for idx, item in enumerate(recent_obs) if idx not in inds_to_remove]\\n    recent_score = [item for idx, item in enumerate(recent_score) if idx not in inds_to_remove]\\n    recent_reward = [item for idx, item in enumerate(recent_reward) if idx not in inds_to_remove]\\n    recent_locs = [item for idx, item in enumerate(recent_locs) if idx not in inds_to_remove]\\n    return recent_actions, recent_obs, recent_score, recent_reward, recent_locs\\n\\n    ',\n",
       "  'function_name': 'clean_history',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def get_model_output(args, input_str, tokenizer, lm_model, device, logger): \\n    input_ids = tokenizer(input_str, return_tensors=\"pt\", max_length=args[\"max_input_len\"] , truncation=True).input_ids\\n\\n    sample_outputs = lm_model.generate(\\n        input_ids.to(device),\\n        max_length=16,\\n        num_return_sequences=args[\\'beams\\'],\\n        num_beams=args[\\'beams\\'],\\n    )\\n \\n    lm_pred = sample_outputs\\n\\n    # Take the first prediction that is not \"look around\"\\n    logger.info(\"Top N Predictions:\")\\n    predStrs = []\\n    for i, pred in enumerate(lm_pred):\\n        text = tokenizer.decode(pred)\\n        text = post_process_generation(text)\\n        logger.info(\"\\\\t\" + str(i) + \"\\\\t\" + str(text) )\\n        predStrs.append(text)\\n\\n    return predStrs\\n\\n',\n",
       "  'function_name': 'get_model_output',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def post_process_generation(raw_pred):\\n    ans_match = re.match(r\".*<extra_id_0>(.*)<extra_id_1>.*\", raw_pred)\\n    if ans_match is not None:\\n        result = ans_match.group(1)\\n    else:\\n        result = raw_pred\\n\\n    # remove extra <*>\\'s left in\\n    result = result.replace(\"<\", \" <\")\\n    out = \"\"\\n    for token in result.split(\" \"):\\n        if (len(token.strip()) > 0):\\n            if (token[0] != \"<\"):\\n                out += token + \" \"\\n    result = out\\n\\n    return result.strip()\\n\\n',\n",
       "  'function_name': 'post_process_generation',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def gpt_select_valid(action, candidates, look, inventory, goal, logger, n=1, gpt_version=\"gpt-4\", llm=None):\\n    prompt_to_search = []\\n    prompt_to_search.append(\"Let\\'s play a text game.\")\\n    prompt_to_search.append(clean_look(look, version=\"all\"))\\n    prompt_to_search.append(inventory)\\n    prompt_to_search.append(\"There are some action candidates as follows:\")\\n    for ac in candidates:\\n        prompt_to_search.append(f\"- {ac}\")\\n    prompt_to_search.append(f\"\\\\n I want to achieve this goal: {goal} but my action \\'{action}\\' is not in the candidate list.\")\\n    prompt_to_search.append(f\"Please consider the objects in the room and inventory and my goal. Think carefully, and then select the best replacement from the list. If no one in the list is a good replacement, return \\'none\\'.\")\\n    prompt_to_search.append(f\"Selected action:\") \\n\\n    prompt_to_search = \"\\\\n\".join(prompt_to_search)\\n    logger(\"-\"*30 + \"prompt_to_search\" + \"-\"*30)\\n    logger(\"\\\\n\"+prompt_to_search)\\n    logger(\"-\"*35 + \"-\"*35)\\n    if llm is None:\\n        responses = completion_with_backoff(model=gpt_version,\\n                messages=[{\"role\": \"user\", \"content\": prompt_to_search},  \\n                            ], n = n, temperature=0, top_p=1)\\n        # logger(responses)\\n        selections = [responses[\"choices\"][i][\"message\"][\"content\"] for i in range(n)]\\n    else:\\n        selections = local_llm.generate(prompt_to_search)\\n\\n    logger(\"\\\\n\" + \"Responses: \\\\n\" + \"\\\\n\".join(selections))\\n\\n    return selections  \\n\\n\\n\\n',\n",
       "  'function_name': 'gpt_select_valid',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': 'def rank_candidates_by_common_words(query, candidates):\\n    \"\"\"\\n    Rank the candidates based on their edit distance to the query.\\n    \"\"\"\\n\\n    # the first word must be the same \\n    candidates = [va for va in candidates if va.split()[0] == query.split()[0]]\\n    \\n    # Compute the edit distance between each candidate and the query\\n    num_commons = [len(set(query.split()) & set(candidate.split())) for candidate in candidates]\\n    \\n    # Sort the candidates based on their distance to the query\\n    ranked_candidates = [candidate for _, candidate in sorted(zip(num_commons, candidates), reverse=True)]\\n    \\n    return ranked_candidates\\n',\n",
       "  'function_name': 'rank_candidates_by_common_words',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval_utils.py'},\n",
       " {'code': \"def clean(s):\\n    clean_toks = ['\\\\n', '\\\\t']\\n    for tok in clean_toks:\\n        s = s.replace(tok, ' ')\\n    return s\\n\",\n",
       "  'function_name': 'clean',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\\n    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\\n    try:\\n        encoding = tiktoken.encoding_for_model(model)\\n    except KeyError:\\n        print(\"Warning: model not found. Using cl100k_base encoding.\")\\n        encoding = tiktoken.get_encoding(\"cl100k_base\")\\n    if model in {\\n        \"gpt-3.5-turbo-0613\",\\n        \"gpt-3.5-turbo-16k-0613\",\\n        \"gpt-4-0314\",\\n        \"gpt-4-32k-0314\",\\n        \"gpt-4-0613\",\\n        \"gpt-4-32k-0613\",\\n        }:\\n        tokens_per_message = 3\\n        tokens_per_name = 1\\n    elif model == \"gpt-3.5-turbo-0301\":\\n        tokens_per_message = 4  # every message follows <|start|>{role/name}\\\\n{content}<|end|>\\\\n\\n        tokens_per_name = -1  # if there\\'s a name, the role is omitted\\n    elif \"gpt-3.5-turbo\" in model:\\n        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\\n        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\\n    elif \"gpt-4\" in model:\\n        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\\n        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\\n    else:\\n        raise NotImplementedError(\\n            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\\n        )\\n    num_tokens = 0\\n    for message in messages:\\n        num_tokens += tokens_per_message\\n        for key, value in message.items():\\n            num_tokens += len(encoding.encode(value))\\n            if key == \"name\":\\n                num_tokens += tokens_per_name\\n    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\\n    return num_tokens\\n',\n",
       "  'function_name': 'num_tokens_from_messages',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def llm_gpt(prompt: List[Dict[str, str]], model: str) -> str:\\n    if not \\'OPENAI_API_KEY\\' in os.environ:\\n        raise ValueError(\"OPENAI_API_KEY must be set to eval GPT models.\")\\n\\n    for _ in range(3):\\n        try:\\n            openai_api_key = os.environ[\\'OPENAI_API_KEY\\']\\n            openai_api_base = os.environ.get(\\'OPENAI_API_BASE\\', \\'https://api.openai.com/v1\\')\\n            response = requests.post(\\n                openai_api_base + \"/chat/completions\",\\n                headers={\\n                    \\'Authorization\\': f\\'Bearer {openai_api_key}\\'\\n                },\\n                json={\\n                    \\'model\\': model,\\n                    \\'messages\\': prompt,\\n                    \\'temperature\\': 0.0,\\n                    \\'max_tokens\\': 256,\\n                },\\n                timeout=120,\\n            )\\n            text = response.json()[\\'choices\\'][0][\\'message\\'][\\'content\\']\\n            print(text)\\n            return text.strip()\\n        # if timeout or connection error, retry\\n        except Timeout: \\n            print(\"Timeout, retrying...\")\\n        except ConnectionError:\\n            print(\"Connection error, retrying...\")\\n        except Exception:\\n            traceback.print_exc()\\n            try:\\n                print(response)\\n                print(response.text)\\n            except:\\n                pass\\n        time.sleep(5)\\n    else:\\n        raise Exception(\"Timeout after 3 retries.\")\\n',\n",
       "  'function_name': 'llm_gpt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def llm_tgi(prompt: str) -> str:\\n    data = {\\n        \"inputs\": prompt,\\n        \"parameters\": {\\n            \"max_new_tokens\": 256,\\n            \"do_sample\": False,\\n            \\'truncate\\': 4000,\\n        }\\n    }\\n    for _ in range(3):\\n        try:\\n            url = random.choice(CONTROLLER_ADDR) + \"/generate\"\\n            print(f\\'Sending request to {url} ...\\')\\n            response = requests.post(\\n                url,\\n                json=data,\\n                timeout=120,\\n            )\\n            text = response.json()[\"generated_text\"]\\n            print(text)\\n            return text.split(\\'[INST]\\')[0].split(\\'<|end_of_turn|>\\')[0].strip()\\n        # if timeout or connection error, retry\\n        except Timeout: \\n            print(\"Timeout, retrying...\")\\n        except ConnectionError:\\n            print(\"Connection error, retrying...\")\\n        except Exception:\\n            traceback.print_exc()\\n            try:\\n                print(response)\\n                print(response.text)\\n            except:\\n                pass\\n        time.sleep(5)\\n    else:\\n        raise Exception(\"Timeout after 3 retries.\")\\n',\n",
       "  'function_name': 'llm_tgi',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def get_file_name(args, task_num):\\n    if (len(args[\"output_path\"]) > 0):\\n        args[\"output_path\"] = args[\"output_path\"] + \"/\"\\n\\n        # Make path if it doesn\\'t exist\\n        if (not os.path.exists(args[\\'output_path\\'])):\\n            try:\\n                os.makedirs(args[\"output_path\"])\\n            except:\\n                pass\\n\\n    # filenameOutPrefix = args[\"output_path\"] + \"transformer-\" + args[\"mode\"] + \"-eval-\" + str(args[\"lm_path\"].split(\\'/\\')[-1]) + \"-task\" + str(task_num)\\n    filenameOutPrefixSeed = args[\"output_path\"] + \"task\" + str(task_num)\\n\\n    return filenameOutPrefixSeed\\n  ',\n",
       "  'function_name': 'get_file_name',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def process_examples(conv: Conversation, example: List[str]):\\n    for i, ex in enumerate(example):\\n        conv.append_message(conv.roles[i % 2], ex)\\n',\n",
       "  'function_name': 'process_examples',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def get_prompt(conv: Conversation) -> str:\\n    if conv.name == \\'openchat\\':\\n        ret = \\'\\'\\n        for role, message in conv.messages:\\n            if message:\\n                ret += role + \": \" + message + conv.sep\\n            else:\\n                ret += role + \":\"\\n        return ret\\n    else:\\n        return conv.get_prompt()\\n',\n",
       "  'function_name': 'get_prompt',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def eval(args, task_num, logger):\\n\\n    # Initialize environment\\n    # env = ScienceWorldEnv(\"\", args[\"jar_path\"], envStepLimit = args[\"env_step_limit\"], threadNum = 0)\\n    env = ScienceWorldEnv(\"\", args[\"jar_path\"], envStepLimit = args[\"env_step_limit\"])\\n    taskNames = env.getTaskNames()\\n    taskName = taskNames[task_num]\\n    env.load(taskName, 0, args[\\'simplification_str\\'])\\n    variations = load_variation(env, args, task_num, logger)\\n    filenameOutPrefixSeed = get_file_name(args, task_num)\\n\\n    # Load init prompt\\n    with open(args[\"prompt_file\"], \\'r\\') as f:\\n        d = json.load(f)\\n    \\n    # Load encoding tool to count token numbers\\n    token_model = args[\"model_name\"] if \\'gpt\\' in args[\"model_name\"] else \\'gpt-4\\'\\n    encoding = tiktoken.encoding_for_model(token_model)\\n    # plans = get_plans(args)\\n\\n    scores = []\\n\\n    for variation in variations:\\n\\n        # train_data = []\\n        env.load(taskName, variation, args[\"simplification_str\"], generateGoldPath=True)\\n        task_description = env.taskdescription()[18:]\\n        recent_actions = [\"look around\"]\\n \\n        obs, info = env.reset()\\n\\n        done = False\\n        score = 0.0\\n        last_score = 0.0\\n        step = 0\\n\\n        # The env has an internal step count, some actions like look around are free\\n        # however, the t5 model only generates the action \"look around\", which will result in a dead loop below\\n        # so the max_steps here is only used to avoid the model generating the same action forever\\n        max_steps = args[\"env_step_limit\"] * 2\\n\\n\\n        if \\'gpt\\' in args[\"model_name\"]:\\n            conv = get_conversation_template(args[\"model_name\"])\\n            conv.set_system_message(\"You are a helpful, respectful and honest assistant.\")\\n        elif \\'openchat\\' in args[\"model_name\"]:\\n            conv = Conversation(\\n                name=\"openchat\",\\n                roles=(\"GPT4 User\", \"GPT4 Assistant\"),\\n                messages=[],\\n                offset=0,\\n                sep_style=SeparatorStyle.ADD_COLON_SINGLE,\\n                sep=\"<|end_of_turn|>\",\\n            )\\n        elif \\'vicuna\\' in args[\"model_name\"]:\\n            conv = get_conversation_template(\\'vicuna\\')\\n        elif \\'llama\\' in args[\"model_name\"]:\\n            conv = get_conversation_template(\\'llama-2\\')\\n            conv.set_system_message(\"You are a helpful, respectful and honest assistant.\")\\n        else:\\n            conv = get_conversation_template(args[\"model_name\"])\\n        \\n        conv.append_message(conv.roles[0], INIT_PROMPT)\\n        conv.append_message(conv.roles[1], \\'Ok.\\')\\n\\n        examples = d[str(task_num)]\\n        process_examples(conv, examples)\\n\\n        new_task = \\'The preceding task has ended. Now, I will start a new task.\\\\n\\' + clean(obs) + \\'\\\\n\\' + task_description\\n        conv.append_message(conv.roles[0], new_task.strip())\\n\\n        max_len = 4096\\n\\n        # Kill agent if it provides more than 10 consecutive invalid actions\\n        fail_counter = 0\\n\\n        while not done:\\n            # Cut the prompt to make it shorter than maximum token numbers\\n            while len(encoding.encode(get_prompt(conv))) > max_len - 60:\\n                # Remove the oldest actions in the few-shot\\n                del conv.messages[4:6]\\n                # Remove the few-shot if it is empty\\n                if conv.messages[4][1].startswith(\\'The preceding task has ended.\\'):\\n                    del conv.messages[2:4]\\n\\n            conv.append_message(conv.roles[1], None)\\n\\n            if \\'gpt\\' in args[\"model_name\"]:\\n                prompt = conv.to_openai_api_messages()\\n            else:\\n                prompt = get_prompt(conv)\\n            logger.info(\"###Prompt###\\\\n\" + prompt)\\n\\n            if \\'gpt\\' in args[\"model_name\"]:\\n                action = llm_gpt(prompt, args[\"model_name\"])\\n            else:\\n                action = llm_tgi(prompt)\\n            logger.info(\\'###Response###\\\\n\\' + action)\\n\\n            conv.update_last_message(action)\\n\\n            # Don\\'t need to actually do think actions\\n            if action.startswith(\\'Think:\\'):\\n                obs = \\'OK.\\'\\n            else:\\n                action = action.replace(\\'Action:\\', \\'\\').strip()\\n                # Get valid actions at this point\\n                action = findValidActionNew([action], env, info[\\'look\\'], recent_actions, None, logger)\\n                obs, _reward, done, info = env.step(action)\\n\\n                if is_action_failed(obs):\\n                    fail_counter += 1\\n                    if fail_counter >= 10:\\n                        logger.info(\\'Early stop due to consecutive invalid actions\\')\\n                        break\\n                else:\\n                    fail_counter = 0\\n\\n                score = info[\\'score\\']\\n\\n                if score < 0:\\n                    # Our own solution for dealing with such cases\\n                    if args[\"no_stop\"]:\\n                        done = True\\n                        score = last_score\\n                    else:\\n                        done = True\\n                        score = 0\\n                last_score = score\\n            \\n            obs = clean(obs)\\n            print(obs)\\n\\n            # Add action and observation to game prompt\\n            conv.append_message(conv.roles[0], obs)\\n            \\n            recent_actions.append(f\\'({action}, {obs})\\')\\n            \\n            #logger.info(\"Input string: \" + str(input_str))\\n            logger.info(f\"Variation: {variation}, Step: {step}, Action: {action}\")\\n            logger.info(\"Obs: \" + obs)\\n            logger.info(f\"Score: {score}\")\\n            logger.info(\"\")\\n\\n            step += 1\\n            if (step >= max_steps) or done:\\n                break\\n  \\n\\n            logger.info(\"Recent Actions: \" + str(recent_actions))\\n\\n            # Early stopping if we\\'re in a loop\\n            if len(recent_actions) >= 5 and len(set(recent_actions[-5:])) == 2:\\n                logger.info(\"Many recent actions in history are the same -- model is likely in a loop, stopping early.\")\\n                break\\n\\n\\n        # Store results\\n        env.storeRunHistory(variation, notes = {\\'mode\\':\"react_baseline\", \\'lm\\': None} )\\n        env.saveRunHistoriesBufferIfFull(filenameOutPrefixSeed, maxPerFile=args[\"max_episode_per_file\"])\\n\\n        scores.append(score)\\n\\n        logger.info(\"Run completed...\")\\n        logger.info(\"Scores: \" + str(scores))\\n \\n        time.sleep(2)\\n\\n    # Episodes are finished -- manually save any last histories still in the buffer\\n    env.saveRunHistoriesBufferIfFull(filenameOutPrefixSeed, maxPerFile=args[\"max_episode_per_file\"], forceSave=True)\\n\\n    avg = sum(scores) / len(scores)\\n    logger.info(\"Average score: \" + str(avg))\\n\\n    f = open(filenameOutPrefixSeed + \"-score.txt\", \"a\")\\n    f.write(\"\\\\n\" + \"Task name:\" + taskName + \"Scores: \" + str(scores) + \" Average score: \" + str(avg) + \" Args: \" + str(args) + \"\\\\n\")\\n    f.close()\\n\\n    logger.info(\"Shutting down server...\")\\n    # env.shutdown()\\n\\n    logger.info(\"Completed.\")\\n\\n\\n',\n",
       "  'function_name': 'eval',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def parse_args():\\n    parser = argparse.ArgumentParser()\\n    parser.add_argument(\"--jar_path\", type=str, default=\"\") \\n    parser.add_argument(\"--task_nums\", default=\"0\")  # use comma to split \\n    parser.add_argument(\"--env_step_limit\", type=int, default=100)\\n    parser.add_argument(\"--simplification_str\", default=\"easy\")\\n    parser.add_argument(\"--max_episode_per_file\", type=int, default=9999)\\n    parser.add_argument(\"--set\", default=\"test\")\\n    parser.add_argument(\"--output_path\", default=\"\")\\n    parser.add_argument(\"--no_stop\", action=\"store_true\", default=True)\\n    parser.add_argument(\"--prompt_file\", default=\"prompts/prompt.json\")\\n    parser.add_argument(\"--model_name\", default=\"gpt-4\")\\n\\n    args = parser.parse_args()\\n    params = vars(args)\\n    return params\\n',\n",
       "  'function_name': 'parse_args',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def init_logger(args, task_num, log_level=INFO):\\n    filenameOutPrefixSeed = get_file_name(args, task_num)\\n    logger = logging.getLogger()\\n    formatter = logging.Formatter(\"[%(asctime)s][%(levelname)s\\\\t] %(message)s\",\\n                                    datefmt=\\'%Y-%m-%d %H:%M:%S\\')\\n    logger.setLevel(log_level)\\n\\n    ch = logging.StreamHandler()\\n    ch.setLevel(log_level)\\n    ch.setFormatter(formatter)\\n    logger.addHandler(ch)\\n    logging_dir = args[\"output_path\"]\\n    if logging_dir:\\n        os.makedirs(logging_dir, exist_ok=True)\\n        filename = f\"{filenameOutPrefixSeed}.log\"\\n        fh = logging.FileHandler(filename)\\n        fh.setLevel(log_level)\\n        fh.setFormatter(formatter)\\n        if logger.hasHandlers():\\n            logger.handlers.clear()\\n        logger.addHandler(fh)\\n    return logger\\n',\n",
       "  'function_name': 'init_logger',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def main():\\n    args = parse_args()\\n    print(args) \\n\\n    task_nums = args[\"task_nums\"].split(\",\")\\n    for task_num in task_nums:\\n        logger = init_logger(args, task_num)\\n        logger.info(args)\\n        eval(args, int(task_num), logger)\\n        ',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/eval.py'},\n",
       " {'code': 'def main():\\n    parser = HfArgumentParser((ModelArguments, DataTrainingArguments, Seq2SeqTrainingArguments))\\n    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\\n\\n    # Setup logging\\n    logging.basicConfig(\\n        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\\n        datefmt=\"%m/%d/%Y %H:%M:%S\",\\n        handlers=[logging.StreamHandler(sys.stdout)],\\n    )\\n\\n    log_level = training_args.get_process_log_level()\\n    logger.setLevel(log_level)\\n    transformers.utils.logging.set_verbosity(log_level)\\n    transformers.utils.logging.enable_default_handler()\\n    transformers.utils.logging.enable_explicit_format()\\n\\n    # Log on each process the small summary:\\n    logger.warning(\\n        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu} \"\\n        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16} \"\\n        + f\"bf16-bits training: {training_args.bf16}\"\\n    )\\n    logger.info(f\"Training/evaluation parameters {training_args}\")\\n\\n    # Detecting last checkpoint.\\n    last_checkpoint = None\\n    if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\\n        last_checkpoint = get_last_checkpoint(training_args.output_dir)\\n        if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\\n            raise ValueError(\\n                f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\\n                \"Use --overwrite_output_dir to overcome.\"\\n            )\\n        elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\\n            logger.info(\\n                f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\\n                \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\\n            )\\n\\n    # Set seed before initializing model.\\n    set_seed(training_args.seed)\\n\\n    data_files = {}\\n    if data_args.train_file is not None:\\n        data_files[\"train\"] = data_args.train_file\\n    if data_args.validation_file is not None:\\n        data_files[\"validation\"] = data_args.validation_file\\n    if data_args.test_file is not None:\\n        data_files[\"test\"] = data_args.test_file\\n    print(data_files, data_args.test_file)\\n    raw_datasets = load_dataset(\\'json\\', data_files=data_files)\\n\\n    config = AutoConfig.from_pretrained(\\n        model_args.model_name_or_path,\\n        cache_dir=model_args.cache_dir\\n    )\\n    tokenizer = AutoTokenizer.from_pretrained(\\n        model_args.model_name_or_path,\\n        use_fast=True,\\n        cache_dir=model_args.cache_dir\\n    )\\n    model = AutoModelForSeq2SeqLM.from_pretrained(\\n        model_args.model_name_or_path,\\n        from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\\n        config=config,\\n        cache_dir=model_args.cache_dir\\n    )\\n\\n    model.resize_token_embeddings(len(tokenizer))\\n \\n    # if model_args.DualEncoder:\\n    #     DualEncoder_model = DualEncoderT5(model.config)\\n    #     DualEncoder_model.load_t5(model.state_dict())\\n    #     model = DualEncoder_model\\n        \\n    prefix = data_args.source_prefix if data_args.source_prefix is not None else \"\"\\n\\n    # Preprocessing the datasets.\\n    # We need to tokenize inputs and targets.\\n    if training_args.do_train:\\n        column_names = raw_datasets[\"train\"].column_names\\n    elif training_args.do_eval:\\n        column_names = raw_datasets[\"validation\"].column_names\\n    elif training_args.do_predict:\\n        column_names = raw_datasets[\"test\"].column_names\\n    else:\\n        logger.info(\"There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.\")\\n        return\\n\\n    # Temporarily set max_target_length for training.\\n    max_target_length = data_args.max_target_length\\n    padding = False\\n\\n    if training_args.label_smoothing_factor > 0 and not hasattr(model, \"prepare_decoder_input_ids_from_labels\"):\\n        logger.warning(\\n            \"label_smoothing is enabled but the `prepare_decoder_input_ids_from_labels` method is not defined for\"\\n            f\"`{model.__class__.__name__}`. This will lead to loss being calculated twice and will take up more memory\"\\n        )\\n \\n    \\n    def preprocess_function_original(examples):\\n        inputs = [ex for ex in examples[\\'input\\']]\\n        targets = [ex for ex in examples[\\'target\\']]\\n        inputs = [prefix + inp for inp in inputs]\\n        model_inputs = tokenizer(inputs, max_length=data_args.max_source_length, padding=padding, truncation=True)\\n        \\n        with tokenizer.as_target_tokenizer():\\n            labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\\n\\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\\n        return model_inputs\\n    \\n\\n    preprocess_function = preprocess_function_original\\n\\n    if training_args.do_train:\\n        if \"train\" not in raw_datasets:\\n            raise ValueError(\"--do_train requires a train dataset\")\\n        train_dataset = raw_datasets[\"train\"]\\n        if data_args.max_train_samples is not None:\\n            train_dataset = train_dataset.select(range(data_args.max_train_samples))\\n        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\\n            train_dataset = train_dataset.map(\\n                preprocess_function,\\n                batched=True,\\n                num_proc=data_args.preprocessing_num_workers,\\n                remove_columns=column_names,\\n                load_from_cache_file=not data_args.overwrite_cache,\\n                desc=\"Running tokenizer on train dataset\",\\n            )\\n\\n    if training_args.do_eval:\\n        max_target_length = data_args.val_max_target_length\\n        if \"validation\" not in raw_datasets:\\n            raise ValueError(\"--do_eval requires a validation dataset\")\\n        eval_dataset = raw_datasets[\"validation\"]\\n        if data_args.max_eval_samples is not None:\\n            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\\n        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\\n            eval_dataset = eval_dataset.map(\\n                preprocess_function,\\n                batched=True,\\n                num_proc=data_args.preprocessing_num_workers,\\n                remove_columns=column_names,\\n                load_from_cache_file=not data_args.overwrite_cache,\\n                desc=\"Running tokenizer on validation dataset\",\\n            )\\n\\n    if training_args.do_predict:\\n        max_target_length = data_args.val_max_target_length\\n        if \"test\" not in raw_datasets:\\n            raise ValueError(\"--do_predict requires a test dataset\")\\n        predict_dataset = raw_datasets[\"test\"]\\n        if data_args.max_predict_samples is not None:\\n            max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\\n            predict_dataset = predict_dataset.select(range(max_predict_samples))\\n        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\\n            predict_dataset = predict_dataset.map(\\n                preprocess_function,\\n                batched=True,\\n                num_proc=data_args.preprocessing_num_workers,\\n                remove_columns=column_names,\\n                load_from_cache_file=not data_args.overwrite_cache,\\n                desc=\"Running tokenizer on prediction dataset\",\\n            )\\n    # Data collator\\n    label_pad_token_id = -100 if data_args.ignore_pad_token_for_loss else tokenizer.pad_token_id\\n\\n    \\n    data_collator = DataCollatorForSeq2Seq(\\n        tokenizer,\\n        model=model,\\n        label_pad_token_id=label_pad_token_id,\\n        pad_to_multiple_of=8 if training_args.fp16 else None,\\n    )\\n\\n    # Metric\\n    metric = load_metric(\"sacrebleu\")\\n\\n    def postprocess_text(preds, labels):\\n        preds = [pred.strip() for pred in preds]\\n        labels = [[label.strip()] for label in labels]\\n\\n        return preds, labels\\n\\n    def compute_metrics(eval_preds):\\n        preds, labels = eval_preds\\n        if isinstance(preds, tuple):\\n            preds = preds[0]\\n        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\\n        if data_args.ignore_pad_token_for_loss:\\n            # Replace -100 in the labels as we can\\'t decode them.\\n            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\\n        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=False)\\n        # print(\\'AAAA\\', decoded_labels)\\n        # Some simple post-processing\\n        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\\n        # print(decoded_preds, decoded_labels, labels)\\n        result = metric.compute(predictions=decoded_preds, references=decoded_labels)\\n        result = {\"bleu\": result[\"score\"]}\\n\\n        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\\n        result[\"gen_len\"] = np.mean(prediction_lens)\\n        result[\"exact_match\"] = np.mean(\\n            [decoded_preds[idx] == decoded_labels[idx][0] for idx in range(len(decoded_preds))])\\n        result = {k: round(v, 4) for k, v in result.items()}\\n        return result\\n\\n    # Initialize our Trainer\\n\\n    trainer = Seq2SeqTrainer(\\n        model=model,\\n        args=training_args,\\n        train_dataset=train_dataset if training_args.do_train else None,\\n        eval_dataset=eval_dataset if training_args.do_eval else None,\\n        tokenizer=tokenizer,\\n        data_collator=data_collator,\\n        compute_metrics=compute_metrics if training_args.predict_with_generate else None,\\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=model_args.early_stopping_patience)],\\n    )\\n\\n    # Training\\n    if training_args.do_train:\\n        checkpoint = None\\n        if training_args.resume_from_checkpoint is not None:\\n            checkpoint = training_args.resume_from_checkpoint\\n        elif last_checkpoint is not None:\\n            checkpoint = last_checkpoint\\n        train_result = trainer.train(resume_from_checkpoint=checkpoint)\\n        trainer.save_model()  # Saves the tokenizer too for easy upload\\n\\n        metrics = train_result.metrics\\n        max_train_samples = (\\n            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\\n        )\\n        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\\n\\n        trainer.log_metrics(\"train\", metrics)\\n        trainer.save_metrics(\"train\", metrics)\\n        trainer.save_state()\\n\\n    results = {}\\n    max_length = (\\n        training_args.generation_max_length\\n        if training_args.generation_max_length is not None\\n        else data_args.val_max_target_length\\n    )\\n    num_beams = training_args.generation_num_beams\\n    if training_args.do_eval:\\n        logger.info(\"*** Evaluate ***\")\\n        metrics = trainer.evaluate(max_length=max_length, num_beams=num_beams, metric_key_prefix=\"eval\")\\n        max_eval_samples = data_args.max_eval_samples if data_args.max_eval_samples is not None else len(eval_dataset)\\n        metrics[\"eval_samples\"] = min(max_eval_samples, len(eval_dataset))\\n\\n        trainer.log_metrics(\"eval\", metrics)\\n        trainer.save_metrics(\"eval\", metrics)\\n\\n    if training_args.do_predict:\\n        logger.info(\"*** Predict ***\")\\n\\n        predict_results = trainer.predict(\\n            predict_dataset, metric_key_prefix=\"predict\", max_length=max_length, num_beams=num_beams\\n        )\\n        metrics = predict_results.metrics\\n        max_predict_samples = (\\n            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\\n        )\\n        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\\n\\n        trainer.log_metrics(\"predict\", metrics)\\n        trainer.save_metrics(\"predict\", metrics)\\n\\n        if training_args.predict_with_generate:\\n            predictions = tokenizer.batch_decode(\\n                    predict_results.predictions, skip_special_tokens=False, clean_up_tokenization_spaces=True\\n                )\\n            predictions = [pred.strip() for pred in predictions]\\n            output_prediction_file = os.path.join(training_args.output_dir, \"generated_predictions.txt\")\\n            #print(predictions)\\n            with open(output_prediction_file, \"w\") as writer:\\n                writer.write(\"\\\\n\".join(predictions))\\n',\n",
       "  'function_name': 'main',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/fast_agent/ds_train.py'},\n",
       " {'code': 'def _mp_fn(index):\\n    # For xla_spawn (TPUs)\\n    main()\\n\\n',\n",
       "  'function_name': '_mp_fn',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/fast_agent/ds_train.py'},\n",
       " {'code': 'def completion_with_backoff(**kwargs):\\n    return openai.ChatCompletion.create(**kwargs) \\n\\n\\n    triplets_by_task = load_triplets()\\n    prompt = sample_few_shot(triplets_by_task, \"0\")\\n    print(prompt)',\n",
       "  'function_name': 'completion_with_backoff',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/slow_agent/utils.py'},\n",
       " {'code': 'def load(model_name=\"xgen\"):\\n    global llm_model, llm_tokenizer\\n    if model_name == \"xgen\":\\n        model_name = \"Salesforce/xgen-7b-8k-inst\"\\n        llm_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\\n        llm_model = AutoModelForCausalLM.from_pretrained(\\n            model_name, device_map=\"auto\", torch_dtype=torch.bfloat16\\n        ).cuda()\\n    elif model_name == \"mpt\":\\n        model_name = \"mosaicml/mpt-30b-instruct\"\\n        llm_tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\\n        llm_model = AutoModelForCausalLM.from_pretrained(\\n            model_name, torch_dtype=torch.bfloat16\\n        ).cuda()\\n    if torch.cuda.is_available():\\n        llm_model = llm_model.to(\"cuda:0\")\\n    print(\"model device:\", llm_model.device)\\n\\n',\n",
       "  'function_name': 'load',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/slow_agent/local_llm.py'},\n",
       " {'code': 'def generate(sage_input, logger=print):\\n    header = (\\n        \"A chat between a human and an artificial intelligence assistant. \"\\n        \"The assistant gives helpful and detailed answers to the human\\'s questions.\\\\n\\\\n\"\\n    )\\n\\n    prompt = \"### Human: \"\\n\\n    all_input = header + sage_input.replace(\\n        \"Please review the task description\",\\n        \"### Human: Please review the task description\",\\n    ).replace(\\n        \"Please use the above mentioned action\",\\n        \"### Human: Please use the above mentioned action\",\\n    )\\n\\n    inputs = llm_tokenizer(all_input, return_tensors=\"pt\")\\n    cnt = 0 \\n    while True:\\n        sample = llm_model.generate(\\n            input_ids=inputs[\"input_ids\"].to(llm_model.device),\\n            attention_mask=inputs[\"attention_mask\"].to(llm_model.device),\\n            do_sample=True,\\n            max_new_tokens=2048,\\n            top_k=100,\\n            temperature=0.8,\\n            eos_token_id=50256,\\n        )\\n        output = llm_tokenizer.decode(sample[0])\\n        cnt += 1\\n        prefix = \"### Assistant:\"\\n\\n        if prefix in output:\\n            output = output[output.index(prefix) + len(prefix) :]\\n            if \"Question 5:\" in output or \"Action 1: \" in output:\\n                break\\n        if sage_input.startswith(\"Hello, who are you?\"):\\n            break \\n        logger(f\"Count: {cnt}\")\\n    result = output.strip().replace(\"<|endoftext|>\", \"---\")\\n    return result\\n\\n',\n",
       "  'function_name': 'generate',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/slow_agent/local_llm.py'},\n",
       " {'code': 'def greet(all_input):\\n    header = (\\n    \"A chat between a curious human and an artificial intelligence assistant. \"\\n    \"The assistant gives helpful, detailed, and polite answers to the human\\'s questions.\\\\n\\\\n\"\\n    )\\n\\n    prompt = \"### Human: \"\\n\\n    inputs = tokenizer(header + prompt + all_input, return_tensors=\"pt\")\\n\\n    sample = model.generate(input_ids=inputs[\\'input_ids\\'].to(model.device), \\n                            attention_mask=inputs[\\'attention_mask\\'].to(model.device),\\n                            do_sample=True, max_new_tokens=2048, top_k=100, eos_token_id=50256)\\n    output = tokenizer.decode(sample[0])\\n    prefix = \"### Assistant:\"\\n    result  = output[output.strip().index(prefix)+len(prefix):]\\n    return result\\n',\n",
       "  'function_name': 'greet',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/slow_agent/run_gradio.py'},\n",
       " {'code': 'def get_real_task_id(task_name):\\n    task_name = task_name.replace(\"mendelian\", \"mendellian\")\\n    task_table = {\\n        \\'boil\\': \\'1-1\\',\\n        \\'melt\\': \\'1-2\\',\\n        \\'freeze\\': \\'1-3\\',\\n        \\'change-the-state-of-matter-of\\': \\'1-4\\',\\n        \\'use-thermometer\\': \\'2-1\\',\\n        \\'measure-melting-point-known-substance\\': \\'2-2\\',\\n        \\'measure-melting-point-unknown-substance\\': \\'2-3\\',\\n        \\'power-component\\': \\'3-1\\',\\n        \\'power-component-renewable-vs-nonrenewable-energy\\': \\'3-2\\',\\n        \\'test-conductivity\\': \\'3-3\\',\\n        \\'test-conductivity-of-unknown-substances\\': \\'3-4\\',\\n        \\'find-living-thing\\': \\'4-1\\',\\n        \\'find-non-living-thing\\': \\'4-2\\',\\n        \\'find-plant\\': \\'4-3\\',\\n        \\'find-animal\\': \\'4-4\\',\\n        \\'grow-plant\\': \\'5-1\\',\\n        \\'grow-fruit\\': \\'5-2\\',\\n        \\'chemistry-mix\\': \\'6-1\\',\\n        \\'chemistry-mix-paint-secondary-color\\': \\'6-2\\',\\n        \\'chemistry-mix-paint-tertiary-color\\': \\'6-3\\',\\n        \\'lifespan-longest-lived\\': \\'7-1\\',\\n        \\'lifespan-shortest-lived\\': \\'7-2\\',\\n        \\'lifespan-longest-lived-then-shortest-lived\\': \\'7-3\\',\\n        \\'identify-life-stages-1\\': \\'8-1\\',\\n        \\'identify-life-stages-2\\': \\'8-2\\',\\n        \\'inclined-plane-determine-angle\\': \\'9-1\\',\\n        \\'inclined-plane-friction-named-surfaces\\': \\'9-2\\',\\n        \\'inclined-plane-friction-unnamed-surfaces\\': \\'9-3\\',\\n        \\'mendellian-genetics-known-plant\\': \\'10-1\\',\\n        \\'mendellian-genetics-unknown-plant\\': \\'10-2\\'\\n    }\\n    return task_table.get(task_name)\\n\\n',\n",
       "  'function_name': 'get_real_task_id',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def sanitizeStr(inStr):\\n    if inStr is None:\\n        return inStr\\n    out = inStr.replace(\"\\\\n\\\\t\", \" | \")\\n    out = out.replace(\"\\\\n\", \" | \")\\n    out = out.replace(\"\\\\t\", \" | \")\\n    out = out.replace(\"green house\", \"greenhouse\")\\n    return out\\n\\n\\n',\n",
       "  'function_name': 'sanitizeStr',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': \"def clean(s):\\n    clean_toks = ['\\\\n', '\\\\t']\\n    for tok in clean_toks:\\n        s = s.replace(tok, ' ')\\n    return s\\n\",\n",
       "  'function_name': 'clean',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': \"def downsampling(task_idx_real, curr_task_seq):\\n    # Downsampling Task 26 and 29\\n    if task_idx_real.startswith('9-'):\\n        random.seed(1)\\n        random.shuffle(curr_task_seq)\\n        curr_task_seq = curr_task_seq[:50]\\n    elif task_idx_real.startswith('10-'):\\n        random.seed(1)\\n        random.shuffle(curr_task_seq)\\n        curr_task_seq = curr_task_seq[:50]\\n    elif task_idx_real.startswith('3-3'):\\n        random.seed(1)\\n        random.shuffle(curr_task_seq)\\n        curr_task_seq = curr_task_seq[:100]\\n    return curr_task_seq\\n\",\n",
       "  'function_name': 'downsampling',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def add_current_place(curr_obs, look, places):\\n    # Extract current place\\n    index = curr_obs.find(\"move to the\")\\n    if index != -1:\\n        place = curr_obs[index + 12: -1].strip()\\n        if place not in places:\\n            places.append(place)\\n    \\n    # Extract the first room the where the agent is \\n    start = look.find(\"This room is called the\")\\n    end = look.find(\".\")    \\n    if start != -1:\\n        if look[start + 24 : end] not in places:\\n            places.append(look[start + 24 : end])\\n    return\\n\\n',\n",
       "  'function_name': 'add_current_place',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': \"def add_current_objects(task_id, look, objects, limit=20):\\n    # if task_id in ['24', '28', '29']:\\n    if True:\\n        things = re.findall(r'a .*?\\\\n', look.replace(',', '\\\\n').replace(\\n            '.', '\\\\n').replace('(', '\\\\n').replace(')', ' ').replace(' an ', ' a '), re.I)\\n    else:\\n        things = re.findall(r'a .*?\\\\n', look.replace(',',\\n                            '\\\\n').replace('.', '\\\\n').replace(' an ', ' a '), re.I)\\n    # things = re.findall(r'a .*?\\\\n', look, re.I)\\n\\n    flag = 0\\n    for thing in things:\\n        if 'door' in thing:\\n            continue\\n\\n        if ('(' in thing) and (')' not in thing):\\n            start = things.index(thing)\\n            flag = 1\\n\\n        if (')' in thing) and ('(' not in thing):\\n            end = things.index(thing)\\n            thing = 'and '.join(things[start: end + 1])\\n            flag = 0\\n\\n        if flag:\\n            continue\\n\\n        if clean(thing).strip().strip('.') not in objects:\\n            objects.append(clean(thing).strip().strip('.'))\\n\\n    while len(objects) > limit:  # recent seen objects, only keep M = 20\\n        objects.pop(0)\\n    return\\n\\n\\n\",\n",
       "  'function_name': 'add_current_objects',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v5(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    assert mode == \"fast_system\"\\n    label = curr_action\\n\\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}; Score: {int(recent_scores[-1]*100)}; </s> \"\\n    \\n    # if returns_to_go != None :\\n    #     input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    # input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    # input_str += \"The previous observation: \" + prev_obs + \\' </s> \\' \\n\\n    # if curr_obs.strip() != look.strip():  \\n    #     input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    # else:\\n    #     input_str += \\'Current observation: the same as current environment. </s> \\'\\n    \\n    # if recent_actions:\\n    #     input_str += \"Recent actions: \" + \", \".join(recent_actions) + \\' </s> \\'     \\n    input_str += \"Action history: </s>\" \\n    ind = 10\\n    for obs, action, reward in zip(recent_obs[-10:], recent_actions[-10:], recent_reward[-10:]):\\n        input_str += f\" <extra_id_{ind}> {formalize_action(action)} (+{int(reward*100)}) --> {obs} | \"\\n        ind -= 1\\n    input_str += \" </s> \" \\n\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    if places:\\n        input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    # current_objs = []\\n    # add_current_objects(task_id=-1, look=look, objects=current_objs, limit=20)\\n    # if current_objs:\\n    #     input_str += \"Seen current_objs: \" + \", \".join(current_objs) + \\' </s> \\'\\n        \\n    input_str += \\' What action should you do next? </s> \\'\\n    \\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    if label != None:\\n        action_formatted = formalize_action(sanitizeStr(label))\\n        if action_formatted == None:\\n            print(label)\\n            raise Exception\\n    else:\\n        action_formatted = None \\n    return input_str, action_formatted\\n',\n",
       "  'function_name': 'compose_instance_v5',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v4(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    assert mode == \"fast_system\"\\n    label = curr_action\\n\\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}; Score: {int(recent_scores[-1]*100)}; </s> \"\\n    \\n    # if returns_to_go != None :\\n    #     input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    # input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    # input_str += \"The previous observation: \" + prev_obs + \\' </s> \\' \\n\\n    # if curr_obs.strip() != look.strip():  \\n    #     input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    # else:\\n    #     input_str += \\'Current observation: the same as current environment. </s> \\'\\n    \\n    # if recent_actions:\\n    #     input_str += \"Recent actions: \" + \", \".join(recent_actions) + \\' </s> \\'     \\n    input_str += \"Action history: </s>\" \\n    ind = 10\\n    for obs, action, reward in zip(recent_obs[-10:], recent_actions[-10:], recent_reward[-10:]):\\n        input_str += f\" <extra_id_{ind}> {action} (+{int(reward*100)}) --> {obs} | \"\\n        ind -= 1\\n    input_str += \" </s> \" \\n\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    if places:\\n        input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    # current_objs = []\\n    # add_current_objects(task_id=-1, look=look, objects=current_objs, limit=20)\\n    # if current_objs:\\n    #     input_str += \"Seen current_objs: \" + \", \".join(current_objs) + \\' </s> \\'\\n        \\n    input_str += \\' What action should you do next? </s> \\'\\n    \\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    label = sanitizeStr(label)\\n    return input_str, label\\n\\n',\n",
       "  'function_name': 'compose_instance_v4',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v3(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    assert mode == \"fast_system\"\\n    label = curr_action\\n\\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}; Score: {int(recent_scores[-1]*100)}; </s> \"\\n    \\n    # if returns_to_go != None :\\n    #     input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    # input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    # input_str += \"The previous observation: \" + prev_obs + \\' </s> \\' \\n\\n    # if curr_obs.strip() != look.strip():  \\n    #     input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    # else:\\n    #     input_str += \\'Current observation: the same as current environment. </s> \\'\\n    \\n    # if recent_actions:\\n    #     input_str += \"Recent actions: \" + \", \".join(recent_actions) + \\' </s> \\'     \\n    assert len(recent_obs) >= 1\\n    input_str += \"Action history: </s>\" \\n    ind = 10\\n    for obs, action, reward in zip(recent_obs[-5:], recent_actions[-5:], recent_reward[-5:]):\\n        input_str += f\" <extra_id_{ind}> {action} (+{int(reward*100)}) --> {obs} | \"\\n        ind -= 1\\n    input_str += \" </s> \" \\n\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    if places:\\n        input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    if objects:\\n        input_str += \"Seen objects: \" + \", \".join(objects) + \\' </s> \\'\\n        \\n    input_str += \\' What action should you do next? </s> \\'\\n    \\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    label = sanitizeStr(label)\\n    return input_str, label\\n\\n',\n",
       "  'function_name': 'compose_instance_v3',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v2(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    assert mode == \"fast_system\"\\n    label = curr_action\\n\\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}; Score: {int(recent_scores[-1]*100)}; </s> \"\\n    \\n    # if returns_to_go != None :\\n    #     input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    # input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    # input_str += \"The previous observation: \" + prev_obs + \\' </s> \\' \\n\\n    # if curr_obs.strip() != look.strip():  \\n    #     input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    # else:\\n    #     input_str += \\'Current observation: the same as current environment. </s> \\'\\n    \\n    # if recent_actions:\\n    #     input_str += \"Recent actions: \" + \", \".join(recent_actions) + \\' </s> \\'     \\n    assert len(recent_obs) >= 1\\n    input_str += \"Recent actions: \" \\n    ind = 10\\n    for obs, action, reward in zip(recent_obs[-10:], recent_actions[-10:], recent_reward[-10:]):\\n        input_str += f\"<extra_id_{ind}> {action} (+{int(reward*100)}) | \"\\n        ind -= 1\\n    input_str += \" </s> \" \\n\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    # if places:\\n    #     input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    if objects:\\n        input_str += \"Seen objects: \" + \", \".join(objects) + \\' </s> \\'\\n        \\n    input_str += \\' What action should you do next? </s> \\'\\n    \\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    label = sanitizeStr(label)\\n    return input_str, label\\n\\n',\n",
       "  'function_name': 'compose_instance_v2',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v1(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    if mode == \"bc\":\\n        returns_to_go = None \\n        objects, places,recent_actions = None, None, None \\n    elif mode == \"dt\":\\n        objects, places, recent_actions = None, None, None \\n    elif mode == \"dt_recent_actions\":\\n        objects, places = None, None \\n    elif mode == \"dt_seen_objects\":\\n        recent_actions = None \\n    elif mode == \"fast_system\":\\n        returns_to_go = None \\n\\n    label = curr_action\\n       \\n    \\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}  </s> \"\\n    \\n    if returns_to_go != None :\\n        input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    input_str += \"The previous observation: \" + prev_obs + \\' </s> \\' \\n    if curr_obs.strip() != look.strip():  \\n        input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    else:\\n        input_str += \\'Current observation: the same as current environment. </s> \\'\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    if places:\\n        input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    if objects:\\n        input_str += \"Seen objects: \" + \", \".join(objects) + \\' </s> \\'\\n        \\n    input_str += \\' </s> \\'\\n    if recent_actions:\\n        input_str += \"Recent actions: \" + \", \".join(recent_actions) + \\' </s> \\'         \\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    label = sanitizeStr(label)\\n    return input_str, label\\n\\n\\n',\n",
       "  'function_name': 'compose_instance_v1',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def compose_instance_v1_1(mode, step_id, task_desc, returns_to_go, curr_action,\\n                     curr_obs, inventory, look, prev_action, prev_obs, \\n                     objects, places, recent_actions, recent_obs, recent_scores, recent_reward):\\n\\n    if mode == \"bc\":\\n        returns_to_go = None \\n        objects, places,recent_actions = None, None, None \\n    elif mode == \"dt\":\\n        objects, places, recent_actions = None, None, None \\n    elif mode == \"dt_recent_actions\":\\n        objects, places = None, None \\n    elif mode == \"dt_seen_objects\":\\n        recent_actions = None \\n    elif mode == \"fast_system\":\\n        returns_to_go = None \\n\\n    label = curr_action\\n       \\n    \\n    # ============================================================= #\\n        \\n    input_str = task_desc + f\" </s> Time: {step_id}  </s> \"\\n    \\n    if returns_to_go != None :\\n        input_str += \\'Reward:\\' + str(returns_to_go) + + \" </s> \"\\n     \\n    input_str += \\'The previous action: \\' + prev_action + \\' </s> \\'\\n    if step_id == 1:\\n        prev_obs = \"N/A\"\\n    else:\\n        prev_obs = curr_obs\\n    input_str += \"The previous observation: \" + prev_obs + \\' </s> \\'  # TODO: it was actually a bug but it worked great....\\n    if curr_obs.strip() != look.strip():  \\n        input_str += \\'Current observation: \\' + curr_obs + \" </s> \"\\n    else:\\n        input_str += \\'Current observation: the same as current environment. </s> \\'\\n    input_str += \"Current environment: \" + look + \" </s> \" \\n    input_str += \"Current inventory: \" + inventory + \" </s> \"\\n    \\n    if places:\\n        input_str +=  \"Visited rooms: \" + \", \".join(places)  + \\' </s> \\'\\n    \\n    if objects:\\n        input_str += \"Seen objects: \" + \", \".join(objects) + \\' </s> \\'\\n        \\n    input_str += \\' </s> \\'\\n\\n    if recent_actions[0] == \"look around\":\\n        recent_actions.pop(0)\\n    if recent_actions:\\n        input_str += \"Recent actions: \" + \", \".join(recent_actions[-10:]) + \\' </s> \\' #TODO: 5 or 10? I forgot\\n    input_str = sanitizeStr(input_str)\\n    input_str = input_str.replace(\"(that is open)\", \"\")\\n    input_str = input_str.replace(\"(containing nothing)\", \"\") \\n    label = sanitizeStr(label)\\n    return input_str, label\\n\\n\\n',\n",
       "  'function_name': 'compose_instance_v1_1',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def action_conversion(action, pattern, format_str, num_args):\\n        if num_args == 0:\\n            if action.strip() == pattern.strip():\\n                return format_str\\n            else:\\n                return None\\n        match = re.search(pattern, action)\\n        if match:\\n            if num_args == 1:\\n                formatted_action = format_str.format(match.group(1))\\n            elif num_args == 2:\\n                formatted_action = format_str.format(match.group(1), match.group(2))\\n            return formatted_action\\n        return None \\n',\n",
       "  'function_name': 'action_conversion',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def recover_action(formalized_action):\\n    conversion_dict = [\\n        {\"format_str\": \"0\", \"pattern\": \"CHOOSE(0)\", \"num_args\": 0},\\n        {\"format_str\": \"1\", \"pattern\": \"CHOOSE(1)\", \"num_args\": 0},\\n        {\"format_str\": \"look around\", \"pattern\": \"SEE()\", \"num_args\": 0},\\n        {\"format_str\": \"wait\", \"pattern\": \"WAIT()\", \"num_args\": 0},\\n        # {\"format_str\": \"wait1\", \"pattern\": \"WAIT()\", \"num_args\": 0},\\n        {\"format_str\": \"focus on {}\", \"pattern\": r\"^FOCUS\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"wait {}\", \"pattern\": r\"^WAIT\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"look at {}\", \"pattern\": r\"^LOOK\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"read {}\", \"pattern\": r\"^READ\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"pick up {}\", \"pattern\": r\"^PICK\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"pick up {}\", \"pattern\": r\"^PICKUP\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"pick up {}\", \"pattern\": r\"^PICK_UP\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"open door to {}\", \"pattern\": r\"^OPEN_DOOR\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"close door to {}\", \"pattern\": r\"^CLOSE_DOOR\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"open {}\", \"pattern\": r\"^OPEN\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"close {}\", \"pattern\": r\"^CLOSE\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"activate {}\", \"pattern\": r\"^ACTIVATE\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"deactivate {}\", \"pattern\": r\"^DEACTIVATE\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"activate {}\", \"pattern\": r\"^TURN_ON\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"deactivate {}\", \"pattern\": r\"^TURN_OFF\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"go to {}\", \"pattern\": r\"^GO\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"teleport to {}\", \"pattern\": r\"^TELEPORT\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"examine {}\", \"pattern\": r\"^EXAMINE\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"examine {}\", \"pattern\": r\"^OBSERVE\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"connect {} to {}\", \"pattern\": r\"^CONNECT\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"move {} to {}\", \"pattern\": r\"^MOVE\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"move {} to {}\", \"pattern\": r\"^PLACE\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"use {} on {}\", \"pattern\": r\"^USE\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"pour {} into {}\", \"pattern\": r\"^POUR\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"dunk {} into {}\", \"pattern\": r\"^DUNK\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        # {\"format_str\": \"mix {} and {}\", \"pattern\": r\"^MIX\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        # {\"format_str\": \"mix {} and {}\", \"pattern\": r\"^STIR\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"mix {}\", \"pattern\": r\"^MIX\\\\((.+)\\\\)\", \"num_args\": 1},\\n        {\"format_str\": \"drop {} in {}\", \"pattern\": r\"^DROP\\\\((.+), (.+)\\\\)\", \"num_args\": 2},\\n        {\"format_str\": \"drop {}\", \"pattern\": r\"^DROP\\\\((.+)\\\\)\", \"num_args\": 1},\\n    ] \\n     \\n    for item in conversion_dict:\\n        formal_action = action_conversion(formalized_action, **item)\\n        if formal_action:\\n            return formal_action\\n    print(f\"{formalized_action} cannot be matched with any patterns.\")\\n    return None  \\n',\n",
       "  'function_name': 'recover_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'},\n",
       " {'code': 'def formalize_action(action):\\n    conversion_dict = [\\n        {\"pattern\": \"0\", \"format_str\": \"CHOOSE(0)\", \"num_args\": 0},\\n        {\"pattern\": \"1\", \"format_str\": \"CHOOSE(1)\", \"num_args\": 0},\\n        {\"pattern\": \"look around\", \"format_str\": \"SEE()\", \"num_args\": 0},\\n        {\"pattern\": \"wait\", \"format_str\": \"WAIT()\", \"num_args\": 0},\\n        {\"pattern\": \"wait1\", \"format_str\": \"WAIT()\", \"num_args\": 0},\\n        {\"pattern\": r\"^focus on (.+)\", \"format_str\": \"FOCUS({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^look at (.+)\", \"format_str\": \"LOOK({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^read (.+)\", \"format_str\": \"READ({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^pick up (.+)\", \"format_str\": \"PICK({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^open door to (.+)\", \"format_str\": \"OPEN_DOOR({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^close door to (.+)\", \"format_str\": \"CLOSE_DOOR({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^open (.+)\", \"format_str\": \"OPEN({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^close (.+)\", \"format_str\": \"CLOSE({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^activate (.+)\", \"format_str\": \"ACTIVATE({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^deactivate (.+)\", \"format_str\": \"DEACTIVATE({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^go to (.+)\", \"format_str\": \"GO({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^teleport to (.+)\", \"format_str\": \"TELEPORT({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^examine (.+)\", \"format_str\": \"EXAMINE({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^connect (.+) to (.+)\", \"format_str\": \"CONNECT({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^move (.+) to (.+)\", \"format_str\": \"MOVE({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^use (.+) on (.+)\", \"format_str\": \"USE({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^pour (.+) into (.+)\", \"format_str\": \"POUR({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^pour (.+) in (.+)\", \"format_str\": \"POUR({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^dunk (.+) into (.+)\", \"format_str\": \"DUNK({}, {})\", \"num_args\": 2},\\n        # {\"pattern\": r\"^mix (.+) and (.+)\", \"format_str\": \"MIX({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^mix (.+)\", \"format_str\": \"MIX({})\", \"num_args\": 1},\\n        {\"pattern\": r\"^drop (.+) in (.+)\", \"format_str\": \"DROP({}, {})\", \"num_args\": 2},\\n        {\"pattern\": r\"^drop (.+)\", \"format_str\": \"DROP({})\", \"num_args\": 1},\\n    ]     \\n    for item in conversion_dict:\\n        formal_action = action_conversion(action, **item)\\n        if formal_action:\\n            return formal_action\\n    \\n    return None  \\n\\n\\n',\n",
       "  'function_name': 'formalize_action',\n",
       "  'filepath': '/home/sonofman/Research/Arxiv2Arxode/temprepo/eval_heldout/science-world/data_utils/data_utils.py'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings import create_embedding_collection, load_and_chunk_code, get_embedding_func\n",
    "import openai\n",
    "import langchain\n",
    "# db_conn = get_db_connection(\"agentTuning_code_vecdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_code_docs = load_and_chunk_code(\"./temprepo/\")\n",
    "split_code_docs\n",
    "code_embedding_dbconn = create_embedding_collection(\n",
    "    chunked_docs=split_code_docs, embeddings=get_embedding_func(),\n",
    "    collection_name=\"agentTuning_code_vecdb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def eval_subject(\n",
      "        model,\n",
      "        tokenizer,\n",
      "        subject_name,\n",
      "        test_df,\n",
      "        k=5,\n",
      "        dev_df=None,\n",
      "        few_shot=False,\n",
      "        save_result_dir=None,\n",
      "        **kwargs\n",
      "):\n",
      "    result = []\n",
      "    score = []\n",
      "\n",
      "    cov = generate_few_shot_prompt(\n",
      "        k, subject_name, dev_df) if few_shot else []\n",
      "    all_probs = {'prob_A': [], 'prob_B': [], 'prob_C': [], 'prob_D': []}\n",
      "\n",
      "    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
      "        question = format_example(row, include_answer=False)\n",
      "        cov.append_message(cov.roles[0], question.split(\"Answer:\")[0].rstrip())\n",
      "        cov.append_message(cov.roles[1], None)\n",
      "        full_prompt = cov.get_prompt() + \" Answer: \"\n",
      "        cov = generate_few_shot_prompt(\n",
      "            k, subject_name, dev_df) if few_shot else []\n",
      "\n",
      "        output, input_info = get_logits(tokenizer, model, [full_prompt])\n",
      "        assert output.shape[0] == 1\n",
      "        logits = output.flatten()\n",
      "\n",
      "        softval = torch.nn.functional.softmax(\n",
      "            torch.tensor(\n",
      "                [\n",
      "                    logits[tokenizer(\" A\")['input_ids'][-1]],\n",
      "                    logits[tokenizer(\" B\")['input_ids'][-1]],\n",
      "                    logits[tokenizer(\" C\")['input_ids'][-1]],\n",
      "                    logits[tokenizer(\" D\")['input_ids'][-1]],\n",
      "                ]\n",
      "            ),\n",
      "            dim=0,\n",
      "        )\n",
      "        if softval.dtype in {torch.bfloat16, torch.float16}:\n",
      "            softval = softval.to(dtype=torch.float32)\n",
      "        probs = softval.detach().cpu().numpy()\n",
      "\n",
      "        for i, choice in enumerate(choices):\n",
      "            all_probs[f'prob_{choice}'].append(probs[i])\n",
      "        pred = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\"}[np.argmax(probs)]\n",
      "\n",
      "        if 'answer' in row:\n",
      "            correct = 1 if pred == row['answer'] else 0\n",
      "            score.append(correct)\n",
      "            if args.debug:\n",
      "                print(f'{question} pred: {pred} ref: {row[\"answer\"]}')\n",
      "        result.append(pred)\n",
      "\n",
      "    if save_result_dir:\n",
      "        test_df['model_output'] = result\n",
      "        for i, choice in enumerate(choices):\n",
      "            test_df[f'prob_{choice}'] = (all_probs[f'prob_{choice}'])\n",
      "        if score:\n",
      "            test_df[\"correctness\"] = score\n",
      "        os.makedirs(save_result_dir, exist_ok=True)\n",
      "        test_df.to_csv(os.path.join(\n",
      "            save_result_dir, f'{subject_name}_result.csv'), encoding=\"utf-8\", index=False)\n",
      "    return score\n",
      "\n",
      "\n",
      "def cal_mmlu(res):\n",
      "    acc_sum_dict = dict()\n",
      "    acc_norm_sum_dict = dict()\n",
      "    cnt_dict = dict()\n",
      "    acc_sum = 0.\n",
      "    cnt = 0\n",
      "    hard_cnt = 0\n",
      "    hard_acc_sum = 0.\n",
      "\n",
      "    for class_ in TASK_NAME_MAPPING.keys():\n",
      "        acc_sum_dict[class_] = 0.\n",
      "        acc_norm_sum_dict[class_] = 0.\n",
      "        cnt_dict[class_] = 0.\n",
      "\n",
      "        for tt in TASK_NAME_MAPPING[class_]:\n",
      "            acc_sum += sum(res[tt])\n",
      "            cnt += len(res[tt])\n",
      "\n",
      "            acc_sum_dict[class_] += sum(res[tt])\n",
      "            cnt_dict[class_] += len(res[tt])\n",
      "\n",
      "    for k in TASK_NAME_MAPPING.keys():\n",
      "        if k in cnt_dict:\n",
      "            print('%s ACC: %.2f ' % (\n",
      "                k, acc_sum_dict[k] / cnt_dict[k] * 100))\n",
      "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
      "    with open(f\"mmlu_eval_result_{timestamp}.json\", \"w\") as f:\n",
      "        result = {}\n",
      "        result[\"acc\"] = acc_sum / cnt * 100\n",
      "        result[\"cnt\"] = cnt\n",
      "        result[\"acc_sum_dict\"] = acc_sum_dict\n",
      "        result[\"cnt_dict\"] = cnt_dict\n",
      "        f.write(json.dumps(result))\n",
      "'''\n",
      "This script is adopted from https://github.com/QwenLM/Qwen/blob/main/eval/evaluate_mmlu.py\n",
      "'''\n",
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import argparse\n",
      "import torch\n",
      "import datetime\n",
      "\n",
      "from typing import List\n",
      "from tqdm import tqdm\n",
      "from transformers.trainer_utils import set_seed\n",
      "\n",
      "import transformers\n",
      "from transformers import AutoTokenizer\n",
      "from transformers.generation import GenerationConfig\n",
      "\n",
      "from fastchat.model.model_adapter import get_conversation_template\n",
      "\n",
      "'''\n",
      "This script is used to evaluate the MMLU dataset.\n",
      "wget https://people.eecs.berkeley.edu/~hendrycks/data.tar\n",
      "mkdir data/mmlu\n",
      "mv data.tar data/mmlu\n",
      "cd data/mmlu; tar xf data.tar\n",
      "cd ../../\n",
      "python eval/evaluate_mmlu.py -c /path/to/checkpoint\n",
      "'''\n",
      "\n",
      "def load_models_tokenizer(args):\n",
      "    tokenizer = AutoTokenizer.from_pretrained(args.checkpoint_path)\n",
      "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
      "        args.checkpoint_path, use_safetensors=True, device_map=\"auto\", trust_remote_code=True, torch_dtype=torch.bfloat16).eval()\n",
      "    model.generation_config = GenerationConfig.from_pretrained(\n",
      "        args.checkpoint_path)\n",
      "    return model, tokenizer\n",
      "\n",
      "def format_example(line, include_answer=True):\n",
      "    example = 'Question: ' + line['question']\n",
      "    for choice in choices:\n",
      "        example += f'\\n{choice}. {line[f\"{choice}\"]}'\n",
      "\n",
      "    if include_answer:\n",
      "        example += '\\nAnswer: ' + line[\"answer\"] + '\\n\\n'\n",
      "    else:\n",
      "        example += '\\nAnswer:'\n",
      "    return example\n",
      "\n",
      "\n",
      "def generate_few_shot_prompt(k, subject, dev_df):\n",
      "\n",
      "    def format_subject(subject):\n",
      "        l = subject.split(\"_\")\n",
      "        s = \"\"\n",
      "        for entry in l:\n",
      "            s += \" \" + entry\n",
      "        return s.strip()\n",
      "\n",
      "    # Use llama2 template to generate answer\n",
      "    prompt = f\"The following is a multiple-choice question about {format_subject(subject)}. Please choose the most suitable one among A, B, C and D as the answer to this question.\"\n",
      "    conv = get_conversation_template(\"llama-2\")\n",
      "    conv.set_system_message(f\"{prompt}\")\n",
      "    for i in range(k):\n",
      "        line = dev_df.iloc[i, :]\n",
      "        conv.append_message(conv.roles[0], f'Question: {line[\"question\"]}\\n' + '\\n'.join(\n",
      "            [f\"{choice}. {line[f'{choice}']}\" for choice in [\"A\", \"B\", \"C\", \"D\"]]))\n",
      "        conv.append_message(conv.roles[1], 'Answer: ' + line[\"answer\"])\n",
      "\n",
      "    return conv\n",
      "\n",
      "\n",
      "def get_logits(tokenizer, model, inputs: List[str]):\n",
      "    input_ids = tokenizer(inputs, padding=False)['input_ids']\n",
      "    input_ids = torch.tensor(input_ids, device=model.device)\n",
      "\n",
      "    if input_ids.shape[1] > args.max_seq_len:\n",
      "        input_ids = input_ids[:, input_ids.shape[1]-args.max_seq_len+1:]\n",
      "    tokens = {'input_ids': input_ids}\n",
      "\n",
      "    outputs = model(input_ids)['logits']\n",
      "    logits = outputs[:, -1, :]\n",
      "    log_probs = torch.nn.functional.softmax(logits, dim=-1)\n",
      "    return log_probs, {'tokens': tokens}\n",
      "\n",
      "\n",
      "@torch.no_grad()\n",
      "\"\"\"base class for evaluation\"\"\"\n",
      "# answer string match\n",
      "import importlib\n",
      "import json\n",
      "import time\n",
      "import urllib\n",
      "from pathlib import Path\n",
      "from typing import Any, Tuple, Union\n",
      "\n",
      "import evaluate  # type: ignore[import]\n",
      "from beartype import beartype\n",
      "from beartype.door import is_bearable\n",
      "from playwright.sync_api import CDPSession, Page\n",
      "\n",
      "from browser_env.actions import Action\n",
      "from browser_env.utils import StateInfo\n",
      "from evaluation_harness.helper_functions import (\n",
      "    gitlab_get_project_memeber_role,\n",
      "    llm_fuzzy_match,\n",
      "    reddit_get_post_url,\n",
      "    shopping_get_latest_order_url,\n",
      "    shopping_get_sku_latest_review_author,\n",
      "    shopping_get_sku_latest_review_rating,\n",
      ")\n",
      "\n",
      "Trajectory = list[Union[Action, StateInfo]]\n",
      "\n",
      "\n",
      "@beartype\n",
      "class Evaluator(object):\n",
      "    def __init__(self, eval_tag: str = \"\") -> None:\n",
      "        self.eval_tag = eval_tag\n",
      "\n",
      "    def __call__(\n",
      "        self,\n",
      "        trajectory: Trajectory,\n",
      "        config_file: Path | str,\n",
      "        page: Page,\n",
      "        client: CDPSession,\n",
      "    ) -> float:\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @staticmethod\n",
      "    def get_last_action(trajectory: Trajectory) -> Action:\n",
      "        try:\n",
      "            is_bearable(trajectory[-1], Action)\n",
      "            last_action = trajectory[-1]\n",
      "        except Exception:\n",
      "            raise ValueError(\n",
      "                \"The last element of trajectory should be an action, add a fake stop action if needed\"\n",
      "            )\n",
      "\n",
      "        return last_action  # type: ignore[return-value]\n",
      "\n",
      "    @staticmethod\n",
      "    def get_last_state(trajectory: Trajectory) -> StateInfo:\n",
      "        try:\n",
      "            is_bearable(trajectory[-2], StateInfo)\n",
      "            last_state = trajectory[-2]\n",
      "        except Exception:\n",
      "            raise ValueError(\n",
      "                \"The second last element of trajectory should be a state, add a fake stop action if needed\"\n",
      "            )\n",
      "\n",
      "        return last_state  # type: ignore[return-value]\n",
      "\n",
      "\n",
      "@beartype\n",
      "class StringExactEvaluator(Evaluator):\n",
      "    \"\"\"Check whether the answer is exactly the same as one of the reference answers\"\"\"\n",
      "\n",
      "    def __call__(\n",
      "        self,\n",
      "        trajectory: Trajectory,\n",
      "        config_file: Path | str,\n",
      "        page: Page | None = None,\n",
      "        client: CDPSession | None = None,\n",
      "    ) -> float:\n",
      "        with open(config_file, \"r\") as f:\n",
      "            configs = json.load(f)\n",
      "\n",
      "        def clean_answer(answer: str) -> str:\n",
      "            if answer.startswith(\"'\") and answer.endswith(\"'\"):\n",
      "                answer = answer[1:-1]\n",
      "            elif answer.startswith('\"') and answer.endswith('\"'):\n",
      "                answer = answer[1:-1]\n",
      "            return answer\n",
      "\n",
      "        last_action = self.get_last_action(trajectory)\n",
      "        pred = clean_answer(last_action[\"answer\"])\n",
      "        ref = [clean_answer(x) for x in configs[\"eval\"][\"reference_answers\"]]\n",
      "        if pred in ref:\n",
      "            return 1.0\n",
      "        else:\n",
      "            return 0.0\n",
      "\n",
      "\n",
      "@beartype\n",
      "class Evaluator:\n",
      "    def __init__(self, task, dataset, algo, maxtry=3):\n",
      "        assert task in [\"hotpot_qa\", \"trivia_qa\", \"gsm8k\", \"physics_question\", \"disfl_qa\",\n",
      "                        \"sports_understanding\", \"strategy_qa\", \"sotu_qa\"]\n",
      "        assert isinstance(dataset, pd.DataFrame)\n",
      "        assert isinstance(algo, (PWS_Base, PWS_Extra, ReactBase, IO, CoT))\n",
      "\n",
      "        self.task = task\n",
      "        self.dataset = dataset\n",
      "        self.algo = algo\n",
      "        self.maxtry = maxtry\n",
      "        self.failed_response = self._failed_response()\n",
      "        self.eval_data = self._initialize_eval_dict()\n",
      "\n",
      "    def run(self):\n",
      "        print(\"\\n******************* Start Evaluation *******************\\n\")\n",
      "        if self.task in [\"hotpot_qa\", \"sotu_qa\"]:\n",
      "            for i in tqdm.tqdm(range(len(self.dataset))):\n",
      "                question = self.dataset[\"question\"][i]\n",
      "                label = self.dataset[\"answer\"][i]\n",
      "                for _ in range(self.maxtry):\n",
      "                    try:\n",
      "                        response = self.algo.run(question)\n",
      "                        break\n",
      "                    except Exception:\n",
      "                        traceback.print_exc()\n",
      "                        response = self.failed_response\n",
      "                self._update_eval_dict(question, label, response)\n",
      "\n",
      "        elif self.task == \"fever\":\n",
      "            for i in tqdm.tqdm(range(len(self.dataset))):\n",
      "                question = self.dataset[\"claim\"][i]\n",
      "                label = self.dataset[\"label\"][i]\n",
      "                for _ in range(self.maxtry):\n",
      "                    try:\n",
      "                        response = self.algo.run(question)\n",
      "                        break\n",
      "                    except:\n",
      "                        response = self.failed_response\n",
      "                self._update_eval_dict(question, label, response)\n",
      "        elif self.task == \"trivia_qa\":\n",
      "            for i in tqdm.tqdm(range(len(self.dataset))):\n",
      "                question = self.dataset[\"question\"][i]\n",
      "                label = self.dataset[\"answer\"][i][\"value\"]\n",
      "                for _ in range(self.maxtry):\n",
      "                    try:\n",
      "                        response = self.algo.run(question)\n",
      "                        break\n",
      "                    except:\n",
      "                        response = self.failed_response\n",
      "                self._update_eval_dict(question, label, response)\n",
      "        elif self.task == \"gsm8k\":\n",
      "            for i in tqdm.tqdm(range(len(self.dataset))):\n",
      "                question = self.dataset[\"question\"][i]\n",
      "                label = self.dataset[\"answer\"][i].split(\"#### \")[1]\n",
      "                for _ in range(self.maxtry):\n",
      "                    try:\n",
      "                        response = self.algo.run(question)\n",
      "                        break\n",
      "                    except:\n",
      "                        response = self.failed_response\n",
      "                self._update_eval_dict(question, label, response)\n",
      "        elif self.task in [\"physics_question\", \"sports_understanding\", \"strategy_qa\"]:\n",
      "            for i in tqdm.tqdm(range(len(self.dataset))):\n",
      "                question = self.dataset[\"input\"][i]\n",
      "                label = self.dataset[\"target\"][i]\n",
      "                for _ in range(self.maxtry):\n",
      "                    try:\n",
      "                        response = self.algo.run(question)\n",
      "                        break\n",
      "                    except:\n",
      "                        response = self.failed_response\n",
      "                self._update_eval_dict(question, label, response)\n",
      "        else:\n",
      "            raise NotImplementedError\n",
      "\n",
      "        return self._get_avg_results(), self.eval_data\n",
      "\n",
      "    def _initialize_eval_dict(self):\n",
      "        data = {}\n",
      "        for d in [\"label\", \"preds\", \"em\", \"f1\", \"acc\", \"wall_time\", \"total_tokens\", \"total_cost\", \"steps\", \"token_cost\",\n",
      "                  \"tool_cost\", \"planner_log\", \"solver_log\"]:\n",
      "            data[d] = []\n",
      "        return data\n",
      "\n",
      "    def _update_eval_dict(self, question, label, response):\n",
      "        print(\"=== Planner ===\" + '\\n\\n' + response.get(\"planner_log\", '') + '\\n' + \"=== Solver ===\" + '\\n\\n' + response.get(\"solver_log\", ''))\n"
     ]
    }
   ],
   "source": [
    "for doc in code_embedding_dbconn.similarity_search(\"mmlu eval\"):\n",
    "    print(doc.page_content)\n",
    "# print(code_embedding_dbconn.similarity_search(\"mmlu eval\")[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv2arxode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
