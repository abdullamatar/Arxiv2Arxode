{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arxiv_search import ArxivScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'arxiv_paper.ArxivPaper'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ArxivPaper(pid='2307.02485v1', title='Building Cooperative Embodied Agents Modularly with Large Language Models', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Large Language Models (LLMs) have demonstrated impressive planning abilities\\nin single-agent embodied tasks across various domains. However, their capacity\\nfor planning and communication in multi-agent cooperation remains unclear, even\\nthough these are crucial skills for intelligent embodied agents. In this paper,\\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\\ntests it in various embodied environments. Our framework enables embodied\\nagents to plan, communicate, and cooperate with other embodied agents or humans\\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\\neffective communication using our framework without requiring fine-tuning or\\nfew-shot prompting. We also discover that LLM-based agents that communicate in\\nnatural language can earn more trust and cooperate more effectively with\\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\\nthe foundation for future research in multi-agent cooperation. Videos can be\\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.', link='http://arxiv.org/pdf/2307.02485v1'),\n",
       " ArxivPaper(pid='2310.14985v1', title='LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='This paper aims to investigate the open research problem of uncovering the\\nsocial behaviors of LLM-based agents. To achieve this goal, we adopt Avalon, a\\nrepresentative communication game, as the environment and use system prompts to\\nguide LLM agents to play the game. While previous studies have conducted\\npreliminary investigations into gameplay with LLM agents, there lacks research\\non their social behaviors. In this paper, we present a novel framework designed\\nto seamlessly adapt to Avalon gameplay. The core of our proposed framework is a\\nmulti-agent system that enables efficient communication and interaction among\\nagents. We evaluate the performance of our framework based on metrics from two\\nperspectives: winning the game and analyzing the social behaviors of LLM\\nagents. Our results demonstrate the effectiveness of our framework in\\ngenerating adaptive and intelligent agents and highlight the potential of\\nLLM-based agents in addressing the challenges associated with dynamic social\\nenvironment interaction. By analyzing the social behaviors of LLM agents from\\nthe aspects of both collaboration and confrontation, we provide insights into\\nthe research and applications of this domain.', link='http://arxiv.org/pdf/2310.14985v1'),\n",
       " ArxivPaper(pid='2310.12823v2', title='AgentTuning: Enabling Generalized Agent Abilities for LLMs', authors=<class 'arxiv.arxiv.Result.Author'>, abstract=\"Open large language models (LLMs) with great performance in various tasks\\nhave significantly advanced the development of LLMs. However, they are far\\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\\ncentral controller responsible for planning, memorization, and tool\\nutilization, necessitating both fine-grained prompting methods and robust LLMs\\nto achieve satisfactory performance. Though many prompting methods have been\\nproposed to complete particular agent tasks, there is lack of research focusing\\non improving the agent capabilities of LLMs themselves without compromising\\ntheir general abilities. In this work, we present AgentTuning, a simple and\\ngeneral method to enhance the agent abilities of LLMs while maintaining their\\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\\ninstruction-tuning dataset containing high-quality interaction trajectories. We\\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\\nopen-source instructions from general domains. AgentTuning is used to\\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\\nthat AgentTuning enables LLMs' agent capabilities without compromising general\\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\\ntasks, demonstrating generalized agent capabilities. We open source the\\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\\nhttps://github.com/THUDM/AgentTuning, serving open and powerful alternatives to\\ncommercial LLMs for agent tasks.\", link='http://arxiv.org/pdf/2310.12823v2'),\n",
       " ArxivPaper(pid='2310.03903v1', title='Evaluating Multi-Agent Coordination Abilities in Large Language Models', authors=<class 'arxiv.arxiv.Result.Author'>, abstract=\"A pivotal aim in contemporary AI research is to develop agents proficient in\\nmulti-agent coordination, enabling effective collaboration with both humans and\\nother systems. Large Language Models (LLMs), with their notable ability to\\nunderstand, generate, and interpret language in a human-like manner, stand out\\nas promising candidates for the development of such agents. In this study, we\\nbuild and assess the effectiveness of agents crafted using LLMs in various\\ncoordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework,\\nspecifically designed to enable LLMs to play coordination games. With the\\nLLM-Co framework, we conduct our evaluation with three game environments and\\norganize the evaluation into five aspects: Theory of Mind, Situated Reasoning,\\nSustained Coordination, Robustness to Partners, and Explicit Assistance. First,\\nthe evaluation of the Theory of Mind and Situated Reasoning reveals the\\ncapabilities of LLM to infer the partner's intention and reason actions\\naccordingly. Then, the evaluation around Sustained Coordination and Robustness\\nto Partners further showcases the ability of LLMs to coordinate with an unknown\\npartner in complex long-horizon tasks, outperforming Reinforcement Learning\\nbaselines. Lastly, to test Explicit Assistance, which refers to the ability of\\nan agent to offer help proactively, we introduce two novel layouts into the\\nOvercooked-AI benchmark, examining if agents can prioritize helping their\\npartners, sacrificing time that could have been spent on their tasks. This\\nresearch underscores the promising capabilities of LLMs in sophisticated\\ncoordination environments and reveals the potential of LLMs in building strong\\nreal-world agents for multi-agent coordination.\", link='http://arxiv.org/pdf/2310.03903v1'),\n",
       " ArxivPaper(pid='2310.02170v1', title='Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Large language model (LLM) agents have been shown effective on a wide range\\nof tasks, and by ensembling multiple LLM agents, their performances could be\\nfurther improved. Existing approaches employ a fixed set of agents to interact\\nwith each other in a static architecture, which limits their generalizability\\nto various tasks and requires strong human prior in designing these agents. In\\nthis work, we propose to construct a strategic team of agents communicating in\\na dynamic interaction architecture based on the task query. Specifically, we\\nbuild a framework named Dynamic LLM-Agent Network ($\\\\textbf{DyLAN}$) for\\nLLM-agent collaboration on complicated tasks like reasoning and code\\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\\narchitecture with inference-time agent selection and an early-stopping\\nmechanism to improve performance and efficiency. We further design an automatic\\nagent team optimization algorithm based on an unsupervised metric termed\\n$\\\\textit{Agent Importance Score}$, enabling the selection of best agents based\\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\\nperforms well in both reasoning and code generation tasks with reasonable\\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\\nby up to 25.0%.', link='http://arxiv.org/pdf/2310.02170v1'),\n",
       " ArxivPaper(pid='2310.20151v1', title='Multi-Agent Consensus Seeking via Large Language Models', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Multi-agent systems driven by large language models (LLMs) have shown\\npromising abilities for solving complex tasks in a collaborative manner. This\\nwork considers a fundamental problem in multi-agent collaboration: consensus\\nseeking. When multiple agents work together, we are interested in how they can\\nreach a consensus through inter-agent negotiation. To that end, this work\\nstudies a consensus-seeking task where the state of each agent is a numerical\\nvalue and they negotiate with each other to reach a consensus value. It is\\nrevealed that when not explicitly directed on which strategy should be adopted,\\nthe LLM-driven agents primarily use the average strategy for consensus seeking\\nalthough they may occasionally use some other strategies. Moreover, this work\\nanalyzes the impact of the agent number, agent personality, and network\\ntopology on the negotiation process. The findings reported in this work can\\npotentially lay the foundations for understanding the behaviors of LLM-driven\\nmulti-agent systems for solving more complex tasks. Furthermore, LLM-driven\\nconsensus seeking is applied to a multi-robot aggregation task. This\\napplication demonstrates the potential of LLM-driven agents to achieve\\nzero-shot autonomous planning for multi-robot collaboration tasks. Project\\nwebsite: westlakeintelligentrobotics.github.io/ConsensusLLM/.', link='http://arxiv.org/pdf/2310.20151v1'),\n",
       " ArxivPaper(pid='2310.18940v1', title='Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game', authors=<class 'arxiv.arxiv.Result.Author'>, abstract=\"Agents built with large language models (LLMs) have recently achieved great\\nadvancements. However, most of the efforts focus on single-agent or cooperative\\nsettings, leaving more general multi-agent environments underexplored. We\\npropose a new framework powered by reinforcement learning (RL) to develop\\nstrategic language agents, i.e., LLM-based agents with strategic thinking\\nability, for a popular language game, Werewolf. Werewolf is a social deduction\\ngame with hidden roles that involves both cooperation and competition and\\nemphasizes deceptive communication and diverse gameplay. Our agent tackles this\\ngame by first using LLMs to reason about potential deceptions and generate a\\nset of strategically diverse actions. Then an RL policy, which selects an\\naction from the candidates, is learned by population-based training to enhance\\nthe agents' decision-making ability. By combining LLMs with the RL policy, our\\nagent produces a variety of emergent strategies, achieves the highest win rate\\nagainst other LLM-based agents, and stays robust against adversarial human\\nplayers in the Werewolf game.\", link='http://arxiv.org/pdf/2310.18940v1'),\n",
       " ArxivPaper(pid='2310.09454v1', title='LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Recent advancements in reasoning abilities of Large Language Models (LLM) has\\npromoted their usage in problems that require high-level planning for robots\\nand artificial agents. However, current techniques that utilize LLMs for such\\nplanning tasks make certain key assumptions such as, access to datasets that\\npermit finetuning, meticulously engineered prompts that only provide relevant\\nand essential information to the LLM, and most importantly, a deterministic\\napproach to allow execution of the LLM responses either in the form of existing\\npolicies or plan operators. In this work, we propose LgTS (LLM-guided\\nTeacher-Student learning), a novel approach that explores the planning\\nabilities of LLMs to provide a graphical representation of the sub-goals to a\\nreinforcement learning (RL) agent that does not have access to the transition\\ndynamics of the environment. The RL agent uses Teacher-Student learning\\nalgorithm to learn a set of successful policies for reaching the goal state\\nfrom the start state while simultaneously minimizing the number of\\nenvironmental interactions. Unlike previous methods that utilize LLMs, our\\napproach does not assume access to a propreitary or a fine-tuned LLM, nor does\\nit require pre-trained policies that achieve the sub-goals proposed by the LLM.\\nThrough experiments on a gridworld based DoorKey domain and a search-and-rescue\\ninspired domain, we show that generating a graphical structure of sub-goals\\nhelps in learning policies for the LLM proposed sub-goals and the\\nTeacher-Student learning algorithm minimizes the number of environment\\ninteractions when the transition dynamics are unknown.', link='http://arxiv.org/pdf/2310.09454v1'),\n",
       " ArxivPaper(pid='2307.02757v1', title='Wireless Multi-Agent Generative AI: From Connected Intelligence to Collective Intelligence', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='The convergence of generative large language models (LLMs), edge networks,\\nand multi-agent systems represents a groundbreaking synergy that holds immense\\npromise for future wireless generations, harnessing the power of collective\\nintelligence and paving the way for self-governed networks where intelligent\\ndecision-making happens right at the edge. This article puts the stepping-stone\\nfor incorporating multi-agent generative artificial intelligence (AI) in\\nwireless networks, and sets the scene for realizing on-device LLMs, where\\nmulti-agent LLMs are collaboratively planning and solving tasks to achieve a\\nnumber of network goals. We further investigate the profound limitations of\\ncloud-based LLMs, and explore multi-agent LLMs from a game theoretic\\nperspective, where agents collaboratively solve tasks in competitive\\nenvironments. Moreover, we establish the underpinnings for the architecture\\ndesign of wireless multi-agent generative AI systems at the network level and\\nthe agent level, and we identify the wireless technologies that are envisioned\\nto play a key role in enabling on-device LLM. To demonstrate the promising\\npotentials of wireless multi-agent generative AI networks, we highlight the\\nbenefits that can be achieved when implementing wireless generative agents in\\nintent-based networking, and we provide a case study to showcase how on-device\\nLLMs can contribute to solving network intents in a collaborative fashion. We\\nfinally shed lights on potential challenges and sketch a research roadmap\\ntowards realizing the vision of wireless collective intelligence.', link='http://arxiv.org/pdf/2307.02757v1'),\n",
       " ArxivPaper(pid='2310.05746v1', title='Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Can Large Language Models (LLMs) simulate human behavior in complex\\nenvironments? LLMs have recently been shown to exhibit advanced reasoning\\nskills but much of NLP evaluation still relies on static benchmarks. Answering\\nthis requires evaluation environments that probe strategic reasoning in\\ncompetitive, dynamic scenarios that involve long-term planning. We introduce\\nAucArena, a novel simulation environment for evaluating LLMs within auctions, a\\nsetting chosen for being highly unpredictable and involving many skills related\\nto resource and risk management, while also being easy to evaluate. We conduct\\nseveral controlled simulations using state-of-the-art LLMs as bidding agents.\\nWe find that through simple prompting, LLMs do indeed demonstrate many of the\\nskills needed for effectively engaging in auctions (e.g., managing budget,\\nadhering to long-term goals and priorities), skills that we find can be\\nsharpened by explicitly encouraging models to be adaptive and observe\\nstrategies in past auctions. These results are significant as they show the\\npotential of using LLM agents to model intricate social dynamics, especially in\\ncompetitive settings. However, we also observe considerable variability in the\\ncapabilities of individual LLMs. Notably, even our most advanced models (GPT-4)\\nare occasionally surpassed by heuristic baselines and human agents,\\nhighlighting the potential for further improvements in the design of LLM agents\\nand the important role that our simulation environment can play in further\\ntesting and refining agent architectures.', link='http://arxiv.org/pdf/2310.05746v1')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ◉_◉\n",
    "axs = ArxivScraper()\n",
    "papers = axs.search_papers('all:LLM OR LLM AND Agent OR Agents', max_results=10)\n",
    "print(type(papers[0]))\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArxivPaper(pid='2307.02485v1', title='Building Cooperative Embodied Agents Modularly with Large Language Models', authors=<class 'arxiv.arxiv.Result.Author'>, abstract='Large Language Models (LLMs) have demonstrated impressive planning abilities\\nin single-agent embodied tasks across various domains. However, their capacity\\nfor planning and communication in multi-agent cooperation remains unclear, even\\nthough these are crucial skills for intelligent embodied agents. In this paper,\\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\\ntests it in various embodied environments. Our framework enables embodied\\nagents to plan, communicate, and cooperate with other embodied agents or humans\\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\\neffective communication using our framework without requiring fine-tuning or\\nfew-shot prompting. We also discover that LLM-based agents that communicate in\\nnatural language can earn more trust and cooperate more effectively with\\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\\nthe foundation for future research in multi-agent cooperation. Videos can be\\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.', link='http://arxiv.org/pdf/2307.02485v1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "papers[0]\n",
    "# axs.download_papers(papers[:1], dirpath='temp')\n",
    "# axs.download_paper(papers, dirpath='temp')\n",
    "# for p in papers:\n",
    "#     if p.has_github_link():\n",
    "#         print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper 'Building Cooperative Embodied Agents Modularly with Large Language Models':\n",
      "GitHub URL(s): \n",
      "Other URL(s): https://vis-www.cs.umass.edu/Co-LLM-Agents\n",
      "No relevant URLs found in the paper: LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay abstract.\n",
      "Paper 'AgentTuning: Enabling Generalized Agent Abilities for LLMs':\n",
      "GitHub URL(s): https://github.com/THUDM/AgentTuning\n",
      "Other URL(s): \n",
      "No relevant URLs found in the paper: Evaluating Multi-Agent Coordination Abilities in Large Language Models abstract.\n",
      "No relevant URLs found in the paper: Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization abstract.\n",
      "No relevant URLs found in the paper: Multi-Agent Consensus Seeking via Large Language Models abstract.\n",
      "No relevant URLs found in the paper: Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game abstract.\n",
      "No relevant URLs found in the paper: LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents abstract.\n",
      "No relevant URLs found in the paper: Wireless Multi-Agent Generative AI: From Connected Intelligence to Collective Intelligence abstract.\n",
      "No relevant URLs found in the paper: Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena abstract.\n"
     ]
    }
   ],
   "source": [
    "for p in papers:\n",
    "    p.extract_github_links()\n",
    "\n",
    "# papers[0].extract_github_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path ./temp/\n"
     ]
    }
   ],
   "source": [
    "from pre_proc_pdfs import init_vectorDB, create_word_embeddings, load_and_chunk_papers\n",
    "\n",
    "docs = load_and_chunk_papers('./temp/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = create_word_embeddings()\n",
    "\n",
    "db_conn = init_vectorDB(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, tuple, langchain.schema.document.Document, float)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_response =db_conn.similarity_search_with_score(\"How many publicly available language models are there?\")\n",
    "len(query_response), type(query_response[0]), type(query_response[0][0]), type(query_response[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "score: 0.15521328048822958\n",
      "Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs are announced each week, many of which are deposited to Hugging Face, a repository of machine learning models and datasets. To date, nearly 16,000 Text Generation models have been uploaded to the site. Given the huge influx of LLMs, it is of interest to know which LLM backbones, settings, training methods, and families are popular or trending. However, there is no comprehensive index of LLMs available. We take advantage of the relatively systematic nomenclature to perform hierarchical clustering and identify of Hugging Face LLMs communities amongst LLMs using n-grams and term frequency-inverse document frequency. Our methods successfully identify families of LLMs and accurately cluster LLMs into meaningful subgroups. We present a public web application to navigate and explore Constellation, our atlas of 15,821 LLMs. Constellation\n",
      "****************************************\n",
      "****************************************\n",
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "score: 0.16293333018620848\n",
      "Introduction\n",
      "\n",
      "Large language models (LLMs) are trained to generate realistic text given a user prompt [1]. Popular LLMs include ChatGPT, Bard, and the LLaMa family of models [2]. In addition to large companies like OpenAI and Google, smaller research groups and individuals can also train LLMs and share them through Hugging Face, a popular machine learning repository [3,4]. As of July 18, 2023 at 12 PM (GMT -5), 15,821 LLMs (or at least, Text Generation models) were available publicly on Hugging Face. To our knowledge, few attempts have been made to organize these LLMs, perhaps due to the immense number of models. Inspired by the bioinformatics technique of using hierarchical clustering on DNA sequences, we apply hierarchical clustering to the Hugging Face model names, assuming that similar names indicate similarity [5]. We also construct a graph of LLMs and detect communities using the Louvain method. Additionally, we generate other visualizations and explore the data.\n",
      "\n",
      "3\n",
      "\n",
      "Methods\n",
      "****************************************\n",
      "****************************************\n",
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "score: 0.1718139401618729\n",
      "1\n",
      "\n",
      "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models\n",
      "\n",
      "Sarah R Gao, Andrew K Gao Canyon Crest Academy, Stanford University\n",
      "\n",
      "2\n",
      "\n",
      "Abstract\n",
      "****************************************\n",
      "****************************************\n",
      "dict_keys(['page_content', 'metadata', 'type'])\n",
      "score: 0.17722437653250978\n",
      "By making Constellation publicly available, we hope to encourage more systematic and informed engagement with LLMs. As the landscape of LLMs continues to evolve rapidly, tools\n",
      "\n",
      "10\n",
      "\n",
      "such as Constellation will be instrumental in assisting the researcher and developer communities in keeping pace with these developments.\n",
      "\n",
      "References\n",
      "\n",
      "1. Gao, A. (2023, July 8). Prompt Engineering for Large Language Models. SSRN; SSRN.\n",
      "\n",
      "https://doi.org/10.2139/ssrn.4504303\n",
      "\n",
      "2. Arancio, J. (2023, April 17). Llama, Alpaca and Vicuna: the new Chatgpt running on your laptop. Medium.\n",
      "\n",
      "https://medium.com/@jeremyarancio/exploring-llamas-family-models-how-we-achieved-running-llms-on-l\n",
      "\n",
      "aptops-16bf2539a1bb\n",
      "\n",
      "3. Hiter, S. (2023, June 6). What Is a Large Language Model? | Guide to LLMs. EWEEK.\n",
      "\n",
      "https://www.eweek.com/artificial-intelligence/large-language-model/\n",
      "\n",
      "4. Hugging Face. (n.d.). Hugging Face – On a mission to solve NLP, one commit at a time. Huggingface.co.\n",
      "\n",
      "https://huggingface.co/\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "for doc, score in query_response:\n",
    "    print(\"*\" * 40)\n",
    "    print(doc.dict().keys())\n",
    "    # print(doc.from_orm(doc).dict())\n",
    "    print(\"score: %s\" % score)\n",
    "    print(doc.page_content)\n",
    "    print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reconnect to a vec_db, just call db_conn = PGVectorDB(collectioname, connstr, embeddingfunc)\n",
    "# from langchain.vectorstores.pgvector import PGVector\n",
    "# db_conn = PGVector('papers', 'postgresql://postgres:postgres@localhost:5432/postgres', embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv2arxode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
