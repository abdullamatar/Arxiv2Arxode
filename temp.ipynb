{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "from arxiv_paper import ArxivPaper\n",
    "from arxiv_search import ArxivScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivPaper(id='2310.03903v1', title='Evaluating Multi-Agent Coordination Abilities in Large Language Models', published='2023-10-05T21:18:15Z', authors=['Saaket Agashe', 'Yue Fan', 'Xin Eric Wang'], abstract=\"A pivotal aim in contemporary AI research is to develop agents proficient in\\nmulti-agent coordination, enabling effective collaboration with both humans and\\nother systems. Large Language Models (LLMs), with their notable ability to\\nunderstand, generate, and interpret language in a human-like manner, stand out\\nas promising candidates for the development of such agents. In this study, we\\nbuild and assess the effectiveness of agents crafted using LLMs in various\\ncoordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework,\\nspecifically designed to enable LLMs to play coordination games. With the\\nLLM-Co framework, we conduct our evaluation with three game environments and\\norganize the evaluation into five aspects: Theory of Mind, Situated Reasoning,\\nSustained Coordination, Robustness to Partners, and Explicit Assistance. First,\\nthe evaluation of the Theory of Mind and Situated Reasoning reveals the\\ncapabilities of LLM to infer the partner's intention and reason actions\\naccordingly. Then, the evaluation around Sustained Coordination and Robustness\\nto Partners further showcases the ability of LLMs to coordinate with an unknown\\npartner in complex long-horizon tasks, outperforming Reinforcement Learning\\nbaselines. Lastly, to test Explicit Assistance, which refers to the ability of\\nan agent to offer help proactively, we introduce two novel layouts into the\\nOvercooked-AI benchmark, examining if agents can prioritize helping their\\npartners, sacrificing time that could have been spent on their tasks. This\\nresearch underscores the promising capabilities of LLMs in sophisticated\\ncoordination environments and reveals the potential of LLMs in building strong\\nreal-world agents for multi-agent coordination.\", links=[{'href': 'http://arxiv.org/abs/2310.03903v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.03903v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment=None),\n",
       " ArxivPaper(id='2307.02485v1', title='Building Cooperative Embodied Agents Modularly with Large Language\\n  Models', published='2023-07-05T17:59:27Z', authors=['Hongxin Zhang', 'Weihua Du', 'Jiaming Shan', 'Qinhong Zhou', 'Yilun Du', 'Joshua B. Tenenbaum', 'Tianmin Shu', 'Chuang Gan'], abstract='Large Language Models (LLMs) have demonstrated impressive planning abilities\\nin single-agent embodied tasks across various domains. However, their capacity\\nfor planning and communication in multi-agent cooperation remains unclear, even\\nthough these are crucial skills for intelligent embodied agents. In this paper,\\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\\ntests it in various embodied environments. Our framework enables embodied\\nagents to plan, communicate, and cooperate with other embodied agents or humans\\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\\neffective communication using our framework without requiring fine-tuning or\\nfew-shot prompting. We also discover that LLM-based agents that communicate in\\nnatural language can earn more trust and cooperate more effectively with\\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\\nthe foundation for future research in multi-agent cooperation. Videos can be\\nfound on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.', links=[{'href': 'http://arxiv.org/abs/2307.02485v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2307.02485v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='Project page: https://vis-www.cs.umass.edu/Co-LLM-Agents/'),\n",
       " ArxivPaper(id='2310.02170v1', title='Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with\\n  Agent Team Optimization', published='2023-10-03T16:05:48Z', authors=['Zijun Liu', 'Yanzhe Zhang', 'Peng Li', 'Yang Liu', 'Diyi Yang'], abstract='Large language model (LLM) agents have been shown effective on a wide range\\nof tasks, and by ensembling multiple LLM agents, their performances could be\\nfurther improved. Existing approaches employ a fixed set of agents to interact\\nwith each other in a static architecture, which limits their generalizability\\nto various tasks and requires strong human prior in designing these agents. In\\nthis work, we propose to construct a strategic team of agents communicating in\\na dynamic interaction architecture based on the task query. Specifically, we\\nbuild a framework named Dynamic LLM-Agent Network ($\\\\textbf{DyLAN}$) for\\nLLM-agent collaboration on complicated tasks like reasoning and code\\ngeneration. DyLAN enables agents to interact for multiple rounds in a dynamic\\narchitecture with inference-time agent selection and an early-stopping\\nmechanism to improve performance and efficiency. We further design an automatic\\nagent team optimization algorithm based on an unsupervised metric termed\\n$\\\\textit{Agent Importance Score}$, enabling the selection of best agents based\\non the contribution each agent makes. Empirically, we demonstrate that DyLAN\\nperforms well in both reasoning and code generation tasks with reasonable\\ncomputational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and\\nHumanEval, respectively, compared to a single execution on GPT-35-turbo. On\\nspecific subjects of MMLU, agent team optimization in DyLAN increases accuracy\\nby up to 25.0%.', links=[{'href': 'http://arxiv.org/abs/2310.02170v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.02170v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='Preprint, under review. 21 pages'),\n",
       " ArxivPaper(id='2309.14534v1', title='\"Teach AI How to Code\": Using Large Language Models as Teachable Agents\\n  for Programming Education', published='2023-09-25T21:20:04Z', authors=['Hyoungwook Jin', 'Seonghee Lee', 'Hyungyu Shin', 'Juho Kim'], abstract='This work investigates large language models (LLMs) as teachable agents for\\nlearning by teaching (LBT). LBT with teachable agents helps learners identify\\ntheir knowledge gaps and discover new knowledge. However, teachable agents\\nrequire expensive programming of subject-specific knowledge. While LLMs as\\nteachable agents can reduce the cost, LLMs\\' over-competence as tutees\\ndiscourages learners from teaching. We propose a prompting pipeline that\\nrestrains LLMs\\' competence and makes them initiate \"why\" and \"how\" questions\\nfor effective knowledge-building. We combined these techniques into TeachYou,\\nan LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee\\nchatbot that can simulate misconceptions and unawareness prescribed in its\\nknowledge state. Our technical evaluation confirmed that our prompting pipeline\\ncan effectively configure AlgoBo\\'s problem-solving performance. Through a\\nbetween-subject study with 40 algorithm novices, we also observed that AlgoBo\\'s\\nquestions led to knowledge-dense conversations (effect size=0.73). Lastly, we\\ndiscuss design implications, cost-efficiency, and personalization of LLM-based\\nteachable agents.', links=[{'href': 'http://arxiv.org/abs/2309.14534v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2309.14534v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment=None),\n",
       " ArxivPaper(id='2310.01557v2', title='SmartPlay : A Benchmark for LLMs as Intelligent Agents', published='2023-10-02T18:52:11Z', authors=['Yue Wu', 'Xuan Tang', 'Tom M. Mitchell', 'Yuanzhi Li'], abstract=\"Recent large language models (LLMs) have demonstrated great potential toward\\nintelligent agents and next-gen automation, but there currently lacks a\\nsystematic benchmark for evaluating LLMs' abilities as agents. We introduce\\nSmartPlay: both a challenging benchmark and a methodology for evaluating LLMs\\nas agents. SmartPlay consists of 6 different games, including\\nRock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique\\nsetting, providing up to 20 evaluation settings and infinite environment\\nvariations. Each game in SmartPlay uniquely challenges a subset of 9 important\\ncapabilities of an intelligent LLM agent, including reasoning with object\\ndependencies, planning ahead, spatial reasoning, learning from history, and\\nunderstanding randomness. The distinction between the set of capabilities each\\ngame test allows us to analyze each capability separately. SmartPlay serves not\\nonly as a rigorous testing ground for evaluating the overall performance of LLM\\nagents but also as a road-map for identifying gaps in current methodologies. We\\nrelease our benchmark at github.com/microsoft/SmartPlay\", links=[{'href': 'http://arxiv.org/abs/2310.01557v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.01557v2', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment=None),\n",
       " ArxivPaper(id='2307.02757v1', title='Wireless Multi-Agent Generative AI: From Connected Intelligence to\\n  Collective Intelligence', published='2023-07-06T03:41:15Z', authors=['Hang Zou', 'Qiyang Zhao', 'Lina Bariah', 'Mehdi Bennis', 'Merouane Debbah'], abstract='The convergence of generative large language models (LLMs), edge networks,\\nand multi-agent systems represents a groundbreaking synergy that holds immense\\npromise for future wireless generations, harnessing the power of collective\\nintelligence and paving the way for self-governed networks where intelligent\\ndecision-making happens right at the edge. This article puts the stepping-stone\\nfor incorporating multi-agent generative artificial intelligence (AI) in\\nwireless networks, and sets the scene for realizing on-device LLMs, where\\nmulti-agent LLMs are collaboratively planning and solving tasks to achieve a\\nnumber of network goals. We further investigate the profound limitations of\\ncloud-based LLMs, and explore multi-agent LLMs from a game theoretic\\nperspective, where agents collaboratively solve tasks in competitive\\nenvironments. Moreover, we establish the underpinnings for the architecture\\ndesign of wireless multi-agent generative AI systems at the network level and\\nthe agent level, and we identify the wireless technologies that are envisioned\\nto play a key role in enabling on-device LLM. To demonstrate the promising\\npotentials of wireless multi-agent generative AI networks, we highlight the\\nbenefits that can be achieved when implementing wireless generative agents in\\nintent-based networking, and we provide a case study to showcase how on-device\\nLLMs can contribute to solving network intents in a collaborative fashion. We\\nfinally shed lights on potential challenges and sketch a research roadmap\\ntowards realizing the vision of wireless collective intelligence.', links=[{'href': 'http://arxiv.org/abs/2307.02757v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2307.02757v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment=None),\n",
       " ArxivPaper(id='2310.08535v1', title='Formally Specifying the High-Level Behavior of LLM-Based Agents', published='2023-10-12T17:24:15Z', authors=['Maxwell Crouse', 'Ibrahim Abdelaziz', 'Kinjal Basu', 'Soham Dan', 'Sadhana Kumaravel', 'Achille Fokoue', 'Pavan Kapanipathi', 'Luis Lastras'], abstract='LLM-based agents have recently emerged as promising tools for solving\\nchallenging problems without the need for task-specific finetuned models that\\ncan be expensive to procure. Currently, the design and implementation of such\\nagents is ad hoc, as the wide variety of tasks that LLM-based agents may be\\napplied to naturally means there can be no one-size-fits-all approach to agent\\ndesign. In this work we aim to alleviate the difficulty of designing and\\nimplementing new agents by proposing a minimalistic, high-level generation\\nframework that simplifies the process of building agents. The framework we\\nintroduce allows the user to specify desired agent behaviors in Linear Temporal\\nLogic (LTL). The declarative LTL specification is then used to construct a\\nconstrained decoder that guarantees the LLM will produce an output exhibiting\\nthe desired behavior. By designing our framework in this way, we obtain several\\nbenefits, including the ability to enforce complex agent behavior, the ability\\nto formally validate prompt examples, and the ability to seamlessly incorporate\\ncontent-focused logical constraints into generation. In particular, our\\ndeclarative approach, in which the desired behavior is simply described without\\nconcern for how it should be implemented or enforced, enables rapid design,\\nimplementation and experimentation with different LLM-based agents. We\\ndemonstrate how the proposed framework can be used to implement recent\\nLLM-based agents, and show how the guardrails our approach provides can lead to\\nimprovements in agent performance. In addition, we release our code for general\\nuse.', links=[{'href': 'http://arxiv.org/abs/2310.08535v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.08535v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='Preprint under review'),\n",
       " ArxivPaper(id='2310.05746v1', title='Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and\\n  Execution of LLM Agents in an Auction Arena', published='2023-10-09T14:22:09Z', authors=['Jiangjie Chen', 'Siyu Yuan', 'Rong Ye', 'Bodhisattwa Prasad Majumder', 'Kyle Richardson'], abstract='Can Large Language Models (LLMs) simulate human behavior in complex\\nenvironments? LLMs have recently been shown to exhibit advanced reasoning\\nskills but much of NLP evaluation still relies on static benchmarks. Answering\\nthis requires evaluation environments that probe strategic reasoning in\\ncompetitive, dynamic scenarios that involve long-term planning. We introduce\\nAucArena, a novel simulation environment for evaluating LLMs within auctions, a\\nsetting chosen for being highly unpredictable and involving many skills related\\nto resource and risk management, while also being easy to evaluate. We conduct\\nseveral controlled simulations using state-of-the-art LLMs as bidding agents.\\nWe find that through simple prompting, LLMs do indeed demonstrate many of the\\nskills needed for effectively engaging in auctions (e.g., managing budget,\\nadhering to long-term goals and priorities), skills that we find can be\\nsharpened by explicitly encouraging models to be adaptive and observe\\nstrategies in past auctions. These results are significant as they show the\\npotential of using LLM agents to model intricate social dynamics, especially in\\ncompetitive settings. However, we also observe considerable variability in the\\ncapabilities of individual LLMs. Notably, even our most advanced models (GPT-4)\\nare occasionally surpassed by heuristic baselines and human agents,\\nhighlighting the potential for further improvements in the design of LLM agents\\nand the important role that our simulation environment can play in further\\ntesting and refining agent architectures.', links=[{'href': 'http://arxiv.org/abs/2310.05746v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.05746v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='Preprint'),\n",
       " ArxivPaper(id='2310.01444v2', title='Adapting LLM Agents Through Communication', published='2023-10-01T07:50:30Z', authors=['Kuan Wang', 'Yadong Lu', 'Michael Santacroce', 'Yeyun Gong', 'Chao Zhang', 'Yelong Shen'], abstract='Recent advancements in large language models (LLMs) have shown potential for\\nhuman-like agents. To help these agents adapt to new tasks without extensive\\nhuman supervision, we propose the Learning through Communication (LTC)\\nparadigm, a novel training approach enabling LLM agents to improve continuously\\nthrough interactions with their environments and other agents. Recent\\nadvancements in large language models (LLMs) have shown potential for\\nhuman-like agents. To help these agents adapt to new tasks without extensive\\nhuman supervision, we propose the Learning through Communication (LTC)\\nparadigm, a novel training approach enabling LLM agents to improve continuously\\nthrough interactions with their environments and other agents. Through\\niterative exploration and PPO training, LTC empowers the agent to assimilate\\nshort-term experiences into long-term memory. To optimize agent interactions\\nfor task-specific learning, we introduce three structured communication\\npatterns: Monologue, Dialogue, and Analogue-tailored for common tasks such as\\ndecision-making, knowledge-intensive reasoning, and numerical reasoning. We\\nevaluated LTC on three datasets: ALFWorld (decision-making), HotpotQA\\n(knowledge-intensive reasoning), and GSM8k (numerical reasoning). On ALFWorld,\\nit exceeds the instruction tuning baseline by 12% in success rate. On HotpotQA,\\nLTC surpasses the instruction-tuned LLaMA-7B agent by 5.1% in EM score, and it\\noutperforms the instruction-tuned 9x larger PaLM-62B agent by 0.6%. On GSM8k,\\nLTC outperforms the CoT-Tuning baseline by 3.6% in accuracy. The results\\nshowcase the versatility and efficiency of the LTC approach across diverse\\ndomains. We will open-source our code to promote further development of the\\ncommunity.', links=[{'href': 'http://arxiv.org/abs/2310.01444v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2310.01444v2', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='Preprint'),\n",
       " ArxivPaper(id='2308.11136v1', title='Is There Any Social Principle for LLM-Based Agents?', published='2023-08-22T02:32:14Z', authors=['Jitao Bai', 'Simiao Zhang', 'Zhonghao Chen'], abstract='Focus on Large Language Model based agents should involve more than\\n\"human-centered\" alignment or application. We argue that more attention should\\nbe paid to the agent itself and discuss the potential of social sciences for\\nagents.', links=[{'href': 'http://arxiv.org/abs/2308.11136v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2308.11136v1', 'rel': 'related', 'type': 'application/pdf'}], journal_ref=None, comment='3 pages, 1 figure')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insane TDD and craxy coverage ◉_◉\n",
    "query = ArxivScraper()\n",
    "query.search_papers('all:LLM+AND+abs:Agents', max_results=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv2arxode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
